{"title":"FastAI Course Lecture 2 Notes","markdown":{"yaml":{"title":"FastAI Course Lecture 2 Notes","author":"Kanav Sharma","date":"2024-04-09","categories":["Computer Vision","FastAI"],"toc":true,"title-block-banner":true,"order":0},"headingText":"This notebook is to enhance my learning on lecture 2 of FAST AI course so I'll be creating a big cat classification model","containsRefs":false,"markdown":"\n\n\nLet's install all required packages\n\n``` python\n#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n```\n\n```         \n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m719.8/719.8 kB[0m [31m7.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m510.5/510.5 kB[0m [31m10.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m116.3/116.3 kB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m194.1/194.1 kB[0m [31m9.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.8/134.8 kB[0m [31m15.4 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m16.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m23.7/23.7 MB[0m [31m15.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m823.6/823.6 kB[0m [31m26.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m14.1/14.1 MB[0m [31m53.7 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m731.7/731.7 MB[0m [31m901.8 kB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m410.6/410.6 MB[0m [31m2.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m121.6/121.6 MB[0m [31m8.2 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m56.5/56.5 MB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m124.2/124.2 MB[0m [31m8.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m196.0/196.0 MB[0m [31m2.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m166.0/166.0 MB[0m [31m7.2 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m99.1/99.1 kB[0m [31m15.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m21.1/21.1 MB[0m [31m68.6 MB/s[0m eta [36m0:00:00[0m\n[?25hMounted at /content/gdrive\n```\n\n## 1. Download and sort out the data(images).\n\nExtract Data using **DuckDuckGo** function\n\n1.  Create dynamic path according to their name store file\n\n2.  Create a dictionary to track the number of downloaded images per category (e.g., cat).\n\n``` python\n??search_images_ddg\n```\n\n*Signature*: search_images_ddg(term, max_images=200)\n\n``` python\ncat_types = 'Leopard','Cougar','Tiger','Lion','Cheetah','SnowLeopard'\npath = Path('CAT')\n\n#remove folder with file in it\nimport shutil\nif path.exists():\n  shutil.rmtree(path)\n\nper_cat_count = {}\n\nif not path.exists():\n    path.mkdir()\n    for o in cat_types:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True)\n        results = search_images_ddg(f'{o}')\n        download_images(dest, urls=results)\n        per_cat_count[f'{o}'] = len(results)\n```\n\n```         \n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n```\n\nCount of Images per category\n\n``` python\nper_cat_count\n```\n\n```         \n{'Leopard': 200,\n 'Cougar': 200,\n 'Tiger': 200,\n 'Lion': 200,\n 'Cheetah': 200,\n 'SnowLeopard': 200}\n```\n\nSo we got 200 images per type\n\nWhile downloading we can get corrupt images.So lets first remove them. `verify_images()` will return path of such images and using `unlink` we can remove these files.\n\n``` python\nfns = get_image_files(path)\ntotal_imagelength = len(fns)\nfailed = verify_images(fns)\nfailed_imagelength = len(failed)\nfailed\n```\n\n```         \n(#51) [Path('CAT/Lion/d61427d6-f097-4727-a3ba-de31366199d6.jpg'),Path('CAT/Lion/85f17699-5ebe-4e88-9798-14b7e66281d7.png'),Path('CAT/Lion/84589c8d-a1da-45be-9fe6-1f87a34289b3.jpg'),Path('CAT/Lion/cf746926-23d6-4754-b7d0-25779410ee15.jpg'),Path('CAT/SnowLeopard/f3ce804b-5071-4312-8633-9895e721340c.jpg'),Path('CAT/SnowLeopard/961333aa-79da-4dc2-9f56-f4d07697a14e.jpg'),Path('CAT/SnowLeopard/57b3a667-1d3e-47bb-8fff-3e1505a5a12f.jpg'),Path('CAT/SnowLeopard/1b3f2639-1c5d-4e26-86c8-feb4b99bf76a.jpg'),Path('CAT/Cougar/cd7a89c9-8667-4d24-aceb-3a85bb7b247e.jpg'),Path('CAT/Cougar/44b6067c-f159-4d5f-819a-11e7d50a3fd8.jpg')...]\n```\n\n``` python\nfailed.map(Path.unlink);\nDict = {\"Total_Image_Count\": total_imagelength, \"Failed_Image_Count\": failed_imagelength}\nDict\n```\n\n```         \n{'Total_Image_Count': 1115, 'Failed_Image_Count': 51}\n```\n\n## 2. Prepare data for model training (Data Loaders, Data Augmentaion, etc.).\n\nCreate a data block and load that data block in data loader.\n\n-   Data Block - Is a blueprint on how to assemble data that we want to send for training.\n-   Data Loader - Is used to pass that data which is in batch format(i.e created using data blocks) to the GPU.\n\n``` python\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = big_cat.dataloaders(path)\n```\n\n**DataBlock** is a convenient way to organize the data loading, splitting, and transformation steps in preparation for training a deep learning model using the fastai library.\n\n`DataBlock()`: is suitable for a classification task where you have a dataset of images, and each image belongs to a specific category (e.g., types of cats).\n\n`blocks=(ImageBlock, CategoryBlock)`: It specify that our inputs are images & our targets are categories(types of big cat)\n\n`get_image_files`: This helps to get list of all the images from subfolder.\n\n`parent_label`: This is a function that extracts the labels (categories) for each item.'Leapord','Tiger','Lion'\n\nA `DataLoaders` includes validation and training `DataLoader`. Let's check random validation dataset.\n\n``` python\ndls.valid.show_batch(max_n=6, nrows=2)\n```\n\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_19_0.png)\n\n**Squishing or Padding for Model Training :**\n\n-   Squishing or padding is applied to images during training.\n-   Cropping may result in data loss, while squishing/stretching can lead to unrealistic shapes, impacting accuracy.\n-   Padding may introduce excessive empty space, causing wasted computation.\n\n**Practical Approach - Data Augmentation:** The idea of getting different picture every time from same image is called data augmentation.\n\n-   Randomly select and crop parts of the image during each epoch.\n-   Train the model on different image parts across multiple epochs.\n-   This approach creates random variations in input data without altering its meaning.\n-   Aiming to provide diverse perspectives, it ensures that the model sees different pictures from the same image in each iteration..\n\n------------------------------------------------------------------------\n\nTo train our model, we'll use `RandomResizedCrop` with an image size of 224 px, which is fairly standard for image classification, and default `aug_transforms`:\n\n``` python\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n```\n\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_21_0.png)\n\n## 3. Train the model\n\n**Tip1** - Prioritaize to train a quick and simple model first, rather than going for big model directly.\n\n**Tip2** - Build model first and then clean the data. And then again train the model.\n\n``` python\nlearn = vision_learner(big_cat_dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 1.878671   | 0.548061   | 0.183962   | 00:36 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 0.669399   | 0.442041   | 0.160377   | 00:36 |\n| 1     | 0.566393   | 0.425440   | 0.136792   | 00:38 |\n| 2     | 0.476826   | 0.555463   | 0.179245   | 00:38 |\n| 3     | 0.429597   | 0.524273   | 0.146226   | 00:37 |\n| 4     | 0.367606   | 0.519690   | 0.117925   | 00:36 |\n| 5     | 0.319734   | 0.529199   | 0.113208   | 00:37 |\n| 6     | 0.287094   | 0.516044   | 0.127358   | 00:38 |\n| 7     | 0.260760   | 0.514551   | 0.132075   | 00:36 |\n\nHere we see, in last epoch rise in error_rate which means that in stochastic gradient descent we have surpassed deepest point and trending towards upward direction which leads to higher loss rate. It indicates that the training process should likely be stopped to prevent further divergence from the optimal solution\n\n###Visualize Confusion Matrix\n\n``` python\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_26_4.png)\n\n`plot_top_losses` shows us the images with the highest loss in our dataset.\n\n``` python\ninterp.plot_top_losses(4, nrows=1, figsize=(18,4))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_28_2.png)\n\n## 4. Clean the data\n\n`ImageClassifierCleaner` enables us to review all images associated with a specific category and identify their placement within the dataloader, whether in the training or validation set.\n\nThe images are organized in ascending order of confidence, prioritizing those with the highest loss. This allows for efficient data sorting by simply examining the initial images. Users can choose to keep, delete, or modify the category label (type of cat) as required\n\n``` python\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nVBox(children=(Dropdown(options=('Cheetah', 'Cougar', 'Leopard', 'Lion', 'SnowLeopard', 'Tiger'), value='Cheet…\n```\n\nThe `Cleaner` possesses information regarding the files we deleted and whose labels we modified. Now, we will implement these changes.\n\n``` python\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n```\n\n## 5. Re train the model using updated data\n\n``` python\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n```\n\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_35_0.png)\n\n``` python\nlearn = vision_learner(big_cat_dls, resnet34, metrics=error_rate)\nlearn.fine_tune(8)\n```\n\n```         \nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 121MB/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 1.839337   | 0.557398   | 0.161137   | 00:36 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 0.552628   | 0.516515   | 0.137441   | 00:37 |\n| 1     | 0.457381   | 0.544474   | 0.175355   | 00:42 |\n| 2     | 0.399777   | 0.615449   | 0.146919   | 00:38 |\n| 3     | 0.345620   | 0.601597   | 0.151659   | 00:40 |\n| 4     | 0.293677   | 0.630620   | 0.146919   | 00:37 |\n| 5     | 0.256501   | 0.669779   | 0.137441   | 00:37 |\n| 6     | 0.227690   | 0.648144   | 0.142180   | 00:36 |\n| 7     | 0.207254   | 0.651927   | 0.137441   | 00:37 |\n\n``` python\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_37_4.png)\n\n``` python\ninterp.plot_top_losses(4, nrows=1, figsize=(17,4))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_38_2.png)\n\n#### So by reading confusion matrix and looking at output from plot_top_losses, we can say that we still have a problem with our data and it will take a lot more iteration to fix it. For now, let's conclude our efforts at this point.\n\n## 6. Let's download our model and use it make prediction. In next lesson 😊.\n\n``` python\nlearn.export('Lecture2_Big_Cat_Model.pkl')\n```\n\n## 7. Live Model\n\nYou can access live model [here](https://huggingface.co/spaces/mekanavsharma/minima) deployed using Hugging Face & gradio. Wanna know how to do it ? refer [Gradio-HuggingFace](https://www.tanishq.ai/blog/posts/2021-11-16-gradio-huggingface.html).\n\nYou can access repo [here](https://huggingface.co/spaces/mekanavsharma/minima/tree/main)\n","srcMarkdownNoYaml":"\n\n# This notebook is to enhance my learning on lecture 2 of FAST AI course so I'll be creating a big cat classification model\n\nLet's install all required packages\n\n``` python\n#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n```\n\n```         \n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m719.8/719.8 kB[0m [31m7.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m510.5/510.5 kB[0m [31m10.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m116.3/116.3 kB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m194.1/194.1 kB[0m [31m9.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.8/134.8 kB[0m [31m15.4 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m16.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m23.7/23.7 MB[0m [31m15.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m823.6/823.6 kB[0m [31m26.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m14.1/14.1 MB[0m [31m53.7 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m731.7/731.7 MB[0m [31m901.8 kB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m410.6/410.6 MB[0m [31m2.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m121.6/121.6 MB[0m [31m8.2 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m56.5/56.5 MB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m124.2/124.2 MB[0m [31m8.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m196.0/196.0 MB[0m [31m2.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m166.0/166.0 MB[0m [31m7.2 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m99.1/99.1 kB[0m [31m15.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m21.1/21.1 MB[0m [31m68.6 MB/s[0m eta [36m0:00:00[0m\n[?25hMounted at /content/gdrive\n```\n\n## 1. Download and sort out the data(images).\n\nExtract Data using **DuckDuckGo** function\n\n1.  Create dynamic path according to their name store file\n\n2.  Create a dictionary to track the number of downloaded images per category (e.g., cat).\n\n``` python\n??search_images_ddg\n```\n\n*Signature*: search_images_ddg(term, max_images=200)\n\n``` python\ncat_types = 'Leopard','Cougar','Tiger','Lion','Cheetah','SnowLeopard'\npath = Path('CAT')\n\n#remove folder with file in it\nimport shutil\nif path.exists():\n  shutil.rmtree(path)\n\nper_cat_count = {}\n\nif not path.exists():\n    path.mkdir()\n    for o in cat_types:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True)\n        results = search_images_ddg(f'{o}')\n        download_images(dest, urls=results)\n        per_cat_count[f'{o}'] = len(results)\n```\n\n```         \n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n```\n\nCount of Images per category\n\n``` python\nper_cat_count\n```\n\n```         \n{'Leopard': 200,\n 'Cougar': 200,\n 'Tiger': 200,\n 'Lion': 200,\n 'Cheetah': 200,\n 'SnowLeopard': 200}\n```\n\nSo we got 200 images per type\n\nWhile downloading we can get corrupt images.So lets first remove them. `verify_images()` will return path of such images and using `unlink` we can remove these files.\n\n``` python\nfns = get_image_files(path)\ntotal_imagelength = len(fns)\nfailed = verify_images(fns)\nfailed_imagelength = len(failed)\nfailed\n```\n\n```         \n(#51) [Path('CAT/Lion/d61427d6-f097-4727-a3ba-de31366199d6.jpg'),Path('CAT/Lion/85f17699-5ebe-4e88-9798-14b7e66281d7.png'),Path('CAT/Lion/84589c8d-a1da-45be-9fe6-1f87a34289b3.jpg'),Path('CAT/Lion/cf746926-23d6-4754-b7d0-25779410ee15.jpg'),Path('CAT/SnowLeopard/f3ce804b-5071-4312-8633-9895e721340c.jpg'),Path('CAT/SnowLeopard/961333aa-79da-4dc2-9f56-f4d07697a14e.jpg'),Path('CAT/SnowLeopard/57b3a667-1d3e-47bb-8fff-3e1505a5a12f.jpg'),Path('CAT/SnowLeopard/1b3f2639-1c5d-4e26-86c8-feb4b99bf76a.jpg'),Path('CAT/Cougar/cd7a89c9-8667-4d24-aceb-3a85bb7b247e.jpg'),Path('CAT/Cougar/44b6067c-f159-4d5f-819a-11e7d50a3fd8.jpg')...]\n```\n\n``` python\nfailed.map(Path.unlink);\nDict = {\"Total_Image_Count\": total_imagelength, \"Failed_Image_Count\": failed_imagelength}\nDict\n```\n\n```         \n{'Total_Image_Count': 1115, 'Failed_Image_Count': 51}\n```\n\n## 2. Prepare data for model training (Data Loaders, Data Augmentaion, etc.).\n\nCreate a data block and load that data block in data loader.\n\n-   Data Block - Is a blueprint on how to assemble data that we want to send for training.\n-   Data Loader - Is used to pass that data which is in batch format(i.e created using data blocks) to the GPU.\n\n``` python\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = big_cat.dataloaders(path)\n```\n\n**DataBlock** is a convenient way to organize the data loading, splitting, and transformation steps in preparation for training a deep learning model using the fastai library.\n\n`DataBlock()`: is suitable for a classification task where you have a dataset of images, and each image belongs to a specific category (e.g., types of cats).\n\n`blocks=(ImageBlock, CategoryBlock)`: It specify that our inputs are images & our targets are categories(types of big cat)\n\n`get_image_files`: This helps to get list of all the images from subfolder.\n\n`parent_label`: This is a function that extracts the labels (categories) for each item.'Leapord','Tiger','Lion'\n\nA `DataLoaders` includes validation and training `DataLoader`. Let's check random validation dataset.\n\n``` python\ndls.valid.show_batch(max_n=6, nrows=2)\n```\n\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_19_0.png)\n\n**Squishing or Padding for Model Training :**\n\n-   Squishing or padding is applied to images during training.\n-   Cropping may result in data loss, while squishing/stretching can lead to unrealistic shapes, impacting accuracy.\n-   Padding may introduce excessive empty space, causing wasted computation.\n\n**Practical Approach - Data Augmentation:** The idea of getting different picture every time from same image is called data augmentation.\n\n-   Randomly select and crop parts of the image during each epoch.\n-   Train the model on different image parts across multiple epochs.\n-   This approach creates random variations in input data without altering its meaning.\n-   Aiming to provide diverse perspectives, it ensures that the model sees different pictures from the same image in each iteration..\n\n------------------------------------------------------------------------\n\nTo train our model, we'll use `RandomResizedCrop` with an image size of 224 px, which is fairly standard for image classification, and default `aug_transforms`:\n\n``` python\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n```\n\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_21_0.png)\n\n## 3. Train the model\n\n**Tip1** - Prioritaize to train a quick and simple model first, rather than going for big model directly.\n\n**Tip2** - Build model first and then clean the data. And then again train the model.\n\n``` python\nlearn = vision_learner(big_cat_dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 1.878671   | 0.548061   | 0.183962   | 00:36 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 0.669399   | 0.442041   | 0.160377   | 00:36 |\n| 1     | 0.566393   | 0.425440   | 0.136792   | 00:38 |\n| 2     | 0.476826   | 0.555463   | 0.179245   | 00:38 |\n| 3     | 0.429597   | 0.524273   | 0.146226   | 00:37 |\n| 4     | 0.367606   | 0.519690   | 0.117925   | 00:36 |\n| 5     | 0.319734   | 0.529199   | 0.113208   | 00:37 |\n| 6     | 0.287094   | 0.516044   | 0.127358   | 00:38 |\n| 7     | 0.260760   | 0.514551   | 0.132075   | 00:36 |\n\nHere we see, in last epoch rise in error_rate which means that in stochastic gradient descent we have surpassed deepest point and trending towards upward direction which leads to higher loss rate. It indicates that the training process should likely be stopped to prevent further divergence from the optimal solution\n\n###Visualize Confusion Matrix\n\n``` python\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_26_4.png)\n\n`plot_top_losses` shows us the images with the highest loss in our dataset.\n\n``` python\ninterp.plot_top_losses(4, nrows=1, figsize=(18,4))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_28_2.png)\n\n## 4. Clean the data\n\n`ImageClassifierCleaner` enables us to review all images associated with a specific category and identify their placement within the dataloader, whether in the training or validation set.\n\nThe images are organized in ascending order of confidence, prioritizing those with the highest loss. This allows for efficient data sorting by simply examining the initial images. Users can choose to keep, delete, or modify the category label (type of cat) as required\n\n``` python\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nVBox(children=(Dropdown(options=('Cheetah', 'Cougar', 'Leopard', 'Lion', 'SnowLeopard', 'Tiger'), value='Cheet…\n```\n\nThe `Cleaner` possesses information regarding the files we deleted and whose labels we modified. Now, we will implement these changes.\n\n``` python\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n```\n\n## 5. Re train the model using updated data\n\n``` python\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n```\n\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_35_0.png)\n\n``` python\nlearn = vision_learner(big_cat_dls, resnet34, metrics=error_rate)\nlearn.fine_tune(8)\n```\n\n```         \nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 121MB/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 1.839337   | 0.557398   | 0.161137   | 00:36 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 0.552628   | 0.516515   | 0.137441   | 00:37 |\n| 1     | 0.457381   | 0.544474   | 0.175355   | 00:42 |\n| 2     | 0.399777   | 0.615449   | 0.146919   | 00:38 |\n| 3     | 0.345620   | 0.601597   | 0.151659   | 00:40 |\n| 4     | 0.293677   | 0.630620   | 0.146919   | 00:37 |\n| 5     | 0.256501   | 0.669779   | 0.137441   | 00:37 |\n| 6     | 0.227690   | 0.648144   | 0.142180   | 00:36 |\n| 7     | 0.207254   | 0.651927   | 0.137441   | 00:37 |\n\n``` python\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_37_4.png)\n\n``` python\ninterp.plot_top_losses(4, nrows=1, figsize=(17,4))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n![png](Lecture_2_Production_Self_files/Lecture_2_Production_Self_38_2.png)\n\n#### So by reading confusion matrix and looking at output from plot_top_losses, we can say that we still have a problem with our data and it will take a lot more iteration to fix it. For now, let's conclude our efforts at this point.\n\n## 6. Let's download our model and use it make prediction. In next lesson 😊.\n\n``` python\nlearn.export('Lecture2_Big_Cat_Model.pkl')\n```\n\n## 7. Live Model\n\nYou can access live model [here](https://huggingface.co/spaces/mekanavsharma/minima) deployed using Hugging Face & gradio. Wanna know how to do it ? refer [Gradio-HuggingFace](https://www.tanishq.ai/blog/posts/2021-11-16-gradio-huggingface.html).\n\nYou can access repo [here](https://huggingface.co/spaces/mekanavsharma/minima/tree/main)\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":{"light":"flatly","dark":"solar"},"title-block-banner":true,"title":"FastAI Course Lecture 2 Notes","author":"Kanav Sharma","date":"2024-04-09","categories":["Computer Vision","FastAI"],"order":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}