{"title":"FastAI Course Lecture 6 Part 3 Notes","markdown":{"yaml":{"title":"FastAI Course Lecture 6 Part 3 Notes","author":"Kanav Sharma","date":"2024-05-07","categories":["Computer Vision","FastAI"],"toc":true,"title-block-banner":true,"order":0,"editor":{"markdown":{"wrap":"sentence"}}},"headingText":"Call library, download data, create folder blah blah..","containsRefs":false,"markdown":"\n\n\n``` python\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = Path('/content/food-101/images')\ntest_path = Path('/content/food-101/test')\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n```\n\n```         \nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"5686607872\" class max=\"5686607260\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n100.00% \\[5686607872/5686607260 02:04\\<00:00\\]\n\n</div>\n\n``` python\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n```\n\n![](lecture-6-road-to-the-top-part-3-self_files/lecture-6-road-to-the-top-part-3-self_2_0.png)\n\n### Under-sampling\n\nPreviously, we had very big data to be trained on, which is why it took so long to train our model.\nLearning from that, we can undersample our training dataset so that we can get a picture of which model works best.\nGenerally, if a model is performing well proportion of dataset, it will likely perform well on the whole dataset.\n\nThere are two ways of doing this :\n\n-   We can take 5-10% of all types of food & then train our model\n\n-   We can target 1 food type and train our model on it.\n\nProblem with case 1 is that we would have so little that from every type of food that our model might not be able to understand it well.\nIn case 2, we can significantly reduce the training time and computational resources required.\n\n``` python\nsubfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]\nsubfolder_count = len(subfolders)\nprint(subfolders)\n```\n\n```         \n['fish_and_chips', 'caprese_salad', 'strawberry_shortcake', 'pork_chop', 'edamame', 'macaroni_and_cheese', 'gnocchi', 'lobster_roll_sandwich', 'takoyaki', 'baklava', 'sushi', 'beef_tartare', 'miso_soup', 'steak', 'hot_dog', 'grilled_cheese_sandwich', 'greek_salad', 'crab_cakes', 'falafel', 'beet_salad', 'apple_pie', 'onion_rings', 'chocolate_mousse', 'risotto', 'chicken_wings', 'french_fries', 'pancakes', 'paella', 'chicken_quesadilla', 'gyoza', 'bread_pudding', 'beignets', 'carrot_cake', 'waffles', 'ceviche', 'huevos_rancheros', 'ravioli', 'sashimi', 'bibimbap', 'creme_brulee', 'spaghetti_bolognese', 'cheese_plate', 'oysters', 'filet_mignon', 'baby_back_ribs', 'fried_rice', 'ice_cream', 'tacos', 'cheesecake', 'foie_gras', 'shrimp_and_grits', 'macarons', 'poutine', 'french_onion_soup', 'deviled_eggs', 'grilled_salmon', 'eggs_benedict', 'croque_madame', 'seaweed_salad', 'churros', 'hummus', 'bruschetta', 'club_sandwich', 'ramen', 'clam_chowder', 'cup_cakes', 'hot_and_sour_soup', 'garlic_bread', 'breakfast_burrito', 'guacamole', 'lobster_bisque', 'spring_rolls', 'samosa', 'red_velvet_cake', 'pulled_pork_sandwich', 'escargots', 'chocolate_cake', 'spaghetti_carbonara', 'caesar_salad', 'hamburger', 'tuna_tartare', 'donuts', 'fried_calamari', 'mussels', 'omelette', 'panna_cotta', 'pad_thai', 'beef_carpaccio', 'pizza', 'nachos', 'chicken_curry', 'pho', 'tiramisu', 'frozen_yogurt', 'peking_duck', 'prime_rib', 'cannoli', 'dumplings', 'french_toast', 'lasagna', 'scallops']\n```\n\n``` python\n# let's randomly take baby_back_ribs folder for training\ntrn_path = train_path/'baby_back_ribs'\ntst_files = get_image_files(test_path).sorted()\n```\n\n## GPU Problem\n\nIn the previous file, we encountered a problem regarding GPU, where we run out of memory & have to wait to till our memory was cleared by Kaggle(on Saturday).\nWe can use `Gradient accumulation` or `Half-Precision floating point` to save from future GPU constraints.\nRegarding Half-Precision floating point, we tested it in our [first notebook](https://mekanavsharma.github.io/Blog/posts/FastAI_Course_Lect6_Part1/#model-building) of this series and observed minimal change in performance.\n\n### Gradient Accumulation\n\nWorking of Gradient Accumulation :\n\n-   Forward pass: Input data is fed through the model to compute predictions.\n\n-   Backward pass: Gradients are computed by back-propagating the error through the network.\n\n-   Gradients are accumulated over multiple mini-batches.\n\n-   Model parameters are updated after a certain number of mini-batches.\n\nBy accumulating gradients over multiple batches,it allows to simulate the effects of a larger batch size without exceeding the available memory.\n\nHowever, there is a catch that it can have **Impact on Training Time.** While increasing accumulation can save GPU memory, it may also slow down the training process.\nThe model parameters are updated less frequently, potentially prolonging the convergence time.\n\n### fine_tune() vs fit_one_cycle()\n\n`fine_tune()` It uses transfer learning, where it take a pre-trained model (on ImageNet) & fine-tune it on a specific dataset.\nIdea is to leverage features learned by the pre-trained model & adapt them to new dataset.\n\nIt uses '*discriminative learning rates*', where earlier layers are trained with lower learning rates (taking more time but understand data better) to avoid disrupting the general features they have learned.\nIn contrast, later layers are trained with higher learning rates to adapt more quickly to the new tasks.\n\n`fit_one_cycle()` It used for training a model from scratch or for further fine tuning already fine tuned model.\n\n-   It starts with low learning rate & gradually increases it over the courses of first half of learning rate.\n\n-   In second half it decreases.\n\n-   This cyclical pattern of learning rates is repeated for no of epochs specified.\n\n**fine_tune()** is primarily used for transfer learning, leveraging pre-trained models & adapting them to new data.\nWhile **fit_one_cycle()** is used for training models from scratch or further fine-tuning them using a cyclical learning rate schedule.\n\n**fine_tune()** is faster since it doesn't do an initial fine-tuning of the head.\n\n``` python\ndef train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=5):\n    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=item,\n        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n    cbs = GradientAccumulation(64) if accum else []\n    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n    if finetune:\n        learn.fine_tune(epochs, 0.01)\n        return learn.tta(dl=dls.test_dl(tst_files))\n    else:\n        learn.unfreeze()\n        learn.fit_one_cycle(epochs, 0.01)\n                        \n```\n\n#### Check the available GPU memory on Kaggle.\n\n``` python\nimport torch\n\ndef check_gpu_memory():\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        total_memory = torch.cuda.get_device_properties(device).total_memory\n        reserved_memory = torch.cuda.memory_reserved(device)\n        allocated_memory = torch.cuda.memory_allocated(device)\n        free_memory = total_memory - reserved_memory - allocated_memory\n\n        print(f\"Total GPU memory: {total_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Reserved GPU memory: {reserved_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Allocated GPU memory: {allocated_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Free GPU memory: {free_memory / (1024 ** 3):.2f} GB\")\n    else:\n        print(\"GPU not available.\")\n\n# Call the function to check GPU memory\ncheck_gpu_memory()\n```\n\n```         \nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.00 GB\nAllocated GPU memory: 0.00 GB\nFree GPU memory: 14.75 GB\n```\n\n### Impact of Gradient Accumulation\n\n``` python\ntrain('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:08   |\n+---------+------------+------------+------------+---------+\n\n\\*\\*It took 0:08 In GPU T4\\*2 and 0:22 in GPU P100\\*\\*\n\n#### Memory Consumption and Clearning It after usage\n\n``` python\nimport gc\ndef report_gpu():\n    print(torch.cuda.list_gpu_processes())\n    gc.collect()\n    torch.cuda.empty_cache()\n```\n\n``` python\nreport_gpu()\n```\n\n```         \nGPU:0\nprocess       2200 uses     3250.000 MB GPU memory\n```\n\nSo with `accum=1` the GPU used around 3GB RAM.\nLet's try `accum=2`:\n\n``` python\ntrain('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:06   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     2200.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\nAs we can see that, the RAM usage has now gone down to 2GB.\nIt's not halved since there's other overhead involved (for larger models this overhead is likely to be relatively lower).\n\nLet's try `4`:\n\n``` python\ntrain('convnext_small_in22k', 128, epochs=1, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:08   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     1664.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\nWe are down to half of original version\n\n## Memory Usage of Every Model\n\nLet's test this approach on all models that we want to evaluate and determine the optimal value for gradient accumulation.\nKaggle provides a `16 GB` GPU, and our goal is to fit all of our architectures within this constraint.\n\n`convnext_large_in22k` make GPU Crash always, so let's tone it down to `convnext_base_in22k`\n\n``` python\ntrain('convnext_base_in22k', 256, epochs=2, accum=1, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22k to current convnext_base.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses    12246.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\n``` python\ntrain('convnext_base_in22k', 256, epochs=2, accum=2, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     6988.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\n``` python\ntrain('convnext_base_in22k', 256, epochs=2, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:13   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     4360.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\nWith accum = 4 there 1/3 of the memory consumption than original and also there not very high change in time taken\n\n`vit_base` which is a transformer\n\n``` python\ntrain('vit_base_patch16_224', 224, epochs=2, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```         \nmodel.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:09   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:08   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     2998.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\n## Scaling It Up!, Training on full data\n\nLet's create dictonary of all the required models & the preprocessing techinque like crop,squish etc.\n\n``` python\ntrn_path = train_path\n\nmodels = {\n    'convnext_base_in22k': {\n        (Resize(480), (224)),\n    }, 'vit_base_patch16_224': {\n        (Resize(480, method='squish'), 224),\n        (Resize(480), 224),\n    }\n}\n```\n\n``` python\nmodels.items()\n```\n\n```         \ndict_items([('convnext_base_in22k', {(Resize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}:\nencodes: (Image,object) -> encodes\n(TensorBBox,object) -> encodes\n(TensorPoint,object) -> encodes\ndecodes: , 224)}), ('vit_base_patch16_224', {(Resize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}:\nencodes: (Image,object) -> encodes\n(TensorBBox,object) -> encodes\n(TensorPoint,object) -> encodes\ndecodes: , 224), (Resize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}:\nencodes: (Image,object) -> encodes\n(TensorBBox,object) -> encodes\n(TensorPoint,object) -> encodes\ndecodes: , 224)})])\n```\n\nAppend each set of TTA predictions on the test set into a list called `tta_res`\n\n``` python\ntta_res = []\n\nfor arch,details in models.items():\n    for item,size in details:\n        print('---',arch)\n        print(size)\n        print(item.name)\n        tta_res.append(train(arch, size, item=item, accum=4)) #, epochs=1))\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n```\n\n```         \n--- convnext_base_in22k\n224\nResize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.921503   | 0.649621   | 0.179557   | 12:54   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.623931   | 0.491215   | 0.132964   | 16:42   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.590722   | 0.472942   | 0.128422   | 16:56   |\n+---------+------------+------------+------------+---------+\n| 2       | 0.414496   | 0.423165   | 0.111881   | 16:38   |\n+---------+------------+------------+------------+---------+\n| 3       | 0.234155   | 0.403548   | 0.100291   | 17:14   |\n+---------+------------+------------+------------+---------+\n| 4       | 0.168659   | 0.408064   | 0.099418   | 16:41   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"5\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \n--- vit_base_patch16_224\n224\nResize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 1.048016   | 0.767763   | 0.210891   | 10:24   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.901554   | 0.667587   | 0.179441   | 13:21   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.723949   | 0.652103   | 0.176296   | 13:18   |\n+---------+------------+------------+------------+---------+\n| 2       | 0.525216   | 0.550479   | 0.146302   | 13:19   |\n+---------+------------+------------+------------+---------+\n| 3       | 0.276363   | 0.497780   | 0.126616   | 13:16   |\n+---------+------------+------------+------------+---------+\n| 4       | 0.183772   | 0.490051   | 0.119802   | 13:15   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"5\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \n--- vit_base_patch16_224\n224\nResize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 1.054235   | 0.758079   | 0.205708   | 10:19   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.881566   | 0.701312   | 0.193710   | 13:15   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.741848   | 0.650074   | 0.174490   | 13:15   |\n+---------+------------+------------+------------+---------+\n| 2       | 0.547625   | 0.550333   | 0.144904   | 13:15   |\n+---------+------------+------------+------------+---------+\n| 3       | 0.274780   | 0.499551   | 0.125859   | 13:13   |\n+---------+------------+------------+------------+---------+\n| 4       | 0.173512   | 0.485806   | 0.118987   | 13:15   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"5\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n### Save the Model\n\n``` python\nsave_pickle('/kaggle/working/Lecture6_Part3_tta_res.pkl', tta_res)\n```\n\n## Ensemble\n\n`Learner.tta` returns predictions and targets for each rows.\nWe just want the predictions\n\n``` python\n tta_prs = first(zip(*tta_res))\n```\n\n``` python\ntta_prs\n```\n\n```         \n(tensor([[1.4376e-09, 6.0367e-10, 8.9613e-10,  ..., 5.5386e-09, 8.7931e-08, 4.2121e-10],\n         [4.7340e-05, 7.8465e-06, 1.3157e-05,  ..., 3.5937e-05, 6.6248e-06, 2.0246e-06],\n         [2.3749e-05, 2.8122e-07, 8.3784e-08,  ..., 6.6318e-06, 5.9989e-08, 9.9459e-07],\n         ...,\n         [1.9584e-06, 1.3206e-07, 3.0607e-06,  ..., 1.4922e-07, 5.0935e-09, 8.6562e-08],\n         [4.8399e-03, 1.2087e-04, 4.5856e-04,  ..., 5.0185e-06, 9.4111e-05, 1.8684e-05],\n         [5.0047e-06, 4.3755e-05, 1.8506e-06,  ..., 6.1585e-06, 5.6130e-07, 1.9855e-06]]),\n tensor([[3.4493e-08, 5.3500e-09, 1.6126e-07,  ..., 3.8252e-08, 1.5104e-06, 2.6966e-09],\n         [6.6286e-03, 7.0347e-05, 3.0234e-05,  ..., 1.9852e-04, 4.9287e-05, 1.0562e-05],\n         [3.3405e-08, 9.6962e-08, 1.1187e-08,  ..., 7.3134e-08, 6.8583e-09, 2.5434e-08],\n         ...,\n         [3.6105e-09, 2.5499e-09, 1.0355e-07,  ..., 4.7640e-10, 4.5013e-08, 5.3833e-10],\n         [1.8239e-06, 1.0662e-06, 9.2194e-07,  ..., 7.3355e-07, 1.3718e-07, 8.0097e-07],\n         [8.3010e-08, 1.5209e-06, 3.5702e-07,  ..., 2.3531e-07, 7.9341e-09, 3.4715e-09]]),\n tensor([[2.3078e-09, 5.1558e-09, 2.3751e-09,  ..., 1.5020e-08, 2.7991e-08, 4.2394e-10],\n         [2.2522e-02, 1.2250e-05, 2.0199e-05,  ..., 1.2231e-04, 7.0627e-06, 2.2908e-06],\n         [1.0235e-07, 1.3238e-08, 4.5449e-09,  ..., 8.5051e-09, 9.0174e-10, 2.8542e-08],\n         ...,\n         [1.2824e-07, 1.0214e-08, 1.7250e-07,  ..., 3.6925e-09, 3.7722e-07, 2.4337e-09],\n         [1.6956e-05, 5.6481e-06, 5.4464e-06,  ..., 1.2303e-06, 1.3186e-05, 2.0320e-04],\n         [4.9362e-08, 1.2064e-06, 1.6594e-06,  ..., 1.0572e-08, 2.2195e-08, 4.6684e-09]]))\n```\n\n`Ensemble` is a model which is combination of multiple models.\nBagging,Boosting are it's types.Those are bit complicated & we will stick to simple version that is averaging them out.\n\n``` python\navg_pr = torch.stack(tta_prs).mean(0)\navg_pr.shape\n```\n\n```         \ntorch.Size([15150, 101])\n```\n\n## Test Data Set\n\n``` python\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=Resize(480, method='squish'),\n    batch_tfms=aug_transforms(size=224, min_scale=0.75))\n```\n\n``` python\nidxs = avg_pr.argmax(dim=1)\nidxs\n```\n\n```         \ntensor([57, 71, 24,  ..., 32, 47, 38])\n```\n\n``` python\nvocab = np.array(dls.vocab)\nvocab\n```\n\n```         \narray(['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli',\n       'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros',\n       'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel',\n       'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad',\n       'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque',\n       'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta',\n       'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad',\n       'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles'],\n      dtype='<U23')\n```\n\n``` python\ntst_files = get_image_files(test_path).sorted()\nfilenames = [path.name for path in tst_files]\nss = pd.DataFrame({'image_id': filenames})\nss['label'] = vocab[idxs]\nss\n```\n\n<div>\n\n```{=html}\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n```\n+-------+-------------+---------------------+\n|       | image_id    | label               |\n+=======+=============+=====================+\n| 0     | 1000314.jpg | hummus              |\n+-------+-------------+---------------------+\n| 1     | 1000412.jpg | paella              |\n+-------+-------------+---------------------+\n| 2     | 1000873.jpg | clam_chowder        |\n+-------+-------------+---------------------+\n| 3     | 100127.jpg  | spaghetti_bolognese |\n+-------+-------------+---------------------+\n| 4     | 1001332.jpg | panna_cotta         |\n+-------+-------------+---------------------+\n| ...   | ...         | ...                 |\n+-------+-------------+---------------------+\n| 15145 | 999118.jpg  | french_onion_soup   |\n+-------+-------------+---------------------+\n| 15146 | 999178.jpg  | cup_cakes           |\n+-------+-------------+---------------------+\n| 15147 | 999236.jpg  | dumplings           |\n+-------+-------------+---------------------+\n| 15148 | 999449.jpg  | gnocchi             |\n+-------+-------------+---------------------+\n| 15149 | 999908.jpg  | fish_and_chips      |\n+-------+-------------+---------------------+\n\n<p>15150 rows Ã— 2 columns</p>\n\n</div>\n\n### Save the file\n\n``` python\nss.to_csv('/kaggle/working/Subm_Part3.csv', index=False)\n```\n\n## Concluding Remarks\n\n`convnext_base` worked way better than `convnext_tiny` and significantly, better than both data augmentated variants of the transformer models `ViT`.\nAnd in the end we created a ensemble model by averaging them all.\n","srcMarkdownNoYaml":"\n\n## Call library, download data, create folder blah blah..\n\n``` python\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = Path('/content/food-101/images')\ntest_path = Path('/content/food-101/test')\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n```\n\n```         \nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"5686607872\" class max=\"5686607260\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n100.00% \\[5686607872/5686607260 02:04\\<00:00\\]\n\n</div>\n\n``` python\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n```\n\n![](lecture-6-road-to-the-top-part-3-self_files/lecture-6-road-to-the-top-part-3-self_2_0.png)\n\n### Under-sampling\n\nPreviously, we had very big data to be trained on, which is why it took so long to train our model.\nLearning from that, we can undersample our training dataset so that we can get a picture of which model works best.\nGenerally, if a model is performing well proportion of dataset, it will likely perform well on the whole dataset.\n\nThere are two ways of doing this :\n\n-   We can take 5-10% of all types of food & then train our model\n\n-   We can target 1 food type and train our model on it.\n\nProblem with case 1 is that we would have so little that from every type of food that our model might not be able to understand it well.\nIn case 2, we can significantly reduce the training time and computational resources required.\n\n``` python\nsubfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]\nsubfolder_count = len(subfolders)\nprint(subfolders)\n```\n\n```         \n['fish_and_chips', 'caprese_salad', 'strawberry_shortcake', 'pork_chop', 'edamame', 'macaroni_and_cheese', 'gnocchi', 'lobster_roll_sandwich', 'takoyaki', 'baklava', 'sushi', 'beef_tartare', 'miso_soup', 'steak', 'hot_dog', 'grilled_cheese_sandwich', 'greek_salad', 'crab_cakes', 'falafel', 'beet_salad', 'apple_pie', 'onion_rings', 'chocolate_mousse', 'risotto', 'chicken_wings', 'french_fries', 'pancakes', 'paella', 'chicken_quesadilla', 'gyoza', 'bread_pudding', 'beignets', 'carrot_cake', 'waffles', 'ceviche', 'huevos_rancheros', 'ravioli', 'sashimi', 'bibimbap', 'creme_brulee', 'spaghetti_bolognese', 'cheese_plate', 'oysters', 'filet_mignon', 'baby_back_ribs', 'fried_rice', 'ice_cream', 'tacos', 'cheesecake', 'foie_gras', 'shrimp_and_grits', 'macarons', 'poutine', 'french_onion_soup', 'deviled_eggs', 'grilled_salmon', 'eggs_benedict', 'croque_madame', 'seaweed_salad', 'churros', 'hummus', 'bruschetta', 'club_sandwich', 'ramen', 'clam_chowder', 'cup_cakes', 'hot_and_sour_soup', 'garlic_bread', 'breakfast_burrito', 'guacamole', 'lobster_bisque', 'spring_rolls', 'samosa', 'red_velvet_cake', 'pulled_pork_sandwich', 'escargots', 'chocolate_cake', 'spaghetti_carbonara', 'caesar_salad', 'hamburger', 'tuna_tartare', 'donuts', 'fried_calamari', 'mussels', 'omelette', 'panna_cotta', 'pad_thai', 'beef_carpaccio', 'pizza', 'nachos', 'chicken_curry', 'pho', 'tiramisu', 'frozen_yogurt', 'peking_duck', 'prime_rib', 'cannoli', 'dumplings', 'french_toast', 'lasagna', 'scallops']\n```\n\n``` python\n# let's randomly take baby_back_ribs folder for training\ntrn_path = train_path/'baby_back_ribs'\ntst_files = get_image_files(test_path).sorted()\n```\n\n## GPU Problem\n\nIn the previous file, we encountered a problem regarding GPU, where we run out of memory & have to wait to till our memory was cleared by Kaggle(on Saturday).\nWe can use `Gradient accumulation` or `Half-Precision floating point` to save from future GPU constraints.\nRegarding Half-Precision floating point, we tested it in our [first notebook](https://mekanavsharma.github.io/Blog/posts/FastAI_Course_Lect6_Part1/#model-building) of this series and observed minimal change in performance.\n\n### Gradient Accumulation\n\nWorking of Gradient Accumulation :\n\n-   Forward pass: Input data is fed through the model to compute predictions.\n\n-   Backward pass: Gradients are computed by back-propagating the error through the network.\n\n-   Gradients are accumulated over multiple mini-batches.\n\n-   Model parameters are updated after a certain number of mini-batches.\n\nBy accumulating gradients over multiple batches,it allows to simulate the effects of a larger batch size without exceeding the available memory.\n\nHowever, there is a catch that it can have **Impact on Training Time.** While increasing accumulation can save GPU memory, it may also slow down the training process.\nThe model parameters are updated less frequently, potentially prolonging the convergence time.\n\n### fine_tune() vs fit_one_cycle()\n\n`fine_tune()` It uses transfer learning, where it take a pre-trained model (on ImageNet) & fine-tune it on a specific dataset.\nIdea is to leverage features learned by the pre-trained model & adapt them to new dataset.\n\nIt uses '*discriminative learning rates*', where earlier layers are trained with lower learning rates (taking more time but understand data better) to avoid disrupting the general features they have learned.\nIn contrast, later layers are trained with higher learning rates to adapt more quickly to the new tasks.\n\n`fit_one_cycle()` It used for training a model from scratch or for further fine tuning already fine tuned model.\n\n-   It starts with low learning rate & gradually increases it over the courses of first half of learning rate.\n\n-   In second half it decreases.\n\n-   This cyclical pattern of learning rates is repeated for no of epochs specified.\n\n**fine_tune()** is primarily used for transfer learning, leveraging pre-trained models & adapting them to new data.\nWhile **fit_one_cycle()** is used for training models from scratch or further fine-tuning them using a cyclical learning rate schedule.\n\n**fine_tune()** is faster since it doesn't do an initial fine-tuning of the head.\n\n``` python\ndef train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=5):\n    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=item,\n        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n    cbs = GradientAccumulation(64) if accum else []\n    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n    if finetune:\n        learn.fine_tune(epochs, 0.01)\n        return learn.tta(dl=dls.test_dl(tst_files))\n    else:\n        learn.unfreeze()\n        learn.fit_one_cycle(epochs, 0.01)\n                        \n```\n\n#### Check the available GPU memory on Kaggle.\n\n``` python\nimport torch\n\ndef check_gpu_memory():\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        total_memory = torch.cuda.get_device_properties(device).total_memory\n        reserved_memory = torch.cuda.memory_reserved(device)\n        allocated_memory = torch.cuda.memory_allocated(device)\n        free_memory = total_memory - reserved_memory - allocated_memory\n\n        print(f\"Total GPU memory: {total_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Reserved GPU memory: {reserved_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Allocated GPU memory: {allocated_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Free GPU memory: {free_memory / (1024 ** 3):.2f} GB\")\n    else:\n        print(\"GPU not available.\")\n\n# Call the function to check GPU memory\ncheck_gpu_memory()\n```\n\n```         \nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.00 GB\nAllocated GPU memory: 0.00 GB\nFree GPU memory: 14.75 GB\n```\n\n### Impact of Gradient Accumulation\n\n``` python\ntrain('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:08   |\n+---------+------------+------------+------------+---------+\n\n\\*\\*It took 0:08 In GPU T4\\*2 and 0:22 in GPU P100\\*\\*\n\n#### Memory Consumption and Clearning It after usage\n\n``` python\nimport gc\ndef report_gpu():\n    print(torch.cuda.list_gpu_processes())\n    gc.collect()\n    torch.cuda.empty_cache()\n```\n\n``` python\nreport_gpu()\n```\n\n```         \nGPU:0\nprocess       2200 uses     3250.000 MB GPU memory\n```\n\nSo with `accum=1` the GPU used around 3GB RAM.\nLet's try `accum=2`:\n\n``` python\ntrain('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:06   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     2200.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\nAs we can see that, the RAM usage has now gone down to 2GB.\nIt's not halved since there's other overhead involved (for larger models this overhead is likely to be relatively lower).\n\nLet's try `4`:\n\n``` python\ntrain('convnext_small_in22k', 128, epochs=1, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:08   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     1664.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\nWe are down to half of original version\n\n## Memory Usage of Every Model\n\nLet's test this approach on all models that we want to evaluate and determine the optimal value for gradient accumulation.\nKaggle provides a `16 GB` GPU, and our goal is to fit all of our architectures within this constraint.\n\n`convnext_large_in22k` make GPU Crash always, so let's tone it down to `convnext_base_in22k`\n\n``` python\ntrain('convnext_base_in22k', 256, epochs=2, accum=1, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22k to current convnext_base.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses    12246.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\n``` python\ntrain('convnext_base_in22k', 256, epochs=2, accum=2, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     6988.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\n``` python\ntrain('convnext_base_in22k', 256, epochs=2, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:13   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:12   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     4360.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\nWith accum = 4 there 1/3 of the memory consumption than original and also there not very high change in time taken\n\n`vit_base` which is a transformer\n\n``` python\ntrain('vit_base_patch16_224', 224, epochs=2, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n```\n\n```         \nmodel.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.000000   | 0.000000   | 0.000000   | 00:09   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.000000   | 0.000000   | 0.000000   | 00:08   |\n+---------+------------+------------+------------+---------+\n\n```         \nReport GPU:\nGPU:0\nprocess       2200 uses     2998.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\n```\n\n## Scaling It Up!, Training on full data\n\nLet's create dictonary of all the required models & the preprocessing techinque like crop,squish etc.\n\n``` python\ntrn_path = train_path\n\nmodels = {\n    'convnext_base_in22k': {\n        (Resize(480), (224)),\n    }, 'vit_base_patch16_224': {\n        (Resize(480, method='squish'), 224),\n        (Resize(480), 224),\n    }\n}\n```\n\n``` python\nmodels.items()\n```\n\n```         \ndict_items([('convnext_base_in22k', {(Resize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}:\nencodes: (Image,object) -> encodes\n(TensorBBox,object) -> encodes\n(TensorPoint,object) -> encodes\ndecodes: , 224)}), ('vit_base_patch16_224', {(Resize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}:\nencodes: (Image,object) -> encodes\n(TensorBBox,object) -> encodes\n(TensorPoint,object) -> encodes\ndecodes: , 224), (Resize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}:\nencodes: (Image,object) -> encodes\n(TensorBBox,object) -> encodes\n(TensorPoint,object) -> encodes\ndecodes: , 224)})])\n```\n\nAppend each set of TTA predictions on the test set into a list called `tta_res`\n\n``` python\ntta_res = []\n\nfor arch,details in models.items():\n    for item,size in details:\n        print('---',arch)\n        print(size)\n        print(item.name)\n        tta_res.append(train(arch, size, item=item, accum=4)) #, epochs=1))\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n```\n\n```         \n--- convnext_base_in22k\n224\nResize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.921503   | 0.649621   | 0.179557   | 12:54   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.623931   | 0.491215   | 0.132964   | 16:42   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.590722   | 0.472942   | 0.128422   | 16:56   |\n+---------+------------+------------+------------+---------+\n| 2       | 0.414496   | 0.423165   | 0.111881   | 16:38   |\n+---------+------------+------------+------------+---------+\n| 3       | 0.234155   | 0.403548   | 0.100291   | 17:14   |\n+---------+------------+------------+------------+---------+\n| 4       | 0.168659   | 0.408064   | 0.099418   | 16:41   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"5\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \n--- vit_base_patch16_224\n224\nResize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 1.048016   | 0.767763   | 0.210891   | 10:24   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.901554   | 0.667587   | 0.179441   | 13:21   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.723949   | 0.652103   | 0.176296   | 13:18   |\n+---------+------------+------------+------------+---------+\n| 2       | 0.525216   | 0.550479   | 0.146302   | 13:19   |\n+---------+------------+------------+------------+---------+\n| 3       | 0.276363   | 0.497780   | 0.126616   | 13:16   |\n+---------+------------+------------+------------+---------+\n| 4       | 0.183772   | 0.490051   | 0.119802   | 13:15   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"5\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \n--- vit_base_patch16_224\n224\nResize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (<Resampling.BILINEAR: 2>, <Resampling.NEAREST: 0>), 'p': 1.0}\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 1.054235   | 0.758079   | 0.205708   | 10:19   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n+---------+------------+------------+------------+---------+\n| epoch   | train_loss | valid_loss | error_rate | time    |\n+=========+============+============+============+=========+\n| 0       | 0.881566   | 0.701312   | 0.193710   | 13:15   |\n+---------+------------+------------+------------+---------+\n| 1       | 0.741848   | 0.650074   | 0.174490   | 13:15   |\n+---------+------------+------------+------------+---------+\n| 2       | 0.547625   | 0.550333   | 0.144904   | 13:15   |\n+---------+------------+------------+------------+---------+\n| 3       | 0.274780   | 0.499551   | 0.125859   | 13:13   |\n+---------+------------+------------+------------+---------+\n| 4       | 0.173512   | 0.485806   | 0.118987   | 13:15   |\n+---------+------------+------------+------------+---------+\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"5\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n### Save the Model\n\n``` python\nsave_pickle('/kaggle/working/Lecture6_Part3_tta_res.pkl', tta_res)\n```\n\n## Ensemble\n\n`Learner.tta` returns predictions and targets for each rows.\nWe just want the predictions\n\n``` python\n tta_prs = first(zip(*tta_res))\n```\n\n``` python\ntta_prs\n```\n\n```         \n(tensor([[1.4376e-09, 6.0367e-10, 8.9613e-10,  ..., 5.5386e-09, 8.7931e-08, 4.2121e-10],\n         [4.7340e-05, 7.8465e-06, 1.3157e-05,  ..., 3.5937e-05, 6.6248e-06, 2.0246e-06],\n         [2.3749e-05, 2.8122e-07, 8.3784e-08,  ..., 6.6318e-06, 5.9989e-08, 9.9459e-07],\n         ...,\n         [1.9584e-06, 1.3206e-07, 3.0607e-06,  ..., 1.4922e-07, 5.0935e-09, 8.6562e-08],\n         [4.8399e-03, 1.2087e-04, 4.5856e-04,  ..., 5.0185e-06, 9.4111e-05, 1.8684e-05],\n         [5.0047e-06, 4.3755e-05, 1.8506e-06,  ..., 6.1585e-06, 5.6130e-07, 1.9855e-06]]),\n tensor([[3.4493e-08, 5.3500e-09, 1.6126e-07,  ..., 3.8252e-08, 1.5104e-06, 2.6966e-09],\n         [6.6286e-03, 7.0347e-05, 3.0234e-05,  ..., 1.9852e-04, 4.9287e-05, 1.0562e-05],\n         [3.3405e-08, 9.6962e-08, 1.1187e-08,  ..., 7.3134e-08, 6.8583e-09, 2.5434e-08],\n         ...,\n         [3.6105e-09, 2.5499e-09, 1.0355e-07,  ..., 4.7640e-10, 4.5013e-08, 5.3833e-10],\n         [1.8239e-06, 1.0662e-06, 9.2194e-07,  ..., 7.3355e-07, 1.3718e-07, 8.0097e-07],\n         [8.3010e-08, 1.5209e-06, 3.5702e-07,  ..., 2.3531e-07, 7.9341e-09, 3.4715e-09]]),\n tensor([[2.3078e-09, 5.1558e-09, 2.3751e-09,  ..., 1.5020e-08, 2.7991e-08, 4.2394e-10],\n         [2.2522e-02, 1.2250e-05, 2.0199e-05,  ..., 1.2231e-04, 7.0627e-06, 2.2908e-06],\n         [1.0235e-07, 1.3238e-08, 4.5449e-09,  ..., 8.5051e-09, 9.0174e-10, 2.8542e-08],\n         ...,\n         [1.2824e-07, 1.0214e-08, 1.7250e-07,  ..., 3.6925e-09, 3.7722e-07, 2.4337e-09],\n         [1.6956e-05, 5.6481e-06, 5.4464e-06,  ..., 1.2303e-06, 1.3186e-05, 2.0320e-04],\n         [4.9362e-08, 1.2064e-06, 1.6594e-06,  ..., 1.0572e-08, 2.2195e-08, 4.6684e-09]]))\n```\n\n`Ensemble` is a model which is combination of multiple models.\nBagging,Boosting are it's types.Those are bit complicated & we will stick to simple version that is averaging them out.\n\n``` python\navg_pr = torch.stack(tta_prs).mean(0)\navg_pr.shape\n```\n\n```         \ntorch.Size([15150, 101])\n```\n\n## Test Data Set\n\n``` python\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=Resize(480, method='squish'),\n    batch_tfms=aug_transforms(size=224, min_scale=0.75))\n```\n\n``` python\nidxs = avg_pr.argmax(dim=1)\nidxs\n```\n\n```         \ntensor([57, 71, 24,  ..., 32, 47, 38])\n```\n\n``` python\nvocab = np.array(dls.vocab)\nvocab\n```\n\n```         \narray(['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli',\n       'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros',\n       'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel',\n       'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad',\n       'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque',\n       'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta',\n       'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad',\n       'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles'],\n      dtype='<U23')\n```\n\n``` python\ntst_files = get_image_files(test_path).sorted()\nfilenames = [path.name for path in tst_files]\nss = pd.DataFrame({'image_id': filenames})\nss['label'] = vocab[idxs]\nss\n```\n\n<div>\n\n```{=html}\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n```\n+-------+-------------+---------------------+\n|       | image_id    | label               |\n+=======+=============+=====================+\n| 0     | 1000314.jpg | hummus              |\n+-------+-------------+---------------------+\n| 1     | 1000412.jpg | paella              |\n+-------+-------------+---------------------+\n| 2     | 1000873.jpg | clam_chowder        |\n+-------+-------------+---------------------+\n| 3     | 100127.jpg  | spaghetti_bolognese |\n+-------+-------------+---------------------+\n| 4     | 1001332.jpg | panna_cotta         |\n+-------+-------------+---------------------+\n| ...   | ...         | ...                 |\n+-------+-------------+---------------------+\n| 15145 | 999118.jpg  | french_onion_soup   |\n+-------+-------------+---------------------+\n| 15146 | 999178.jpg  | cup_cakes           |\n+-------+-------------+---------------------+\n| 15147 | 999236.jpg  | dumplings           |\n+-------+-------------+---------------------+\n| 15148 | 999449.jpg  | gnocchi             |\n+-------+-------------+---------------------+\n| 15149 | 999908.jpg  | fish_and_chips      |\n+-------+-------------+---------------------+\n\n<p>15150 rows Ã— 2 columns</p>\n\n</div>\n\n### Save the file\n\n``` python\nss.to_csv('/kaggle/working/Subm_Part3.csv', index=False)\n```\n\n## Concluding Remarks\n\n`convnext_base` worked way better than `convnext_tiny` and significantly, better than both data augmentated variants of the transformer models `ViT`.\nAnd in the end we created a ensemble model by averaging them all.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":{"markdown":{"wrap":"sentence"}},"theme":{"light":"flatly","dark":"solar"},"title-block-banner":true,"title":"FastAI Course Lecture 6 Part 3 Notes","author":"Kanav Sharma","date":"2024-05-07","categories":["Computer Vision","FastAI"],"order":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}