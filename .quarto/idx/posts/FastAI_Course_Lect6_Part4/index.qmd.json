{"title":"FastAI Course Lecture 6 Part 4 Notes","markdown":{"yaml":{"title":"FastAI Course Lecture 6 Part 4 Notes","author":"Kanav Sharma","date":"2024-05-11","categories":["Computer Vision","FastAI"],"toc":true,"title-block-banner":true,"order":0},"headingText":"AIM : In this we want to create a multi-target model i.e. to predict calorie count & food type.","containsRefs":false,"markdown":"\n\n\n## Call the library, download data, create folder blah blah..\n\n``` python\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = Path('/content/food-101/images')\ntest_path = Path('/content/food-101/test')\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n```\n\n```         \nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"5686607872\" class max=\"5686607260\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n100.00% \\[5686607872/5686607260 02:26\\<00:00\\]\n\n</div>\n\n#### Size of all subfolders\n\n``` python\nsubfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]\nlen(subfolders)\n```\n\n```         \n101\n```\n\n## Calorie and Food Name Folder\n\nCreate a dataframe which will have all Images from training folder as Index and have a sub folder and calorie count(which is random).\n\n``` python\n# Initialize empty lists to store subfolder names and file names\nsubfolder_names = []\nfile_names = []\n\n# Walk through the directory and its subdirectories\nfor root, dirs, files in os.walk(train_path):\n    for file in files:\n        # Get the subfolder name\n        subfolder_name = os.path.relpath(root, train_path)\n        \n        # Append the subfolder name and file name to the lists\n        subfolder_names.append(subfolder_name)\n        file_names.append(file)\n\n# Create a DataFrame\ndf = pd.DataFrame({'Subfolder_Name': subfolder_names, 'File_name': file_names})\n\n# Generate random calories\ncalories = np.random.randint(100, 800, len(list(set(subfolder_names))))\n\n# Create a DataFrame\nCalorie_Df = pd.DataFrame({'Subfolder_Name': list(set(subfolder_names)), 'Calories': calories})\n\n# Merge the two DataFrames on 'Subfolder_Name'\ndf = pd.merge(df, Calorie_Df, on='Subfolder_Name', how='left')\n\n# Display the DataFrame with 'File_name' as the index\ndf.set_index('File_name', inplace=True)\n\n# Display the updated DataFrame\ndf.head()\n```\n\n<div>\n\n```{=html}\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n```\n|             | Subfolder_Name | Calories |\n|-------------|----------------|----------|\n| File_name   |                |          |\n| 524965.jpg  | fish_and_chips | 479      |\n| 1863408.jpg | fish_and_chips | 479      |\n| 16967.jpg   | fish_and_chips | 479      |\n| 1798422.jpg | fish_and_chips | 479      |\n| 3806847.jpg | fish_and_chips | 479      |\n\n</div>\n\n### Get Calorie\n\nGet subsequent calorie as per food type\n\n``` python\ndf.loc['1863408.jpg', 'Calories']\n```\n\n```         \n479\n```\n\n``` python\ndef get_calorie(p): return df.loc[p.name, 'Calories']\n```\n\n## Dataloaders\n\nLet's create `Dataloaders` & to do that we will use `DataBlock` API, which is convenient in achieving our goal.\n\n``` python\ndls = DataBlock(\n    blocks=(ImageBlock,CategoryBlock,CategoryBlock),\n    n_inp=1,\n    get_items=get_image_files,\n    get_y = [parent_label,get_calorie],\n    splitter=RandomSplitter(0.2, seed=42),\n    item_tfms=Resize(192, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75)\n).dataloaders(train_path)\n```\n\n**Explanation of the code**\n\n``` python\nblocks=(ImageBlock,CategoryBlock,CategoryBlock)\n```\n\nIt will generate three outputs: an image (which we want to use for training), a categorical variable representing the calorie content, and another categorical variable representing the food type. We can add as many additional features as needed.\n\n``` python\nn_inp=1\n```\n\nThis line will tell our dataloader that only 1 of them(1st block i.e ImageBlock) is Independent variable & other two are target variable.\n\n``` python\nget_items=get_image_files\n```\n\nUse get_image_files to get a list of inputs.\n\n``` python\nget_y = [parent_label,get_calorie]\n```\n\nTo create the two outputs for each file, call two functions: parent_label (from fastai) and get_calorie (defined above).\n\nRest of the lines are already explained in [1st lecture](https://mekanavsharma.github.io/Blog/posts/FastAI_Course_Lect6_Part1/).\n\n### Batch\n\n``` python\ndls.show_batch(max_n=6)\n```\n\n![](lecture-6-road-to-the-top-part-4-self_files/lecture-6-road-to-the-top-part-4-self_23_0.png)\n\n### Replicating the Food model\n\nNow we'll replicate the same food model we've made before, but have it work with this new data.\n\nThe key difference is that our metrics and loss will now receive three things instead of two: the model outputs (i.e. the metric and loss function inputs), and the two targets (food_type and calorie). Therefore, we need to define slight variations of our metric (error_rate) and loss function (cross_entropy) to pass on just the `food_type` target:\n\n``` python\ndef food_err(inp,food,calorie): return error_rate(inp,food)\ndef food_loss(inp,food,calorie): return F.cross_entropy(inp,food)\n```\n\nWe're now ready to create our learner.\n\nThere's just one wrinkle to be aware of. Now that our `DataLoaders` is returning multiple targets, fastai doesn't know how many outputs our model will need. Therefore we have to pass n_out when we create our `Learner` -- we need `101 outputs`(no of food type), one for each possible disease:\n\n``` python\narch = 'convnext_small_in22k'\nlearn = vision_learner(dls, arch, loss_func=food_loss, metrics=food_err, n_out=101).to_fp16()\nlr = 0.1\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]\n```\n\nWhen we train this model we should get similar results to what we've seen with similar models before:\n\n``` python\nlearn.fine_tune(5, lr)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | time  |\n|-------|------------|------------|----------|-------|\n| 0     | 5.858690   | 16.570326  | 0.348107 | 05:03 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | time  |\n|-------|------------|------------|----------|-------|\n| 0     | 2.052801   | 24.203112  | 0.343390 | 05:33 |\n| 1     | 2.231666   | 2.649899   | 0.373966 | 05:40 |\n| 2     | 1.380835   | 2.181304   | 0.322423 | 05:39 |\n| 3     | 0.629317   | 1.560569   | 0.217123 | 05:32 |\n| 4     | 0.358618   | 1.224057   | 0.192137 | 05:31 |\n\n## Multi-Target Model\n\nWe had a model that predicted 101 things(no of food types) and among these, whichever has the highest probability(food type) will assign ed to that image. Now, I want to have a model that can predict 202 things(101 food type + 101 calorie count).\n\nWe can define `disease_loss` just like we did earlier, but with one important change: the input tensor is now of length 202, not 101, so it doesn't match the number of possible food type. We can pick whatever part of the input we want to be used to predict food type. Let's use the first 101 values:\n\n``` python\ndef food_loss(inp,food,calorie): return F.cross_entropy(inp[:,:101],food)\n```\n\nThat means we can do the same thing for predicting calorie, but use the last 101 values of the input, and set the target to calorie instead of food:\n\n``` python\ndef calorie_loss(inp,food,calorie): return F.cross_entropy(inp[:,101:],calorie)\n```\n\nOur overall loss will then be the sum of these two losses:\n\n``` python\ndef combine_loss(inp,food,calorie): return food_loss(inp,food,calorie)+calorie_loss(inp,food,calorie)\n```\n\nError Rate for each of the output\n\n``` python\ndef food_err(inp,food,calorie): return error_rate(inp[:,:101],food)\ndef calorie_err(inp,food,calorie): return error_rate(inp[:,101:],calorie)\n\nerr_metrics = (food_err,calorie_err)\n\nall_metrics = err_metrics+(food_loss,calorie_loss)\n```\n\n### Let's Create Learner\n\n``` python\nlearn = vision_learner(dls, arch, loss_func=combine_loss, metrics=all_metrics, n_out=202).to_fp16()\n```\n\n``` python\nlearn.fine_tune(5, lr)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | calorie_err | food_loss | calorie_loss | time  |\n|---------|---------|---------|---------|---------|---------|---------|---------|\n| 0     | 13.486178  | 7.905050   | 0.442050 | 0.449971    | 3.916732  | 3.988317     | 04:29 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | calorie_err | food_loss | calorie_loss | time  |\n|---------|---------|---------|---------|---------|---------|---------|---------|\n| 0     | 4.592400   | 44.517895  | 0.462085 | 0.457484    | 30.451624 | 14.066281    | 05:29 |\n| 1     | 4.814772   | 8.256505   | 0.381246 | 0.378975    | 4.196504  | 4.060001     | 05:29 |\n| 2     | 2.942243   | 12.322714  | 0.274898 | 0.278043    | 6.179482  | 6.143233     | 05:29 |\n| 3     | 1.468126   | 3.271619   | 0.213395 | 0.213920    | 1.606259  | 1.665358     | 05:29 |\n| 4     | 0.805262   | 4.968063   | 0.191322 | 0.192137    | 2.348646  | 2.619417     | 05:31 |\n\n### Save the model\n\n``` python\nsave_pickle('/kaggle/working/Lecture6_Part4_multi_model.pkl', learn)\n```\n\n## Conclusion\n\nSo, is this useful?\n\nWell... if you're truly seeking a model capable of predicting multiple outcomes, then absolutely! However, whether this approach will enhance our ability to predict rice disease is uncertain","srcMarkdownNoYaml":"\n\n#### AIM : In this we want to create a multi-target model i.e. to predict calorie count & food type.\n\n## Call the library, download data, create folder blah blah..\n\n``` python\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = Path('/content/food-101/images')\ntest_path = Path('/content/food-101/test')\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n```\n\n```         \nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"5686607872\" class max=\"5686607260\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n100.00% \\[5686607872/5686607260 02:26\\<00:00\\]\n\n</div>\n\n#### Size of all subfolders\n\n``` python\nsubfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]\nlen(subfolders)\n```\n\n```         \n101\n```\n\n## Calorie and Food Name Folder\n\nCreate a dataframe which will have all Images from training folder as Index and have a sub folder and calorie count(which is random).\n\n``` python\n# Initialize empty lists to store subfolder names and file names\nsubfolder_names = []\nfile_names = []\n\n# Walk through the directory and its subdirectories\nfor root, dirs, files in os.walk(train_path):\n    for file in files:\n        # Get the subfolder name\n        subfolder_name = os.path.relpath(root, train_path)\n        \n        # Append the subfolder name and file name to the lists\n        subfolder_names.append(subfolder_name)\n        file_names.append(file)\n\n# Create a DataFrame\ndf = pd.DataFrame({'Subfolder_Name': subfolder_names, 'File_name': file_names})\n\n# Generate random calories\ncalories = np.random.randint(100, 800, len(list(set(subfolder_names))))\n\n# Create a DataFrame\nCalorie_Df = pd.DataFrame({'Subfolder_Name': list(set(subfolder_names)), 'Calories': calories})\n\n# Merge the two DataFrames on 'Subfolder_Name'\ndf = pd.merge(df, Calorie_Df, on='Subfolder_Name', how='left')\n\n# Display the DataFrame with 'File_name' as the index\ndf.set_index('File_name', inplace=True)\n\n# Display the updated DataFrame\ndf.head()\n```\n\n<div>\n\n```{=html}\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n```\n|             | Subfolder_Name | Calories |\n|-------------|----------------|----------|\n| File_name   |                |          |\n| 524965.jpg  | fish_and_chips | 479      |\n| 1863408.jpg | fish_and_chips | 479      |\n| 16967.jpg   | fish_and_chips | 479      |\n| 1798422.jpg | fish_and_chips | 479      |\n| 3806847.jpg | fish_and_chips | 479      |\n\n</div>\n\n### Get Calorie\n\nGet subsequent calorie as per food type\n\n``` python\ndf.loc['1863408.jpg', 'Calories']\n```\n\n```         \n479\n```\n\n``` python\ndef get_calorie(p): return df.loc[p.name, 'Calories']\n```\n\n## Dataloaders\n\nLet's create `Dataloaders` & to do that we will use `DataBlock` API, which is convenient in achieving our goal.\n\n``` python\ndls = DataBlock(\n    blocks=(ImageBlock,CategoryBlock,CategoryBlock),\n    n_inp=1,\n    get_items=get_image_files,\n    get_y = [parent_label,get_calorie],\n    splitter=RandomSplitter(0.2, seed=42),\n    item_tfms=Resize(192, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75)\n).dataloaders(train_path)\n```\n\n**Explanation of the code**\n\n``` python\nblocks=(ImageBlock,CategoryBlock,CategoryBlock)\n```\n\nIt will generate three outputs: an image (which we want to use for training), a categorical variable representing the calorie content, and another categorical variable representing the food type. We can add as many additional features as needed.\n\n``` python\nn_inp=1\n```\n\nThis line will tell our dataloader that only 1 of them(1st block i.e ImageBlock) is Independent variable & other two are target variable.\n\n``` python\nget_items=get_image_files\n```\n\nUse get_image_files to get a list of inputs.\n\n``` python\nget_y = [parent_label,get_calorie]\n```\n\nTo create the two outputs for each file, call two functions: parent_label (from fastai) and get_calorie (defined above).\n\nRest of the lines are already explained in [1st lecture](https://mekanavsharma.github.io/Blog/posts/FastAI_Course_Lect6_Part1/).\n\n### Batch\n\n``` python\ndls.show_batch(max_n=6)\n```\n\n![](lecture-6-road-to-the-top-part-4-self_files/lecture-6-road-to-the-top-part-4-self_23_0.png)\n\n### Replicating the Food model\n\nNow we'll replicate the same food model we've made before, but have it work with this new data.\n\nThe key difference is that our metrics and loss will now receive three things instead of two: the model outputs (i.e. the metric and loss function inputs), and the two targets (food_type and calorie). Therefore, we need to define slight variations of our metric (error_rate) and loss function (cross_entropy) to pass on just the `food_type` target:\n\n``` python\ndef food_err(inp,food,calorie): return error_rate(inp,food)\ndef food_loss(inp,food,calorie): return F.cross_entropy(inp,food)\n```\n\nWe're now ready to create our learner.\n\nThere's just one wrinkle to be aware of. Now that our `DataLoaders` is returning multiple targets, fastai doesn't know how many outputs our model will need. Therefore we have to pass n_out when we create our `Learner` -- we need `101 outputs`(no of food type), one for each possible disease:\n\n``` python\narch = 'convnext_small_in22k'\nlearn = vision_learner(dls, arch, loss_func=food_loss, metrics=food_err, n_out=101).to_fp16()\nlr = 0.1\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]\n```\n\nWhen we train this model we should get similar results to what we've seen with similar models before:\n\n``` python\nlearn.fine_tune(5, lr)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | time  |\n|-------|------------|------------|----------|-------|\n| 0     | 5.858690   | 16.570326  | 0.348107 | 05:03 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | time  |\n|-------|------------|------------|----------|-------|\n| 0     | 2.052801   | 24.203112  | 0.343390 | 05:33 |\n| 1     | 2.231666   | 2.649899   | 0.373966 | 05:40 |\n| 2     | 1.380835   | 2.181304   | 0.322423 | 05:39 |\n| 3     | 0.629317   | 1.560569   | 0.217123 | 05:32 |\n| 4     | 0.358618   | 1.224057   | 0.192137 | 05:31 |\n\n## Multi-Target Model\n\nWe had a model that predicted 101 things(no of food types) and among these, whichever has the highest probability(food type) will assign ed to that image. Now, I want to have a model that can predict 202 things(101 food type + 101 calorie count).\n\nWe can define `disease_loss` just like we did earlier, but with one important change: the input tensor is now of length 202, not 101, so it doesn't match the number of possible food type. We can pick whatever part of the input we want to be used to predict food type. Let's use the first 101 values:\n\n``` python\ndef food_loss(inp,food,calorie): return F.cross_entropy(inp[:,:101],food)\n```\n\nThat means we can do the same thing for predicting calorie, but use the last 101 values of the input, and set the target to calorie instead of food:\n\n``` python\ndef calorie_loss(inp,food,calorie): return F.cross_entropy(inp[:,101:],calorie)\n```\n\nOur overall loss will then be the sum of these two losses:\n\n``` python\ndef combine_loss(inp,food,calorie): return food_loss(inp,food,calorie)+calorie_loss(inp,food,calorie)\n```\n\nError Rate for each of the output\n\n``` python\ndef food_err(inp,food,calorie): return error_rate(inp[:,:101],food)\ndef calorie_err(inp,food,calorie): return error_rate(inp[:,101:],calorie)\n\nerr_metrics = (food_err,calorie_err)\n\nall_metrics = err_metrics+(food_loss,calorie_loss)\n```\n\n### Let's Create Learner\n\n``` python\nlearn = vision_learner(dls, arch, loss_func=combine_loss, metrics=all_metrics, n_out=202).to_fp16()\n```\n\n``` python\nlearn.fine_tune(5, lr)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | calorie_err | food_loss | calorie_loss | time  |\n|---------|---------|---------|---------|---------|---------|---------|---------|\n| 0     | 13.486178  | 7.905050   | 0.442050 | 0.449971    | 3.916732  | 3.988317     | 04:29 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | food_err | calorie_err | food_loss | calorie_loss | time  |\n|---------|---------|---------|---------|---------|---------|---------|---------|\n| 0     | 4.592400   | 44.517895  | 0.462085 | 0.457484    | 30.451624 | 14.066281    | 05:29 |\n| 1     | 4.814772   | 8.256505   | 0.381246 | 0.378975    | 4.196504  | 4.060001     | 05:29 |\n| 2     | 2.942243   | 12.322714  | 0.274898 | 0.278043    | 6.179482  | 6.143233     | 05:29 |\n| 3     | 1.468126   | 3.271619   | 0.213395 | 0.213920    | 1.606259  | 1.665358     | 05:29 |\n| 4     | 0.805262   | 4.968063   | 0.191322 | 0.192137    | 2.348646  | 2.619417     | 05:31 |\n\n### Save the model\n\n``` python\nsave_pickle('/kaggle/working/Lecture6_Part4_multi_model.pkl', learn)\n```\n\n## Conclusion\n\nSo, is this useful?\n\nWell... if you're truly seeking a model capable of predicting multiple outcomes, then absolutely! However, whether this approach will enhance our ability to predict rice disease is uncertain"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.554","editor":"visual","theme":{"light":"flatly","dark":"solar"},"title-block-banner":true,"title":"FastAI Course Lecture 6 Part 4 Notes","author":"Kanav Sharma","date":"2024-05-11","categories":["Computer Vision","FastAI"],"order":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}