{"title":"FastAI Course Lecture 6 Part 2 Notes","markdown":{"yaml":{"title":"FastAI Course Lecture 6 Part 2 Notes","author":"Kanav Sharma","date":"2024-05-03","categories":["Computer Vision","FastAI"],"toc":true,"title-block-banner":true,"order":0},"headingText":"Install FastAI","containsRefs":false,"markdown":"\n\nIn [Lecture6-Part1](https://mekanavsharma.github.io/Blog/posts/FastAI_Course_Lect6_Part1/) we build our model using `resent26d` architecture with best accuracy `73%`. In this notebook we will be using `ConvNeXt` model and aiming towards higher accuracy.\n\n\n``` python\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n```\n\n```         \nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n```\n\n## Let's download food data from FastAI\n\n``` python\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = '/content/food-101/images'\ntest_path = '/content/food-101/test'\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"5686607872\" class max=\"5686607260\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n100.00% \\[5686607872/5686607260 02:31\\<00:00\\]\n\n</div>\n\n## Let's make it faster\n\nLast time, we encountered a problem even though we were using the fastest architecture. It was still taking too long. For a change, let's resize the images to `256` pixels. This will decrease the size of each pixel and allow us to train our model faster.\n\n``` python\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n```\n\n![](Lecture_6_Road_To_The_Top_Part_2_self_files/Lecture_6_Road_To_The_Top_Part_2_self_4_0.png)\n\n### Make it into a function\n\nIn this notebook, we will be experimenting with lots of models, data(image) augmentation, and other techniques. So instead of repeating the same code every time, let's create a function that can be called whenever needed.\n\n``` python\ndef train(arch, item, batch, epochs=4, learning_rate=0.0002):\n    dls = ImageDataLoaders.from_folder(path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n    learn = vision_learner(dls, arch, metrics=error_rate)\n    learn.fine_tune(epochs, learning_rate)\n    return learn\n```\n\nTo ensure consistent function behavior, we have rigidly set the number of epochs and the learning rate value.\n\n### Call the function\n\n``` python\nlearn = train('resnet26d', item=Resize(256),batch=aug_transforms(size=128, min_scale=0.75))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 3.727076   | 2.929649   | 0.664554   | 04:58 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 3.250653   | 2.632962   | 0.618911   | 05:03 |\n| 1     | 2.837729   | 2.394110   | 0.584109   | 05:09 |\n| 2     | 2.680722   | 2.286321   | 0.563812   | 05:10 |\n| 3     | 2.653321   | 2.266845   | 0.560149   | 05:08 |\n\nThough we were able to reduce the time but we got higher error rate.\n\n## ConvNeXt model\n\nIn our previous notebook, we discussed how the **convnext_tiny_in22k** is go-to model. We would like to reduce image size to **192**(multiple 32) & use **squish** method for data augmentation.\n\n``` python\narch = 'convnext_tiny_in22k'\n\nlearn_squish = train(arch, item=Resize(192, method='squish'),batch=aug_transforms(size=128, min_scale=0.75))\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.464850   | 1.882828   | 0.412178   | 17:27 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.082745   | 1.638774   | 0.375693   | 21:36 |\n| 1     | 1.828319   | 1.418455   | 0.350842   | 21:36 |\n| 2     | 1.719477   | 1.355143   | 0.342327   | 21:34 |\n| 3     | 1.633262   | 1.351079   | 0.340000   | 21:38 |\n\n## Data Augmentation\n\n### Crop\n\n**Squish** has already been performed in the last scenario, so let's check on crop method, which is default in Fastai.\n\n``` python\nlearn_crop = train(arch, item=Resize(192),batch=aug_transforms(size=128, min_scale=0.75))\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.491307   | 1.843047   | 0.401188   | 17:40 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.034851   | 1.604407   | 0.364554   | 21:32 |\n| 1     | 1.804160   | 1.384419   | 0.342921   | 21:39 |\n| 2     | 1.620802   | 1.324999   | 0.334158   | 21:28 |\n| 3     | 1.583603   | 1.313850   | 0.331733   | 21:29 |\n\n``` python\nlearn_crop.export('Lecture6_Part2_Food_Convnext_Tiny_Crop.pkl')\n```\n\n### Padding\n\nIt keeps all the original images without transforming them, unlike squish & crop, which change size of the images.\n\n``` python\nlearn_padding = train(arch, item=Resize((192), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n      batch=aug_transforms(size=(128), min_scale=0.75))\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.619984   | 1.938507   | 0.432228   | 17:25 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.151396   | 1.702708   | 0.392723   | 21:27 |\n| 1     | 1.879488   | 1.477281   | 0.369158   | 21:37 |\n| 2     | 1.783989   | 1.412986   | 0.354554   | 21:28 |\n| 3     | 1.738043   | 1.404341   | 0.354356   | 21:25 |\n\n``` python\nlearn_padding.export('Lecture6_Part2_Food_Convnext_Tiny_Padding.pkl')\n```\n\n##### Best among these three is Padding method. Let's obtain it's learning rate & see if that needs to be changed.\n\n``` python\nlearn_crop.lr_find(suggest_funcs=(valley, slide))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nSuggestedLRs(valley=4.365158383734524e-05, slide=0.019054606556892395)\n```\n\n![](Lecture_6_Road_To_The_Top_Part_2_self_files/Lecture_6_Road_To_The_Top_Part_2_self_22_3.png)\n\nAs far as learning rate is concerned we are good to go.\n\n### Test time augmentation\n\nInstead of making predictions on the original validation image, the model makes predictions on multiple augmented versions of the test image and combines these predictions.\n\nFor more refer : [Test Time Augmentation](https://nbviewer.org/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb#Test-Time-Augmentation).\n\n``` python\ntta_preds,targs = learn_crop.tta(dl=learn_crop.dls.valid)\nerror_rate(tta_preds, targs)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"1\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nTensorBase(0.3120)\n```\n\n## Scaling Up\n\nNow that we have identified the best possible model and data augmentation type, let's scale it up by increasing the image size back to `512` & number of epoch to `6`.\n\nWith more than 5 epochs, we are in danger of overfitting. (`10` is certainly **overfitting** because our model has seen every image 10 times by now).\n\n``` python\nlearn = train(arch,item=Resize(512),batch=aug_transforms(size=(256), min_scale=0.75), epochs=10)\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.119423   | 1.545519   | 0.324604   | 31:25 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 1.857518   | 1.425361   | 0.301139   | 35:32 |\n| 1     | 1.573771   | 1.231033   | 0.280644   | 35:34 |\n| 2     | 1.429572   | 1.093103   | 0.265149   | 35:35 |\n| 3     | 1.246169   | 1.031862   | 0.256931   | 35:35 |\n| 4     | 1.202549   | 1.000573   | 0.249356   | 35:35 |\n| 5     | 1.172318   | 0.974019   | 0.246089   | 35:34 |\n| 6     | 1.095220   | 0.961513   | 0.242673   | 35:36 |\n| 7     | 1.071022   | 0.952826   | 0.242079   | 35:40 |\n| 8     | 1.101088   | 0.950712   | 0.241139   | 35:38 |\n| 9     | 1.096281   | 0.950866   | 0.240545   | 35:35 |\n\nThis is far more accurate than our previous model.\n\n## Conclusion\n\nWe achieved higher accuracy compared to our Part 1 version, but it put too much strain on our GPU. It even crashed at times during the execution of the 'Scale Up!' part. In the next notebook, we will learn how to optimize the GPU for better performance.\n","srcMarkdownNoYaml":"\n\nIn [Lecture6-Part1](https://mekanavsharma.github.io/Blog/posts/FastAI_Course_Lect6_Part1/) we build our model using `resent26d` architecture with best accuracy `73%`. In this notebook we will be using `ConvNeXt` model and aiming towards higher accuracy.\n\n### Install FastAI\n\n``` python\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n```\n\n```         \nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n```\n\n## Let's download food data from FastAI\n\n``` python\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = '/content/food-101/images'\ntest_path = '/content/food-101/test'\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"5686607872\" class max=\"5686607260\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n100.00% \\[5686607872/5686607260 02:31\\<00:00\\]\n\n</div>\n\n## Let's make it faster\n\nLast time, we encountered a problem even though we were using the fastest architecture. It was still taking too long. For a change, let's resize the images to `256` pixels. This will decrease the size of each pixel and allow us to train our model faster.\n\n``` python\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n```\n\n![](Lecture_6_Road_To_The_Top_Part_2_self_files/Lecture_6_Road_To_The_Top_Part_2_self_4_0.png)\n\n### Make it into a function\n\nIn this notebook, we will be experimenting with lots of models, data(image) augmentation, and other techniques. So instead of repeating the same code every time, let's create a function that can be called whenever needed.\n\n``` python\ndef train(arch, item, batch, epochs=4, learning_rate=0.0002):\n    dls = ImageDataLoaders.from_folder(path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n    learn = vision_learner(dls, arch, metrics=error_rate)\n    learn.fine_tune(epochs, learning_rate)\n    return learn\n```\n\nTo ensure consistent function behavior, we have rigidly set the number of epochs and the learning rate value.\n\n### Call the function\n\n``` python\nlearn = train('resnet26d', item=Resize(256),batch=aug_transforms(size=128, min_scale=0.75))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 3.727076   | 2.929649   | 0.664554   | 04:58 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 3.250653   | 2.632962   | 0.618911   | 05:03 |\n| 1     | 2.837729   | 2.394110   | 0.584109   | 05:09 |\n| 2     | 2.680722   | 2.286321   | 0.563812   | 05:10 |\n| 3     | 2.653321   | 2.266845   | 0.560149   | 05:08 |\n\nThough we were able to reduce the time but we got higher error rate.\n\n## ConvNeXt model\n\nIn our previous notebook, we discussed how the **convnext_tiny_in22k** is go-to model. We would like to reduce image size to **192**(multiple 32) & use **squish** method for data augmentation.\n\n``` python\narch = 'convnext_tiny_in22k'\n\nlearn_squish = train(arch, item=Resize(192, method='squish'),batch=aug_transforms(size=128, min_scale=0.75))\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.464850   | 1.882828   | 0.412178   | 17:27 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.082745   | 1.638774   | 0.375693   | 21:36 |\n| 1     | 1.828319   | 1.418455   | 0.350842   | 21:36 |\n| 2     | 1.719477   | 1.355143   | 0.342327   | 21:34 |\n| 3     | 1.633262   | 1.351079   | 0.340000   | 21:38 |\n\n## Data Augmentation\n\n### Crop\n\n**Squish** has already been performed in the last scenario, so let's check on crop method, which is default in Fastai.\n\n``` python\nlearn_crop = train(arch, item=Resize(192),batch=aug_transforms(size=128, min_scale=0.75))\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.491307   | 1.843047   | 0.401188   | 17:40 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.034851   | 1.604407   | 0.364554   | 21:32 |\n| 1     | 1.804160   | 1.384419   | 0.342921   | 21:39 |\n| 2     | 1.620802   | 1.324999   | 0.334158   | 21:28 |\n| 3     | 1.583603   | 1.313850   | 0.331733   | 21:29 |\n\n``` python\nlearn_crop.export('Lecture6_Part2_Food_Convnext_Tiny_Crop.pkl')\n```\n\n### Padding\n\nIt keeps all the original images without transforming them, unlike squish & crop, which change size of the images.\n\n``` python\nlearn_padding = train(arch, item=Resize((192), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n      batch=aug_transforms(size=(128), min_scale=0.75))\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.619984   | 1.938507   | 0.432228   | 17:25 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.151396   | 1.702708   | 0.392723   | 21:27 |\n| 1     | 1.879488   | 1.477281   | 0.369158   | 21:37 |\n| 2     | 1.783989   | 1.412986   | 0.354554   | 21:28 |\n| 3     | 1.738043   | 1.404341   | 0.354356   | 21:25 |\n\n``` python\nlearn_padding.export('Lecture6_Part2_Food_Convnext_Tiny_Padding.pkl')\n```\n\n##### Best among these three is Padding method. Let's obtain it's learning rate & see if that needs to be changed.\n\n``` python\nlearn_crop.lr_find(suggest_funcs=(valley, slide))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nSuggestedLRs(valley=4.365158383734524e-05, slide=0.019054606556892395)\n```\n\n![](Lecture_6_Road_To_The_Top_Part_2_self_files/Lecture_6_Road_To_The_Top_Part_2_self_22_3.png)\n\nAs far as learning rate is concerned we are good to go.\n\n### Test time augmentation\n\nInstead of making predictions on the original validation image, the model makes predictions on multiple augmented versions of the test image and combines these predictions.\n\nFor more refer : [Test Time Augmentation](https://nbviewer.org/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb#Test-Time-Augmentation).\n\n``` python\ntta_preds,targs = learn_crop.tta(dl=learn_crop.dls.valid)\nerror_rate(tta_preds, targs)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n<div>\n\n<progress value=\"0\" class max=\"1\" style=\"width:300px; height:20px; vertical-align: middle;\">\n\n</progress>\n\n</div>\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nTensorBase(0.3120)\n```\n\n## Scaling Up\n\nNow that we have identified the best possible model and data augmentation type, let's scale it up by increasing the image size back to `512` & number of epoch to `6`.\n\nWith more than 5 epochs, we are in danger of overfitting. (`10` is certainly **overfitting** because our model has seen every image 10 times by now).\n\n``` python\nlearn = train(arch,item=Resize(512),batch=aug_transforms(size=(256), min_scale=0.75), epochs=10)\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/178M [00:00<?, ?B/s]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 2.119423   | 1.545519   | 0.324604   | 31:25 |\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | error_rate | time  |\n|-------|------------|------------|------------|-------|\n| 0     | 1.857518   | 1.425361   | 0.301139   | 35:32 |\n| 1     | 1.573771   | 1.231033   | 0.280644   | 35:34 |\n| 2     | 1.429572   | 1.093103   | 0.265149   | 35:35 |\n| 3     | 1.246169   | 1.031862   | 0.256931   | 35:35 |\n| 4     | 1.202549   | 1.000573   | 0.249356   | 35:35 |\n| 5     | 1.172318   | 0.974019   | 0.246089   | 35:34 |\n| 6     | 1.095220   | 0.961513   | 0.242673   | 35:36 |\n| 7     | 1.071022   | 0.952826   | 0.242079   | 35:40 |\n| 8     | 1.101088   | 0.950712   | 0.241139   | 35:38 |\n| 9     | 1.096281   | 0.950866   | 0.240545   | 35:35 |\n\nThis is far more accurate than our previous model.\n\n## Conclusion\n\nWe achieved higher accuracy compared to our Part 1 version, but it put too much strain on our GPU. It even crashed at times during the execution of the 'Scale Up!' part. In the next notebook, we will learn how to optimize the GPU for better performance.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":{"light":"flatly","dark":"solar"},"title-block-banner":true,"title":"FastAI Course Lecture 6 Part 2 Notes","author":"Kanav Sharma","date":"2024-05-03","categories":["Computer Vision","FastAI"],"order":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}