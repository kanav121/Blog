{"title":"FastAI Course Lecture 5 Notes","markdown":{"yaml":{"title":"FastAI Course Lecture 5 Notes","author":"Kanav Sharma","date":"2024-04-21","categories":["Tabular Data","FastAI"],"toc":true,"title-block-banner":true,"order":0},"headingText":"Focusing on Computer Vision and Tabular Data","containsRefs":false,"markdown":"\n\n\nMy primary focus is to write on the lessons and techniques related to building and training models for Computer Vision tasks, such as image classification, object detection, and segmentation. Additionally, I'll be exploring the methods and best practices for working with Tabular Data for this lecture only.\n\n### This chapter focuses on Tabular Data\n\n``` python\nfrom fastai.tabular.all import *\nset_seed(42)\n```\n\n### Read & Prepare the data\n\n``` python\ndf = pd.read_csv('../input/titanic/train.csv')\ndf.head(10)\n```\n\n<div>\n\n```{=html}\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n```\n|     | PassengerId | Survived | Pclass | Name                                                | Sex    | Age   | SibSp | Parch | Ticket           | Fare  | Cabin | Embarked |\n|------|------|------|------|------|------|------|------|------|------|------|------|------|\n| 0   | 1           | 0        | 3      | Braund, Mr. Owen Harris                             | male   | 22.00 | 1     | 0     | A/5 21171        | 7.25  | NaN   | S        |\n| 1   | 2           | 1        | 1      | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female | 38.00 | 1     | 0     | PC 17599         | 71.28 | C85   | C        |\n| 2   | 3           | 1        | 3      | Heikkinen, Miss. Laina                              | female | 26.00 | 0     | 0     | STON/O2. 3101282 | 7.92  | NaN   | S        |\n| 3   | 4           | 1        | 1      | Futrelle, Mrs. Jacques Heath (Lily May Peel)        | female | 35.00 | 1     | 0     | 113803           | 53.10 | C123  | S        |\n| 4   | 5           | 0        | 3      | Allen, Mr. William Henry                            | male   | 35.00 | 0     | 0     | 373450           | 8.05  | NaN   | S        |\n| 5   | 6           | 0        | 3      | Moran, Mr. James                                    | male   | NaN   | 0     | 0     | 330877           | 8.46  | NaN   | Q        |\n| 6   | 7           | 0        | 1      | McCarthy, Mr. Timothy J                             | male   | 54.00 | 0     | 0     | 17463            | 51.86 | E46   | S        |\n| 7   | 8           | 0        | 3      | Palsson, Master. Gosta Leonard                      | male   | 2.00  | 3     | 1     | 349909           | 21.07 | NaN   | S        |\n| 8   | 9           | 1        | 3      | Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   | female | 27.00 | 0     | 2     | 347742           | 11.13 | NaN   | S        |\n| 9   | 10          | 1        | 2      | Nasser, Mrs. Nicholas (Adele Achem)                 | female | 14.00 | 1     | 0     | 237736           | 30.07 | NaN   | C        |\n\n</div>\n\n``` python\ndf.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0].unique()\n```\n\n```         \narray(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n       'Jonkheer'], dtype=object)\n```\n\n``` python\ndef add_features(df):\n    df['LogFare'] = np.log1p(df['Fare'])\n    df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))\n    df['Family'] = df.SibSp+df.Parch\n    df['Alone'] = df.Family==0\n    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n    df['Title'] = df.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    df['Title'] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))\n\nadd_features(df)\n```\n\n-   **df\\['LogFare'\\] = np.log1p(df\\['Fare'\\])** It will create a column LogFare with Log() value of Fare column\n-   **df\\['Deck'\\] = df.Cabin.str\\[0\\].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))** It will create a new 'Deck' column based on the first letter of the 'Cabin' column. The mapping is done to categorize cabins into groups (ABC, DE, FG).\n-   **df\\['Family'\\] = df.SibSp+df.Parch** It will create a new column 'Family' which is the sum of the 'SibSp' (number of siblings/spouses) and 'Parch' (number of parents/children) columns.\n-   **df\\['Alone'\\] = df.Family == 0** It will create a column 'Alone' for those who don't have family.\n-   **df\\['TicketFreq'\\] = df.groupby('Ticket')\\['Ticket'\\].transform('count')** Adds a 'TicketFreq' column, representing the frequency of each ticket in the dataset.\n-   **df\\['Title'\\] = df.Name.str.split(', ', expand=True)\\[1\\].str.split('.', expand=True)\\[0\\]** Extracts the title from the 'Name' column (e.g., Mr, Miss, Mrs) and assigns it to a new 'Title' column.\n-   **df\\['Title'\\] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))** Will take into account only these 3 titles anything else will be labelled as \"NAN\".\n\n``` python\n#we can use RandomSplitter to separate out the training and validation sets:\n    \nsplits = RandomSplitter(seed=42)(df)\n```\n\n``` python\ndls = TabularPandas(\n    df, splits=splits,\n    procs = [Categorify, FillMissing, Normalize],\n    cat_names=[\"Sex\",\"Pclass\",\"Embarked\",\"Deck\", \"Title\"],\n    cont_names=['Age', 'SibSp', 'Parch', 'LogFare', 'Alone', 'TicketFreq', 'Family'],\n    y_names=\"Survived\", y_block = CategoryBlock(),\n).dataloaders(path=\".\")\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n  to[n].fillna(self.na_dict[n], inplace=True)\n```\n\n[Tabular Pandas](https://docs.fast.ai/tabular.core.html#tabularpandas){.uri}\n\n-   **splits=splits** Use splits for indices of training and validation sets\n\n-   **procs = \\[Categorify, FillMissing, Normalize\\]** Turn strings into categories, fill missing values in numeric columns with the median, normalise all numeric columns\n\n-   **cat_names** will have all categorical columns\n\n-   **cont_names** will have all continuous columns\n\n-   **y_names** will have dependent variable\n\n-   **y_block()** The dependent variable is categorical (so build a classification model, not a regression model) possible values RegressionBlock(), CategoryBlock(),MultiCategoryBlock()\n\n### Train the model\n\nCall dataloader(dls) in tabular_learner & set size of hidden layer = \\[15,19\\] defualt is \\[200,100\\] layers parameter defines number of neurons in particular neural network.\n\nArchitecure of Shallow Neural network: 1. Input Layer 2. First Hidden Layer (15 in our case) 3. Second Hidden Layer (19 in our case) 4. Output Layer\n\n![](Lecture_5_Tabular_Data_Self_files/NN.PNG)\n\n[Source](https://www.researchgate.net/figure/General-Architecture-for-a-Deep-Neural-Network-with-Two-Hidden-Layers_fig2_353032163)\n\n``` python\nlearn = tabular_learner(dls, metrics=accuracy, layers=[15,19])\n```\n\n### Learning Rate\n\n[New Lr Finder Output](https://forums.fast.ai/t/new-lr-finder-output/89236/3)\n\n*lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))*\n\n**Lr_find(suggest_func= (slide, valley))** is great way to find learning rate for any model. There are multiple ways of do this, and in this case, we are using slide& valley methods. By picking one value among these two values we will get pretty good learning rate value\n\nGenerally it is established that: Valley \\> Slide \\> Steep \\> Minimum. Hence by defualt we use valley & slide to get best of both.\n\n``` python\nlearn.lr_find(suggest_funcs=(slide, valley))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nSuggestedLRs(slide=0.05754399299621582, valley=0.009120108559727669)\n```\n\n![](Lecture_5_Tabular_Data_Self_files/Lecture_5_Tabular_Data_Self_16_3.png)\n\nThe two colored points are both reasonable choices for a learning rate. I'll pick somewhere between the two (0.04) and train for a few epochs:\n\n``` python\nlearn.fit(20, lr=0.04)  # 20 will define no of epoch\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | accuracy | time  |\n|-------|------------|------------|----------|-------|\n| 0     | 0.594998   | 0.572238   | 0.679775 | 00:00 |\n| 1     | 0.515863   | 0.466670   | 0.803371 | 00:00 |\n| 2     | 0.476732   | 0.433698   | 0.825843 | 00:00 |\n| 3     | 0.446953   | 0.415818   | 0.848315 | 00:00 |\n| 4     | 0.434874   | 0.434143   | 0.831461 | 00:00 |\n| 5     | 0.421784   | 0.410992   | 0.820225 | 00:00 |\n| 6     | 0.412457   | 0.430165   | 0.831461 | 00:00 |\n| 7     | 0.407657   | 0.404660   | 0.820225 | 00:00 |\n| 8     | 0.403021   | 0.412289   | 0.825843 | 00:00 |\n| 9     | 0.397732   | 0.416126   | 0.837079 | 00:00 |\n| 10    | 0.394886   | 0.422662   | 0.842697 | 00:00 |\n| 11    | 0.393001   | 0.441775   | 0.814607 | 00:00 |\n| 12    | 0.391272   | 0.431170   | 0.842697 | 00:00 |\n| 13    | 0.388350   | 0.409692   | 0.831461 | 00:00 |\n| 14    | 0.382384   | 0.416130   | 0.837079 | 00:00 |\n| 15    | 0.379093   | 0.426817   | 0.820225 | 00:00 |\n| 16    | 0.374646   | 0.428383   | 0.820225 | 00:00 |\n| 17    | 0.375685   | 0.453301   | 0.808989 | 00:00 |\n| 18    | 0.376625   | 0.411430   | 0.820225 | 00:00 |\n| 19    | 0.374332   | 0.463273   | 0.825843 | 00:00 |\n\n### Submit to Kaggle\n\nTo submit to Kaggle, we'll need to read in the test set, and do the same feature engineering we did for the training set:\n\n``` python\ntst_df = pd.read_csv('../input/titanic/test.csv')\ntst_df['Fare'] = tst_df.Fare.fillna(0)\nadd_features(tst_df)\n```\n\nWe don’t have to worry about pre-processing in our test dataset , we can call **test_dl()**, but we have to take care of NA value in target column if it didn’t existed in training because NA in target column wasn’t pre-processed so our function **test_dl()** do not have it’s recollection.\n\n``` python\ntst_dl = learn.dls.test_dl(tst_df)\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\nto[n].fillna(self.na_dict[n], inplace=True)\n```\n\nNow we can use **get_preds** to get the predictions for the test set:\n\n``` python\npreds,_ = learn.get_preds(dl=tst_dl)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\nLet's get our predictions\n\n``` python\ntst_df['Survived'] = (preds[:,1]>0.6).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df\n```\n\n![](Lecture_5_Tabular_Data_Self_files/Output.PNG)\n\n### Ensembling\n\nWe can create five separate models, each trained from different random starting points, and average them. This is the simplest approach of ensemble model\n\n``` python\ndef ensemble():\n    learn = tabular_learner(dls, metrics=accuracy, layers=[20,18])\n    with learn.no_bar(),learn.no_logging(): learn.fit(12, lr=0.05)\n    return learn.get_preds(dl=tst_dl)[0]\n```\n\nNow we run this five times, and collect the results into a list:\n\n``` python\nlearns = [ensemble() for _ in range(5)]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\nWe stack this predictions together and take their average predictions:\n\n``` python\nens_preds = torch.stack(learns).mean(0)\n```\n\nFinally, use the same code as before to generate a submission file, which we can submit to Kaggle after the notebook is saved and run:\n\n``` python\ntst_df['Survived'] = (ens_preds[:,1]>0.55).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df\n```\n\n![](Lecture_5_Tabular_Data_Self_files/Submit.PNG)\n","srcMarkdownNoYaml":"\n\n#### Focusing on Computer Vision and Tabular Data\n\nMy primary focus is to write on the lessons and techniques related to building and training models for Computer Vision tasks, such as image classification, object detection, and segmentation. Additionally, I'll be exploring the methods and best practices for working with Tabular Data for this lecture only.\n\n### This chapter focuses on Tabular Data\n\n``` python\nfrom fastai.tabular.all import *\nset_seed(42)\n```\n\n### Read & Prepare the data\n\n``` python\ndf = pd.read_csv('../input/titanic/train.csv')\ndf.head(10)\n```\n\n<div>\n\n```{=html}\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n```\n|     | PassengerId | Survived | Pclass | Name                                                | Sex    | Age   | SibSp | Parch | Ticket           | Fare  | Cabin | Embarked |\n|------|------|------|------|------|------|------|------|------|------|------|------|------|\n| 0   | 1           | 0        | 3      | Braund, Mr. Owen Harris                             | male   | 22.00 | 1     | 0     | A/5 21171        | 7.25  | NaN   | S        |\n| 1   | 2           | 1        | 1      | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female | 38.00 | 1     | 0     | PC 17599         | 71.28 | C85   | C        |\n| 2   | 3           | 1        | 3      | Heikkinen, Miss. Laina                              | female | 26.00 | 0     | 0     | STON/O2. 3101282 | 7.92  | NaN   | S        |\n| 3   | 4           | 1        | 1      | Futrelle, Mrs. Jacques Heath (Lily May Peel)        | female | 35.00 | 1     | 0     | 113803           | 53.10 | C123  | S        |\n| 4   | 5           | 0        | 3      | Allen, Mr. William Henry                            | male   | 35.00 | 0     | 0     | 373450           | 8.05  | NaN   | S        |\n| 5   | 6           | 0        | 3      | Moran, Mr. James                                    | male   | NaN   | 0     | 0     | 330877           | 8.46  | NaN   | Q        |\n| 6   | 7           | 0        | 1      | McCarthy, Mr. Timothy J                             | male   | 54.00 | 0     | 0     | 17463            | 51.86 | E46   | S        |\n| 7   | 8           | 0        | 3      | Palsson, Master. Gosta Leonard                      | male   | 2.00  | 3     | 1     | 349909           | 21.07 | NaN   | S        |\n| 8   | 9           | 1        | 3      | Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   | female | 27.00 | 0     | 2     | 347742           | 11.13 | NaN   | S        |\n| 9   | 10          | 1        | 2      | Nasser, Mrs. Nicholas (Adele Achem)                 | female | 14.00 | 1     | 0     | 237736           | 30.07 | NaN   | C        |\n\n</div>\n\n``` python\ndf.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0].unique()\n```\n\n```         \narray(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n       'Jonkheer'], dtype=object)\n```\n\n``` python\ndef add_features(df):\n    df['LogFare'] = np.log1p(df['Fare'])\n    df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))\n    df['Family'] = df.SibSp+df.Parch\n    df['Alone'] = df.Family==0\n    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n    df['Title'] = df.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    df['Title'] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))\n\nadd_features(df)\n```\n\n-   **df\\['LogFare'\\] = np.log1p(df\\['Fare'\\])** It will create a column LogFare with Log() value of Fare column\n-   **df\\['Deck'\\] = df.Cabin.str\\[0\\].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))** It will create a new 'Deck' column based on the first letter of the 'Cabin' column. The mapping is done to categorize cabins into groups (ABC, DE, FG).\n-   **df\\['Family'\\] = df.SibSp+df.Parch** It will create a new column 'Family' which is the sum of the 'SibSp' (number of siblings/spouses) and 'Parch' (number of parents/children) columns.\n-   **df\\['Alone'\\] = df.Family == 0** It will create a column 'Alone' for those who don't have family.\n-   **df\\['TicketFreq'\\] = df.groupby('Ticket')\\['Ticket'\\].transform('count')** Adds a 'TicketFreq' column, representing the frequency of each ticket in the dataset.\n-   **df\\['Title'\\] = df.Name.str.split(', ', expand=True)\\[1\\].str.split('.', expand=True)\\[0\\]** Extracts the title from the 'Name' column (e.g., Mr, Miss, Mrs) and assigns it to a new 'Title' column.\n-   **df\\['Title'\\] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))** Will take into account only these 3 titles anything else will be labelled as \"NAN\".\n\n``` python\n#we can use RandomSplitter to separate out the training and validation sets:\n    \nsplits = RandomSplitter(seed=42)(df)\n```\n\n``` python\ndls = TabularPandas(\n    df, splits=splits,\n    procs = [Categorify, FillMissing, Normalize],\n    cat_names=[\"Sex\",\"Pclass\",\"Embarked\",\"Deck\", \"Title\"],\n    cont_names=['Age', 'SibSp', 'Parch', 'LogFare', 'Alone', 'TicketFreq', 'Family'],\n    y_names=\"Survived\", y_block = CategoryBlock(),\n).dataloaders(path=\".\")\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n  to[n].fillna(self.na_dict[n], inplace=True)\n```\n\n[Tabular Pandas](https://docs.fast.ai/tabular.core.html#tabularpandas){.uri}\n\n-   **splits=splits** Use splits for indices of training and validation sets\n\n-   **procs = \\[Categorify, FillMissing, Normalize\\]** Turn strings into categories, fill missing values in numeric columns with the median, normalise all numeric columns\n\n-   **cat_names** will have all categorical columns\n\n-   **cont_names** will have all continuous columns\n\n-   **y_names** will have dependent variable\n\n-   **y_block()** The dependent variable is categorical (so build a classification model, not a regression model) possible values RegressionBlock(), CategoryBlock(),MultiCategoryBlock()\n\n### Train the model\n\nCall dataloader(dls) in tabular_learner & set size of hidden layer = \\[15,19\\] defualt is \\[200,100\\] layers parameter defines number of neurons in particular neural network.\n\nArchitecure of Shallow Neural network: 1. Input Layer 2. First Hidden Layer (15 in our case) 3. Second Hidden Layer (19 in our case) 4. Output Layer\n\n![](Lecture_5_Tabular_Data_Self_files/NN.PNG)\n\n[Source](https://www.researchgate.net/figure/General-Architecture-for-a-Deep-Neural-Network-with-Two-Hidden-Layers_fig2_353032163)\n\n``` python\nlearn = tabular_learner(dls, metrics=accuracy, layers=[15,19])\n```\n\n### Learning Rate\n\n[New Lr Finder Output](https://forums.fast.ai/t/new-lr-finder-output/89236/3)\n\n*lr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))*\n\n**Lr_find(suggest_func= (slide, valley))** is great way to find learning rate for any model. There are multiple ways of do this, and in this case, we are using slide& valley methods. By picking one value among these two values we will get pretty good learning rate value\n\nGenerally it is established that: Valley \\> Slide \\> Steep \\> Minimum. Hence by defualt we use valley & slide to get best of both.\n\n``` python\nlearn.lr_find(suggest_funcs=(slide, valley))\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```         \nSuggestedLRs(slide=0.05754399299621582, valley=0.009120108559727669)\n```\n\n![](Lecture_5_Tabular_Data_Self_files/Lecture_5_Tabular_Data_Self_16_3.png)\n\nThe two colored points are both reasonable choices for a learning rate. I'll pick somewhere between the two (0.04) and train for a few epochs:\n\n``` python\nlearn.fit(20, lr=0.04)  # 20 will define no of epoch\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n| epoch | train_loss | valid_loss | accuracy | time  |\n|-------|------------|------------|----------|-------|\n| 0     | 0.594998   | 0.572238   | 0.679775 | 00:00 |\n| 1     | 0.515863   | 0.466670   | 0.803371 | 00:00 |\n| 2     | 0.476732   | 0.433698   | 0.825843 | 00:00 |\n| 3     | 0.446953   | 0.415818   | 0.848315 | 00:00 |\n| 4     | 0.434874   | 0.434143   | 0.831461 | 00:00 |\n| 5     | 0.421784   | 0.410992   | 0.820225 | 00:00 |\n| 6     | 0.412457   | 0.430165   | 0.831461 | 00:00 |\n| 7     | 0.407657   | 0.404660   | 0.820225 | 00:00 |\n| 8     | 0.403021   | 0.412289   | 0.825843 | 00:00 |\n| 9     | 0.397732   | 0.416126   | 0.837079 | 00:00 |\n| 10    | 0.394886   | 0.422662   | 0.842697 | 00:00 |\n| 11    | 0.393001   | 0.441775   | 0.814607 | 00:00 |\n| 12    | 0.391272   | 0.431170   | 0.842697 | 00:00 |\n| 13    | 0.388350   | 0.409692   | 0.831461 | 00:00 |\n| 14    | 0.382384   | 0.416130   | 0.837079 | 00:00 |\n| 15    | 0.379093   | 0.426817   | 0.820225 | 00:00 |\n| 16    | 0.374646   | 0.428383   | 0.820225 | 00:00 |\n| 17    | 0.375685   | 0.453301   | 0.808989 | 00:00 |\n| 18    | 0.376625   | 0.411430   | 0.820225 | 00:00 |\n| 19    | 0.374332   | 0.463273   | 0.825843 | 00:00 |\n\n### Submit to Kaggle\n\nTo submit to Kaggle, we'll need to read in the test set, and do the same feature engineering we did for the training set:\n\n``` python\ntst_df = pd.read_csv('../input/titanic/test.csv')\ntst_df['Fare'] = tst_df.Fare.fillna(0)\nadd_features(tst_df)\n```\n\nWe don’t have to worry about pre-processing in our test dataset , we can call **test_dl()**, but we have to take care of NA value in target column if it didn’t existed in training because NA in target column wasn’t pre-processed so our function **test_dl()** do not have it’s recollection.\n\n``` python\ntst_dl = learn.dls.test_dl(tst_df)\n```\n\n```         \n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\nto[n].fillna(self.na_dict[n], inplace=True)\n```\n\nNow we can use **get_preds** to get the predictions for the test set:\n\n``` python\npreds,_ = learn.get_preds(dl=tst_dl)\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\nLet's get our predictions\n\n``` python\ntst_df['Survived'] = (preds[:,1]>0.6).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df\n```\n\n![](Lecture_5_Tabular_Data_Self_files/Output.PNG)\n\n### Ensembling\n\nWe can create five separate models, each trained from different random starting points, and average them. This is the simplest approach of ensemble model\n\n``` python\ndef ensemble():\n    learn = tabular_learner(dls, metrics=accuracy, layers=[20,18])\n    with learn.no_bar(),learn.no_logging(): learn.fit(12, lr=0.05)\n    return learn.get_preds(dl=tst_dl)[0]\n```\n\nNow we run this five times, and collect the results into a list:\n\n``` python\nlearns = [ensemble() for _ in range(5)]\n```\n\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n```{=html}\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\nWe stack this predictions together and take their average predictions:\n\n``` python\nens_preds = torch.stack(learns).mean(0)\n```\n\nFinally, use the same code as before to generate a submission file, which we can submit to Kaggle after the notebook is saved and run:\n\n``` python\ntst_df['Survived'] = (ens_preds[:,1]>0.55).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df\n```\n\n![](Lecture_5_Tabular_Data_Self_files/Submit.PNG)\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":{"light":"flatly","dark":"solar"},"title-block-banner":true,"title":"FastAI Course Lecture 5 Notes","author":"Kanav Sharma","date":"2024-04-21","categories":["Tabular Data","FastAI"],"order":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}