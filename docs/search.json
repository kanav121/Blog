[
  {
    "objectID": "posts/Job-Search/index.html",
    "href": "posts/Job-Search/index.html",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "",
    "text": "Are you tired of feeling stuck in your career? Do you dream of making a significant change but don’t know where to start? As a data scientist specializing in time series modeling and regression-based models using R, I felt exactly the same way. But I’m here to tell you that with the right mindset and a little bit of hard work, anything is possible."
  },
  {
    "objectID": "posts/Job-Search/index.html#introduction-my-career-shift-story-and-how-you-can-do-it-too",
    "href": "posts/Job-Search/index.html#introduction-my-career-shift-story-and-how-you-can-do-it-too",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Introduction: My career shift story and how you can do it too",
    "text": "Introduction: My career shift story and how you can do it too\nI made the decision to shift my career from the energy sector to either health or finance industries, with a goal of securing a job that would offer at least a 120% salary increase from my current position, ideally in the FinTech space. And guess what? I not only achieved that goal but also landed my dream job!\nDon’t settle for a career that doesn’t excite you. Take charge of your future and make the change you’ve been dreaming of. Join me on this journey, and let’s make 2023 the year of success and fulfillment!\nIn this blog post, I’ll share my journey with you and provide valuable insights and tips for how you too can make a career shift and achieve your dream job. From studying Python and machine learning basics to creating resumes and profiles on job portals, I’ll guide you through the entire process. I’ll also share my experience with the roller-coaster of interviews and how I overcame my lack of knowledge in machine learning algorithms."
  },
  {
    "objectID": "posts/Job-Search/index.html#initial-plan-and-challenges",
    "href": "posts/Job-Search/index.html#initial-plan-and-challenges",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Initial plan and challenges",
    "text": "Initial plan and challenges\nBack in September, I had planned to study Python and machine learning basics for a month before creating an online profile. Unfortunately, my motivation dwindled and I spent two months halfheartedly reading articles and making notes out of them. Nonetheless, I eventually created a resume using resources like codebasics and Krish Naik’s videos and established profiles on job portals such as Naukri and LinkedIn. Soon after, I started receiving calls from various organizations, but the interview process was a reality check for me as my understanding of machine learning algorithms was only surface-level."
  },
  {
    "objectID": "posts/Job-Search/index.html#learning-from-failures",
    "href": "posts/Job-Search/index.html#learning-from-failures",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Learning from failures",
    "text": "Learning from failures\nIn November, I learned some valuable lessons through my experiences.I would usually clear first round but would fail in second round one such example was I confidently answered questions related to my resume but was stumped when asked to elaborate on categorical data encoding like difference between label and hot encoding. Similarly, when asked about hypothesis testing, I gave a confused response and said alpha was 0.5 instead of 0.05. Despite making notes on Krish Naik’s Live Statistics playlist, I hadn’t covered these topics sincerely.\nHowever, instead of giving up, I used these experiences as motivation to learn and grow. I went back to my notes, re-studied the topics where I had made mistakes, and updated my notes accordingly. I realized that learning is a continuous process and that we can always improve.\nIn the introduction, it is mentioned that I have specialized in time series data. However, due to the limited availability of data for some clients, I did not have much exposure to seasonal data and had only relied on regression-based models for time series analysis. Although I had previously attempted to use models such as Prophet and ARIMA, they did not yield favorable results, and I had not included them in my resume nor prepared them for the interviews. Unfortunately, during a technical interview(3rd technical round), I was asked about ACF, PACF, and the ADF test, and I was unable to answer these questions. To address this knowledge gap, I dedicated the next few weeks to learning the basics of time series terminology and models.\n\nGaining confidence\nDespite a dry spell in December where I didn’t receive any recruiter calls, I didn’t lose hope. Instead, I gained the confidence needed to crack technical interviews. I made sure to prepare well, studying topics in which I was lacking."
  },
  {
    "objectID": "posts/Job-Search/index.html#silver-lining",
    "href": "posts/Job-Search/index.html#silver-lining",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Silver Lining",
    "text": "Silver Lining\nLong story short in January, I had received two offers with a 50% salary increase, but they were not in the FinTech industry, which was my goal. I was satisfied but not happy. Then, I cleared the first round of interviews for two companies, X and Y, on the same day while having a high fever (I’m not blowing my own trumpet, I mentioned this to make the point that if you work hard you will gain confidence eventually). One of the interviewers suggested I should reschedule, but I declined as I did not want to tarnish my reputation."
  },
  {
    "objectID": "posts/Job-Search/index.html#alls-well-that-ends-well",
    "href": "posts/Job-Search/index.html#alls-well-that-ends-well",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "All’s Well that Ends Well",
    "text": "All’s Well that Ends Well\nIn February, I received an offer letter from company X with a 95% salary increase. During my last round of interviews with company Y, I showed them this offer, and they offered me a 150% salary increase, which was a dream come true. I deleted my profile from Naukri and this company Y happened to be TransUnion, a FinTech company where I joined as a Senior Analyst."
  },
  {
    "objectID": "posts/Job-Search/index.html#the-reality-of-recruitment-process",
    "href": "posts/Job-Search/index.html#the-reality-of-recruitment-process",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "The Reality of Recruitment Process",
    "text": "The Reality of Recruitment Process\nI realized early on that the recruitment process is not always straightforward. I cleared the first round in one organization, only to be informed weeks later that they had filled the position internally. In two other organizations, after clearing the first round, I was later told that openings were closed. In another organization, I cleared three rounds and even submitted my documents, only to be told later that I was the second priority and the position was filled via referral. However, I didn’t let these setbacks discourage me, and I continued to persevere."
  },
  {
    "objectID": "posts/Job-Search/index.html#the-journey-continues",
    "href": "posts/Job-Search/index.html#the-journey-continues",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "The Journey Continues",
    "text": "The Journey Continues\nI learned that mistakes are an integral part of the learning process. Even though I had an offer from TransUnion I gave another interview (just of fun). The interview taught me about SARIMAX (we can use this for multivariate time series) and I knew only about ARIMA,SARIMA etc. which are univariate models. It was a humbling experience, but it taught me a valuable lesson that ‘You may think you know but actually you don’t’."
  },
  {
    "objectID": "posts/Job-Search/index.html#insights",
    "href": "posts/Job-Search/index.html#insights",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Insights",
    "text": "Insights\n1. Set a clear and measurable goal for yourself.\n2. I found that building a strong online profile is essential when looking for job opportunities even before you started preparing because it take time to get a call.\n3. Make your resume plain and simple. Tailor your resume and cover letter to each position. Highlight your relevant skills and experience and show how you can add value to the company.\n4. Prepare for interviews by researching the company and practicing your responses to common interview questions. Dress professionally and arrive on time.\n5. It’s better to have a deep understanding of a few machine learning algorithms rather than a superficial understanding of many.\n6. Interviews can be nerve-wracking, but it’s essential to remain calm and not let anxiety take over.\n7. Keep your notes updated and review them regularly\n8. Follow up after interviews with a thank-you email or note, and express your continued interest in the position and also ask for the feed back(very important).\n9. There is no such thing called as perfect interview, you can’t answer 100% of the questions.\n10. Don’t be afraid to negotiate job offers. Do your research on salary ranges for the position and make a counter offer if necessary. This is the most important tip I can give you, as it can make a huge difference in your income and satisfaction."
  },
  {
    "objectID": "posts/Job-Search/index.html#study-sources",
    "href": "posts/Job-Search/index.html#study-sources",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Study Sources",
    "text": "Study Sources\nI found the book “Approaching Almost Any Machine Learning Problem” by Abhishek Thakur to be an excellent resource for building a strong foundation in machine learning.\nI also relied heavily on online resources like Statquest and Krish Naik’s videos, as well as blogs on various websites like Medium, Towards Data Science, and Analytics Vidhya, like for Decision tree I think KDnuggets have one of the finest blog on it.\nMachine Learning Interviews Book by Chip Huyen was another source from where I learned non technical (like how to negotiate salary) & technical aspect of interview."
  },
  {
    "objectID": "posts/Job-Search/index.html#conclusion",
    "href": "posts/Job-Search/index.html#conclusion",
    "title": "How I got multiple offers and Landed My Dream Job in Fintech",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, my journey to landing a Senior Analyst role in a FinTech company was not easy, but it taught me valuable lessons about perseverance, learning from mistakes, and the importance of building a strong online profile. I hope my journey can inspire others to pursue their dreams and never give up, no matter how challenging the journey may be.\nHope that’s the key, be willing to work hard ‘you will get success may not be today but tomorrow you surely will’."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "FastAI Course Lecture 6 Part 3 Notes\n\n\n\nComputer Vision\n\n\nFastAI\n\n\n\n\n\n\n\nKanav Sharma\n\n\nMay 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFastAI Course Lecture 6 Part 2 Notes\n\n\n\nComputer Vision\n\n\nFastAI\n\n\n\n\n\n\n\nKanav Sharma\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFastAI Course Lecture 6 Part 1 Notes\n\n\n\nComputer Vision\n\n\nFastAI\n\n\n\n\n\n\n\nKanav Sharma\n\n\nApr 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFastAI Course Lecture 5 Notes\n\n\n\nTabular Data\n\n\nFastAI\n\n\n\n\n\n\n\nKanav Sharma\n\n\nApr 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFastAI Course Lecture 3 Notes\n\n\n\nComputer Vision\n\n\nFastAI\n\n\n\n\n\n\n\nKanav Sharma\n\n\nApr 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFastAI Course Lecture 2 Notes\n\n\n\nComputer Vision\n\n\nFastAI\n\n\n\n\n\n\n\nKanav Sharma\n\n\nApr 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow I got multiple offers and Landed My Dream Job in Fintech\n\n\n\nInformative\n\n\nInterview\n\n\n\nA blog regarding how I got what I wanted\n\n\n\nKanav Sharma\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my digital space! I’m a data scientist in FinTech venturing into the exciting world of Deep Learning. Over the coming months, I’ll share my data science projects and learnings here as I delve deeper into AI and its boundless potential.\nWhether you’re a fellow data enthusiast, an AI aficionado, or simply curious, join me on this captivating journey. Get ready to explore the magic of data, algorithms, and the frontier of Deep Learning. Let’s unravel mysteries and unlock new frontiers together! I’m always eager to learn, so if you’d like to provide feedback, guidance, or engage in discussion on any topic or project, feel free to reach out to me at kanav608@gmail.com."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nSGVU, Jaipur | 2015-2019\nBtech - CSE | 7.96 CGPA"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nTransunion | Senior Analyst | March 2023 - Present\nKreate Energy Pvt Ltd | Junior Associate | Feb 2020 - March 2023\nRoboMq Pvt Ltd | Data Scientist | January 2019 - January 2020"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html",
    "href": "posts/FastAI_Course_Lect2/index.html",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "Let’s install all required packages\n#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m719.8/719.8 kB[0m [31m7.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m510.5/510.5 kB[0m [31m10.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m116.3/116.3 kB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m194.1/194.1 kB[0m [31m9.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.8/134.8 kB[0m [31m15.4 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m16.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m23.7/23.7 MB[0m [31m15.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m823.6/823.6 kB[0m [31m26.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m14.1/14.1 MB[0m [31m53.7 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m731.7/731.7 MB[0m [31m901.8 kB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m410.6/410.6 MB[0m [31m2.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m121.6/121.6 MB[0m [31m8.2 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m56.5/56.5 MB[0m [31m12.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m124.2/124.2 MB[0m [31m8.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m196.0/196.0 MB[0m [31m2.3 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m166.0/166.0 MB[0m [31m7.2 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m99.1/99.1 kB[0m [31m15.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m21.1/21.1 MB[0m [31m68.6 MB/s[0m eta [36m0:00:00[0m\n[?25hMounted at /content/gdrive\n\n\nExtract Data using DuckDuckGo function\n\nCreate dynamic path according to their name store file\nCreate a dictionary to track the number of downloaded images per category (e.g., cat).\n\n??search_images_ddg\nSignature: search_images_ddg(term, max_images=200)\ncat_types = 'Leopard','Cougar','Tiger','Lion','Cheetah','SnowLeopard'\npath = Path('CAT')\n\n#remove folder with file in it\nimport shutil\nif path.exists():\n  shutil.rmtree(path)\n\nper_cat_count = {}\n\nif not path.exists():\n    path.mkdir()\n    for o in cat_types:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True)\n        results = search_images_ddg(f'{o}')\n        download_images(dest, urls=results)\n        per_cat_count[f'{o}'] = len(results)\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nCount of Images per category\nper_cat_count\n{'Leopard': 200,\n 'Cougar': 200,\n 'Tiger': 200,\n 'Lion': 200,\n 'Cheetah': 200,\n 'SnowLeopard': 200}\nSo we got 200 images per type\nWhile downloading we can get corrupt images.So lets first remove them. verify_images() will return path of such images and using unlink we can remove these files.\nfns = get_image_files(path)\ntotal_imagelength = len(fns)\nfailed = verify_images(fns)\nfailed_imagelength = len(failed)\nfailed\n(#51) [Path('CAT/Lion/d61427d6-f097-4727-a3ba-de31366199d6.jpg'),Path('CAT/Lion/85f17699-5ebe-4e88-9798-14b7e66281d7.png'),Path('CAT/Lion/84589c8d-a1da-45be-9fe6-1f87a34289b3.jpg'),Path('CAT/Lion/cf746926-23d6-4754-b7d0-25779410ee15.jpg'),Path('CAT/SnowLeopard/f3ce804b-5071-4312-8633-9895e721340c.jpg'),Path('CAT/SnowLeopard/961333aa-79da-4dc2-9f56-f4d07697a14e.jpg'),Path('CAT/SnowLeopard/57b3a667-1d3e-47bb-8fff-3e1505a5a12f.jpg'),Path('CAT/SnowLeopard/1b3f2639-1c5d-4e26-86c8-feb4b99bf76a.jpg'),Path('CAT/Cougar/cd7a89c9-8667-4d24-aceb-3a85bb7b247e.jpg'),Path('CAT/Cougar/44b6067c-f159-4d5f-819a-11e7d50a3fd8.jpg')...]\nfailed.map(Path.unlink);\nDict = {\"Total_Image_Count\": total_imagelength, \"Failed_Image_Count\": failed_imagelength}\nDict\n{'Total_Image_Count': 1115, 'Failed_Image_Count': 51}\n\n\n\nCreate a data block and load that data block in data loader.\n\nData Block - Is a blueprint on how to assemble data that we want to send for training.\nData Loader - Is used to pass that data which is in batch format(i.e created using data blocks) to the GPU.\n\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = big_cat.dataloaders(path)\nDataBlock is a convenient way to organize the data loading, splitting, and transformation steps in preparation for training a deep learning model using the fastai library.\nDataBlock(): is suitable for a classification task where you have a dataset of images, and each image belongs to a specific category (e.g., types of cats).\nblocks=(ImageBlock, CategoryBlock): It specify that our inputs are images & our targets are categories(types of big cat)\nget_image_files: This helps to get list of all the images from subfolder.\nparent_label: This is a function that extracts the labels (categories) for each item.’Leapord’,‘Tiger’,‘Lion’\nA DataLoaders includes validation and training DataLoader. Let’s check random validation dataset.\ndls.valid.show_batch(max_n=6, nrows=2)\n\n\n\npng\n\n\nSquishing or Padding for Model Training :\n\nSquishing or padding is applied to images during training.\nCropping may result in data loss, while squishing/stretching can lead to unrealistic shapes, impacting accuracy.\nPadding may introduce excessive empty space, causing wasted computation.\n\nPractical Approach - Data Augmentation: The idea of getting different picture every time from same image is called data augmentation.\n\nRandomly select and crop parts of the image during each epoch.\nTrain the model on different image parts across multiple epochs.\nThis approach creates random variations in input data without altering its meaning.\nAiming to provide diverse perspectives, it ensures that the model sees different pictures from the same image in each iteration..\n\n\nTo train our model, we’ll use RandomResizedCrop with an image size of 224 px, which is fairly standard for image classification, and default aug_transforms:\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\n\n\n\nTip1 - Prioritaize to train a quick and simple model first, rather than going for big model directly.\nTip2 - Build model first and then clean the data. And then again train the model.\nlearn = vision_learner(big_cat_dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.878671\n0.548061\n0.183962\n00:36\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.669399\n0.442041\n0.160377\n00:36\n\n\n1\n0.566393\n0.425440\n0.136792\n00:38\n\n\n2\n0.476826\n0.555463\n0.179245\n00:38\n\n\n3\n0.429597\n0.524273\n0.146226\n00:37\n\n\n4\n0.367606\n0.519690\n0.117925\n00:36\n\n\n5\n0.319734\n0.529199\n0.113208\n00:37\n\n\n6\n0.287094\n0.516044\n0.127358\n00:38\n\n\n7\n0.260760\n0.514551\n0.132075\n00:36\n\n\n\nHere we see, in last epoch rise in error_rate which means that in stochastic gradient descent we have surpassed deepest point and trending towards upward direction which leads to higher loss rate. It indicates that the training process should likely be stopped to prevent further divergence from the optimal solution\n###Visualize Confusion Matrix\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\npng\n\n\nplot_top_losses shows us the images with the highest loss in our dataset.\ninterp.plot_top_losses(4, nrows=1, figsize=(18,4))\n\n\n\n\npng\n\n\n\n\n\nImageClassifierCleaner enables us to review all images associated with a specific category and identify their placement within the dataloader, whether in the training or validation set.\nThe images are organized in ascending order of confidence, prioritizing those with the highest loss. This allows for efficient data sorting by simply examining the initial images. Users can choose to keep, delete, or modify the category label (type of cat) as required\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\nVBox(children=(Dropdown(options=('Cheetah', 'Cougar', 'Leopard', 'Lion', 'SnowLeopard', 'Tiger'), value='Cheet…\nThe Cleaner possesses information regarding the files we deleted and whose labels we modified. Now, we will implement these changes.\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n\n\n\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\nlearn = vision_learner(big_cat_dls, resnet34, metrics=error_rate)\nlearn.fine_tune(8)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 121MB/s]\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.839337\n0.557398\n0.161137\n00:36\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.552628\n0.516515\n0.137441\n00:37\n\n\n1\n0.457381\n0.544474\n0.175355\n00:42\n\n\n2\n0.399777\n0.615449\n0.146919\n00:38\n\n\n3\n0.345620\n0.601597\n0.151659\n00:40\n\n\n4\n0.293677\n0.630620\n0.146919\n00:37\n\n\n5\n0.256501\n0.669779\n0.137441\n00:37\n\n\n6\n0.227690\n0.648144\n0.142180\n00:36\n\n\n7\n0.207254\n0.651927\n0.137441\n00:37\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\npng\n\n\ninterp.plot_top_losses(4, nrows=1, figsize=(17,4))\n\n\n\n\npng\n\n\n\n\n\n\n\n\nlearn.export('Lecture2_Big_Cat_Model.pkl')\n\n\n\nYou can access live model here deployed using Hugging Face & gradio. Wanna know how to do it ? refer Gradio-HuggingFace.\nYou can access repo here"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#download-and-sort-out-the-dataimages.",
    "href": "posts/FastAI_Course_Lect2/index.html#download-and-sort-out-the-dataimages.",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "Extract Data using DuckDuckGo function\n\nCreate dynamic path according to their name store file\nCreate a dictionary to track the number of downloaded images per category (e.g., cat).\n\n??search_images_ddg\nSignature: search_images_ddg(term, max_images=200)\ncat_types = 'Leopard','Cougar','Tiger','Lion','Cheetah','SnowLeopard'\npath = Path('CAT')\n\n#remove folder with file in it\nimport shutil\nif path.exists():\n  shutil.rmtree(path)\n\nper_cat_count = {}\n\nif not path.exists():\n    path.mkdir()\n    for o in cat_types:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True)\n        results = search_images_ddg(f'{o}')\n        download_images(dest, urls=results)\n        per_cat_count[f'{o}'] = len(results)\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nCount of Images per category\nper_cat_count\n{'Leopard': 200,\n 'Cougar': 200,\n 'Tiger': 200,\n 'Lion': 200,\n 'Cheetah': 200,\n 'SnowLeopard': 200}\nSo we got 200 images per type\nWhile downloading we can get corrupt images.So lets first remove them. verify_images() will return path of such images and using unlink we can remove these files.\nfns = get_image_files(path)\ntotal_imagelength = len(fns)\nfailed = verify_images(fns)\nfailed_imagelength = len(failed)\nfailed\n(#51) [Path('CAT/Lion/d61427d6-f097-4727-a3ba-de31366199d6.jpg'),Path('CAT/Lion/85f17699-5ebe-4e88-9798-14b7e66281d7.png'),Path('CAT/Lion/84589c8d-a1da-45be-9fe6-1f87a34289b3.jpg'),Path('CAT/Lion/cf746926-23d6-4754-b7d0-25779410ee15.jpg'),Path('CAT/SnowLeopard/f3ce804b-5071-4312-8633-9895e721340c.jpg'),Path('CAT/SnowLeopard/961333aa-79da-4dc2-9f56-f4d07697a14e.jpg'),Path('CAT/SnowLeopard/57b3a667-1d3e-47bb-8fff-3e1505a5a12f.jpg'),Path('CAT/SnowLeopard/1b3f2639-1c5d-4e26-86c8-feb4b99bf76a.jpg'),Path('CAT/Cougar/cd7a89c9-8667-4d24-aceb-3a85bb7b247e.jpg'),Path('CAT/Cougar/44b6067c-f159-4d5f-819a-11e7d50a3fd8.jpg')...]\nfailed.map(Path.unlink);\nDict = {\"Total_Image_Count\": total_imagelength, \"Failed_Image_Count\": failed_imagelength}\nDict\n{'Total_Image_Count': 1115, 'Failed_Image_Count': 51}"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#prepare-data-for-model-training-data-loaders-data-augmentaion-etc..",
    "href": "posts/FastAI_Course_Lect2/index.html#prepare-data-for-model-training-data-loaders-data-augmentaion-etc..",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "Create a data block and load that data block in data loader.\n\nData Block - Is a blueprint on how to assemble data that we want to send for training.\nData Loader - Is used to pass that data which is in batch format(i.e created using data blocks) to the GPU.\n\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = big_cat.dataloaders(path)\nDataBlock is a convenient way to organize the data loading, splitting, and transformation steps in preparation for training a deep learning model using the fastai library.\nDataBlock(): is suitable for a classification task where you have a dataset of images, and each image belongs to a specific category (e.g., types of cats).\nblocks=(ImageBlock, CategoryBlock): It specify that our inputs are images & our targets are categories(types of big cat)\nget_image_files: This helps to get list of all the images from subfolder.\nparent_label: This is a function that extracts the labels (categories) for each item.’Leapord’,‘Tiger’,‘Lion’\nA DataLoaders includes validation and training DataLoader. Let’s check random validation dataset.\ndls.valid.show_batch(max_n=6, nrows=2)\n\n\n\npng\n\n\nSquishing or Padding for Model Training :\n\nSquishing or padding is applied to images during training.\nCropping may result in data loss, while squishing/stretching can lead to unrealistic shapes, impacting accuracy.\nPadding may introduce excessive empty space, causing wasted computation.\n\nPractical Approach - Data Augmentation: The idea of getting different picture every time from same image is called data augmentation.\n\nRandomly select and crop parts of the image during each epoch.\nTrain the model on different image parts across multiple epochs.\nThis approach creates random variations in input data without altering its meaning.\nAiming to provide diverse perspectives, it ensures that the model sees different pictures from the same image in each iteration..\n\n\nTo train our model, we’ll use RandomResizedCrop with an image size of 224 px, which is fairly standard for image classification, and default aug_transforms:\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n\n\n\npng"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#train-the-model",
    "href": "posts/FastAI_Course_Lect2/index.html#train-the-model",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "Tip1 - Prioritaize to train a quick and simple model first, rather than going for big model directly.\nTip2 - Build model first and then clean the data. And then again train the model.\nlearn = vision_learner(big_cat_dls, resnet18, metrics=error_rate)\nlearn.fine_tune(8)\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.878671\n0.548061\n0.183962\n00:36\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.669399\n0.442041\n0.160377\n00:36\n\n\n1\n0.566393\n0.425440\n0.136792\n00:38\n\n\n2\n0.476826\n0.555463\n0.179245\n00:38\n\n\n3\n0.429597\n0.524273\n0.146226\n00:37\n\n\n4\n0.367606\n0.519690\n0.117925\n00:36\n\n\n5\n0.319734\n0.529199\n0.113208\n00:37\n\n\n6\n0.287094\n0.516044\n0.127358\n00:38\n\n\n7\n0.260760\n0.514551\n0.132075\n00:36\n\n\n\nHere we see, in last epoch rise in error_rate which means that in stochastic gradient descent we have surpassed deepest point and trending towards upward direction which leads to higher loss rate. It indicates that the training process should likely be stopped to prevent further divergence from the optimal solution\n###Visualize Confusion Matrix\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\npng\n\n\nplot_top_losses shows us the images with the highest loss in our dataset.\ninterp.plot_top_losses(4, nrows=1, figsize=(18,4))\n\n\n\n\npng"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#clean-the-data",
    "href": "posts/FastAI_Course_Lect2/index.html#clean-the-data",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "ImageClassifierCleaner enables us to review all images associated with a specific category and identify their placement within the dataloader, whether in the training or validation set.\nThe images are organized in ascending order of confidence, prioritizing those with the highest loss. This allows for efficient data sorting by simply examining the initial images. Users can choose to keep, delete, or modify the category label (type of cat) as required\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\nVBox(children=(Dropdown(options=('Cheetah', 'Cougar', 'Leopard', 'Lion', 'SnowLeopard', 'Tiger'), value='Cheet…\nThe Cleaner possesses information regarding the files we deleted and whose labels we modified. Now, we will implement these changes.\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#re-train-the-model-using-updated-data",
    "href": "posts/FastAI_Course_Lect2/index.html#re-train-the-model-using-updated-data",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "big_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\nlearn = vision_learner(big_cat_dls, resnet34, metrics=error_rate)\nlearn.fine_tune(8)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 121MB/s]\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.839337\n0.557398\n0.161137\n00:36\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.552628\n0.516515\n0.137441\n00:37\n\n\n1\n0.457381\n0.544474\n0.175355\n00:42\n\n\n2\n0.399777\n0.615449\n0.146919\n00:38\n\n\n3\n0.345620\n0.601597\n0.151659\n00:40\n\n\n4\n0.293677\n0.630620\n0.146919\n00:37\n\n\n5\n0.256501\n0.669779\n0.137441\n00:37\n\n\n6\n0.227690\n0.648144\n0.142180\n00:36\n\n\n7\n0.207254\n0.651927\n0.137441\n00:37\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\npng\n\n\ninterp.plot_top_losses(4, nrows=1, figsize=(17,4))\n\n\n\n\npng"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#lets-download-our-model-and-use-it-make-prediction.-in-next-lesson-.",
    "href": "posts/FastAI_Course_Lect2/index.html#lets-download-our-model-and-use-it-make-prediction.-in-next-lesson-.",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "learn.export('Lecture2_Big_Cat_Model.pkl')"
  },
  {
    "objectID": "posts/FastAI_Course_Lect2/index.html#live-model",
    "href": "posts/FastAI_Course_Lect2/index.html#live-model",
    "title": "FastAI Course Lecture 2 Notes",
    "section": "",
    "text": "You can access live model here deployed using Hugging Face & gradio. Wanna know how to do it ? refer Gradio-HuggingFace.\nYou can access repo here"
  },
  {
    "objectID": "posts/FastAI_Course_Lect3/index.html",
    "href": "posts/FastAI_Course_Lect3/index.html",
    "title": "FastAI Course Lecture 3 Notes",
    "section": "",
    "text": "Previously, we obtained our data from the DuckDuckGo API and built our model around that.\nThis time, we will retrieve data from a Kaggle dataset, enhance our model, improve our understanding of different available pre-trained vision architectures in PyTorch using the timm library, and implement another model according to our requirements.\n\n\n\n\nfrom google.colab import files\n\n# Upload the Kaggle API key JSON file\nuploaded = files.upload()\n\n!pip install kaggle\n\n!mkdir -p ~/.kaggle\n!mv kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\nSaving kaggle.json to kaggle.json\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\nRequirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach-&gt;kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify-&gt;kaggle) (1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;kaggle) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;kaggle) (3.6)\n\n\nOpen dataset in Kaggle, click on 3 vertical dots (ellipsis) then click on Copy API comamnd, and we are good to go.\n!kaggle datasets download -d gpiosenka/cats-in-the-wild-image-classification\n\n# Create a folder called \"Big Cat\"\n!mkdir -p Big_Cat\n\n# Unzip the dataset into the \"Big Cat\" folder\n!unzip cats-in-the-wild-image-classification.zip -d Big_Cat\n\n# Remove the zip file\n!rm cats-in-the-wild-image-classification.zip\nDownloading cats-in-the-wild-image-classification.zip to /content\n 96% 118M/123M [00:01&lt;00:00, 57.4MB/s]\n100% 123M/123M [00:01&lt;00:00, 65.0MB/s]\nArchive:  cats-in-the-wild-image-classification.zip\n  inflating: Big_Cat/EfficientNetB0-10-(224 X 224)-100.00.h5  \n  inflating: Big_Cat/MobileNetV3 small-10-(224 X 224)-95.96.h5  \n  inflating: Big_Cat/WILDCATS.CSV    \n  inflating: Big_Cat/test/AFRICAN LEOPARD/1.jpg  \n  inflating: Big_Cat/test/AFRICAN LEOPARD/5.jpg  \n  inflating: Big_Cat/test/CARACAL/1.jpg  \n  inflating: Big_Cat/test/CARACAL/5.jpg  \n  inflating: Big_Cat/test/CHEETAH/1.jpg  \n  inflating: Big_Cat/test/CHEETAH/5.jpg  \n  inflating: Big_Cat/test/CLOUDED LEOPARD/1.jpg  \n  inflating: Big_Cat/test/CLOUDED LEOPARD/5.jpg  \n  inflating: Big_Cat/test/JAGUAR/1.jpg  \n  inflating: Big_Cat/test/JAGUAR/5.jpg  \n  inflating: Big_Cat/test/LIONS/1.jpg  \n  inflating: Big_Cat/test/LIONS/5.jpg  \n  inflating: Big_Cat/test/OCELOT/1.jpg  \n  inflating: Big_Cat/test/OCELOT/5.jpg  \n  inflating: Big_Cat/test/PUMA/1.jpg  \n  inflating: Big_Cat/test/PUMA/5.jpg  \n  inflating: Big_Cat/test/SNOW LEOPARD/1.jpg  \n  inflating: Big_Cat/test/SNOW LEOPARD/5.jpg  \n  inflating: Big_Cat/test/TIGER/1.jpg  \n  inflating: Big_Cat/test/TIGER/5.jpg  \n  inflating: Big_Cat/train/AFRICAN LEOPARD/001.jpg  \n  inflating: Big_Cat/train/AFRICAN LEOPARD/236.jpg  \n  inflating: Big_Cat/train/CARACAL/001.jpg  \n  inflating: Big_Cat/train/CARACAL/236.jpg  \n  inflating: Big_Cat/train/CHEETAH/001.jpg  \n  inflating: Big_Cat/train/CHEETAH/235.jpg  \n  inflating: Big_Cat/train/CLOUDED LEOPARD/001.jpg  \n  inflating: Big_Cat/train/CLOUDED LEOPARD/229.jpg  \n  inflating: Big_Cat/train/JAGUAR/001.jpg  \n  inflating: Big_Cat/train/JAGUAR/238.jpg  \n  inflating: Big_Cat/train/LIONS/001.jpg  \n  inflating: Big_Cat/train/LIONS/228.jpg  \n  inflating: Big_Cat/train/OCELOT/001.jpg  \n  inflating: Big_Cat/train/OCELOT/233.jpg  \n  inflating: Big_Cat/train/PUMA/001.jpg  \n  inflating: Big_Cat/train/PUMA/236.jpg  \n  inflating: Big_Cat/train/SNOW LEOPARD/001.jpg  \n  inflating: Big_Cat/train/SNOW LEOPARD/231.jpg  \n  inflating: Big_Cat/train/TIGER/001.jpg  \n  inflating: Big_Cat/train/TIGER/237.jpg  \n  inflating: Big_Cat/valid/AFRICAN LEOPARD/1.jpg  \n  inflating: Big_Cat/valid/AFRICAN LEOPARD/5.jpg  \n  inflating: Big_Cat/valid/CARACAL/1.jpg\n  inflating: Big_Cat/valid/CARACAL/5.jpg  \n  inflating: Big_Cat/valid/CHEETAH/1.jpg  \n  inflating: Big_Cat/valid/CHEETAH/5.jpg  \n  inflating: Big_Cat/valid/CLOUDED LEOPARD/1.jpg  \n  inflating: Big_Cat/valid/CLOUDED LEOPARD/5.jpg  \n  inflating: Big_Cat/valid/JAGUAR/1.jpg  \n  inflating: Big_Cat/valid/JAGUAR/5.jpg  \n  inflating: Big_Cat/valid/LIONS/1.jpg  \n  inflating: Big_Cat/valid/LIONS/5.jpg  \n  inflating: Big_Cat/valid/OCELOT/1.jpg  \n  inflating: Big_Cat/valid/OCELOT/5.jpg  \n  inflating: Big_Cat/valid/PUMA/1.jpg  \n  inflating: Big_Cat/valid/PUMA/5.jpg  \n  inflating: Big_Cat/valid/SNOW LEOPARD/1.jpg  \n  inflating: Big_Cat/valid/SNOW LEOPARD/5.jpg  \n  inflating: Big_Cat/valid/TIGER/1.jpg  \n  inflating: Big_Cat/valid/TIGER/5.jpg  \n\n\n\nimport os\nimport shutil\n\n# Define the absolute paths of main, train and valid folders\nbig_cat_folder = '/content/Big_Cat/'\ntrain_folder = '/content/Big_Cat/train'\nvalid_folder = '/content/Big_Cat/valid'\n\n# Remove all files with \".h5\" extension\n!find {big_cat_folder} -type f -name '*.h5' -delete\n\n# Create a dictionary to track image counts\nimage_counts = {}\n\n# Get a list of subfolders in the train folder\ntrain_subfolders = [f.path for f in os.scandir(train_folder) if f.is_dir()]\n\n# Get a list of subfolders in the valid folder\nvalid_subfolders = [f.path for f in os.scandir(valid_folder) if f.is_dir()]\n\n# Move images from valid to their corresponding subfolders in train\nfor subfolder in valid_subfolders:\n    class_name = os.path.basename(subfolder)\n    train_subfolder = os.path.join(train_folder, class_name)\n\n    # Create the train subfolder if it doesn't exist\n    if not os.path.exists(train_subfolder):\n        os.makedirs(train_subfolder)\n\n    # Initialize counts in the dictionary\n    image_counts[f\"{class_name}_VALID\"] = len(os.listdir(subfolder))\n\n    # Move images from valid to train subfolder and update counts\n    for file in os.listdir(subfolder):\n        file_path = os.path.join(subfolder, file)\n        dest_path = os.path.join(train_subfolder, file)\n        shutil.move(file_path, dest_path)\n\n\n# Remove the empty valid subfolders\nfor subfolder in valid_subfolders:\n    os.rmdir(subfolder)\n\n# Get count of images in train folder so that we can understand on how much we are training\nfor subfolder in train_subfolders:\n    class_name = os.path.basename(subfolder)\n    image_counts[f\"{class_name}_TRAIN\"] = len(os.listdir(subfolder))\n\nsorted_image_counts = dict(sorted(image_counts.items()))\n\n# Print the sorted image counts dictionary\nprint(\"Sorted Image Counts:\")\nfor key, value in sorted_image_counts.items():\n    print(f\"{key}: {value}\")\nSorted Image Counts:\nAFRICAN LEOPARD_TRAIN: 241\nAFRICAN LEOPARD_VALID: 5\nCARACAL_TRAIN: 241\nCARACAL_VALID: 5\nCHEETAH_TRAIN: 240\nCHEETAH_VALID: 5\nCLOUDED LEOPARD_TRAIN: 234\nCLOUDED LEOPARD_VALID: 5\nJAGUAR_TRAIN: 243\nJAGUAR_VALID: 5\nLIONS_TRAIN: 233\nLIONS_VALID: 5\nOCELOT_TRAIN: 238\nOCELOT_VALID: 5\nPUMA_TRAIN: 241\nPUMA_VALID: 5\nSNOW LEOPARD_TRAIN: 236\nSNOW LEOPARD_VALID: 5\nTIGER_TRAIN: 242\nTIGER_VALID: 5\n\n\n\n#hide\n! [ -e /content ] && pip install -Uqq fastbook\n! pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m719.8/719.8 kB[0m [31m7.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m510.5/510.5 kB[0m [31m11.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m116.3/116.3 kB[0m [31m13.7 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m194.1/194.1 kB[0m [31m2.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.8/134.8 kB[0m [31m12.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m19.3 MB/s[0m eta [36m0:00:00[0m\n[?25hCollecting timm\n  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.2/2.2 MB[0m [31m15.2 MB/s[0m eta [36m0:00:00[0m\n[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (3.13.3)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (2023.6.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (4.66.2)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (4.10.0)\nRequirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (24.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (3.2.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (3.1.3)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch-&gt;timm) (12.4.127)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (1.25.2)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (9.4.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;timm) (2.1.5)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (2.0.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (2024.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;timm) (1.3.0)\nInstalling collected packages: timm\nSuccessfully installed timm-0.9.16\nMounted at /content/gdrive\nverify_images() will return path of images which are corrupt and using unlink we can remove these files.\npath = Path('Big_Cat')\n\nfns = get_image_files(path)\ntotal_imagelength = len(fns)\nfailed = verify_images(fns)\nfailed_imagelength = len(failed)\n\nfailed.map(Path.unlink)\nImage_Count_Dict = {\"Total_Image_Count\": total_imagelength, \"Failed_Image_Count\": failed_imagelength}\nImage_Count_Dict\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n\n\n\n\n{'Total_Image_Count': 2439, 'Failed_Image_Count': 0}\nWe have good chunk of images to be trained on\n\n\n\n\n\n\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = big_cat.dataloaders(path)\n\ndls.valid.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\n\n\n\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\n\n\n\n\nlearn = vision_learner(big_cat_dls, resnet34, metrics=error_rate)\nlearn.fine_tune(5)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 164MB/s]\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n1.837715\n\n\n0.237122\n\n\n0.088296\n\n\n00:13\n\n\n\n\n\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.565063\n\n\n0.141556\n\n\n0.041068\n\n\n00:18\n\n\n\n\n1\n\n\n0.431256\n\n\n0.147855\n\n\n0.051335\n\n\n00:20\n\n\n\n\n2\n\n\n0.337753\n\n\n0.119496\n\n\n0.036961\n\n\n00:17\n\n\n\n\n3\n\n\n0.268090\n\n\n0.115800\n\n\n0.032854\n\n\n00:14\n\n\n\n\n\nunderstand structure of model\nlearn.summary()\n\nSequential (Input shape: 64 x 3 x 224 x 224)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     64 x 64 x 112 x 112 \nConv2d                                    9408       True      \nBatchNorm2d                               128        True      \nReLU                                                           \n____________________________________________________________________________\n                     64 x 64 x 56 x 56   \nMaxPool2d                                                      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \n____________________________________________________________________________\n                     64 x 128 x 28 x 28  \nConv2d                                    73728      True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    8192       True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \n____________________________________________________________________________\n                     64 x 256 x 14 x 14  \nConv2d                                    294912     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    32768      True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \n____________________________________________________________________________\n                     64 x 512 x 7 x 7    \nConv2d                                    1179648    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nConv2d                                    131072     True      \nBatchNorm2d                               1024       True      \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \n____________________________________________________________________________\n                     64 x 512 x 1 x 1    \nAdaptiveAvgPool2d                                              \nAdaptiveMaxPool2d                                              \n____________________________________________________________________________\n                     64 x 1024           \nFlatten                                                        \nBatchNorm1d                               2048       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 512            \nLinear                                    524288     True      \nReLU                                                           \nBatchNorm1d                               1024       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 10             \nLinear                                    5120       True      \n____________________________________________________________________________\n\nTotal params: 21,817,152\nTotal trainable params: 21,817,152\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam at 0x7b5a37dbbeb0&gt;\nLoss function: FlattenedLoss of CrossEntropyLoss()\n\nModel unfrozen\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - Recorder\n  - ProgressCallback\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\npng\n\n\n\n\n\ninterp.plot_top_losses(6, nrows=2, figsize=(18,4))\n\n\n\n\npng\n\n\nWe can observe from both the confusion matrix and visual representation that the model is having difficulty differentiating between the Jaguar and the African Leopard. Even I find it challenging to distinguish between the two. 😵 So, we can let it be.\n\n\n\n\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\nVBox(children=(Dropdown(options=('AFRICAN LEOPARD', 'CARACAL', 'CHEETAH', 'CLOUDED LEOPARD', 'JAGUAR', 'LIONS'…\n\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)\n\n\n\n\n\n\n\n\n\n\nLet’s download Ross’s GitHub repository, which is regularly updated with benchmark data for computer vision architectures. These benchmark are created on Imagenet.\n! git clone --depth 1 https://github.com/rwightman/pytorch-image-models.git\n%cd pytorch-image-models/results\nCloning into 'pytorch-image-models'...\nremote: Enumerating objects: 572, done.[K\nremote: Counting objects: 100% (572/572), done.[K\nremote: Compressing objects: 100% (403/403), done.[K\nremote: Total 572 (delta 222), reused 341 (delta 163), pack-reused 0[K\nReceiving objects: 100% (572/572), 2.59 MiB | 4.87 MiB/s, done.\nResolving deltas: 100% (222/222), done.\n/content/pytorch-image-models/results/pytorch-image-models/results\nimport pandas as pd\n\nBenchmark_Result = pd.read_csv('results-imagenet.csv')\nBenchmark_Result['model_org'] = Benchmark_Result['model']\nBenchmark_Result['model'] = Benchmark_Result['model'].str.split('.').str[0]\nBenchmark_Result.head(5)\n\n\n\n\n\n\n\nmodel\n\n\ntop1\n\n\ntop1_err\n\n\ntop5\n\n\ntop5_err\n\n\nparam_count\n\n\nimg_size\n\n\ncrop_pct\n\n\ninterpolation\n\n\nmodel_org\n\n\n\n\n\n\n0\n\n\neva02_large_patch14_448\n\n\n90.052\n\n\n9.948\n\n\n99.048\n\n\n0.952\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_m38m_ft_in22k_in1k\n\n\n\n\n1\n\n\neva02_large_patch14_448\n\n\n89.970\n\n\n10.030\n\n\n99.012\n\n\n0.988\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_in22k_ft_in22k_in1k\n\n\n\n\n2\n\n\neva_giant_patch14_560\n\n\n89.786\n\n\n10.214\n\n\n98.992\n\n\n1.008\n\n\n1,014.45\n\n\n560\n\n\n1.0\n\n\nbicubic\n\n\neva_giant_patch14_560.m30m_ft_in22k_in1k\n\n\n\n\n3\n\n\neva02_large_patch14_448\n\n\n89.622\n\n\n10.378\n\n\n98.950\n\n\n1.050\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_in22k_ft_in1k\n\n\n\n\n4\n\n\neva02_large_patch14_448\n\n\n89.574\n\n\n10.426\n\n\n98.924\n\n\n1.076\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_m38m_ft_in1k\n\n\n\n\n\nLet’s add a “family” column that will allow us to group architectures into categories with similar characteristics:\ndef get_data(part, col):\n    df = pd.read_csv(f'benchmark-{part}-amp-nhwc-pt111-cu113-rtx3090.csv').merge(Benchmark_Result, on='model')\n    df['secs'] = 1. / df[col]\n    df['family'] = df.model.str.extract('^([a-z]+?(?:v2)?)(?:\\d|_|$)')\n    df = df[~df.model.str.endswith('gn')]\n    df.loc[df.model.str.contains('in22'),'family'] = df.loc[df.model.str.contains('in22'),'family'] + '_in22'\n    df.loc[df.model.str.contains('resnet.*d'),'family'] = df.loc[df.model.str.contains('resnet.*d'),'family'] + 'd'\n    return df[df.family.str.contains('^re[sg]netd?|beit|convnext|levit|efficient|vit|vgg|swin')]\n\nInference_Data = get_data('infer', 'infer_samples_per_sec')\nInference_Data.head(5)\n\n\n\n\n\n\n\nmodel\n\n\ninfer_samples_per_sec\n\n\ninfer_step_time\n\n\ninfer_batch_size\n\n\ninfer_img_size\n\n\nparam_count_x\n\n\ntop1\n\n\ntop1_err\n\n\ntop5\n\n\ntop5_err\n\n\nparam_count_y\n\n\nimg_size\n\n\ncrop_pct\n\n\ninterpolation\n\n\nmodel_org\n\n\nsecs\n\n\nfamily\n\n\n\n\n\n\n12\n\n\nlevit_128s\n\n\n21485.80\n\n\n47.648\n\n\n1024\n\n\n224\n\n\n7.78\n\n\n76.526\n\n\n23.474\n\n\n92.872\n\n\n7.128\n\n\n7.78\n\n\n224\n\n\n0.900\n\n\nbicubic\n\n\nlevit_128s.fb_dist_in1k\n\n\n0.000047\n\n\nlevit\n\n\n\n\n13\n\n\nregnetx_002\n\n\n17821.98\n\n\n57.446\n\n\n1024\n\n\n224\n\n\n2.68\n\n\n68.752\n\n\n31.248\n\n\n88.542\n\n\n11.458\n\n\n2.68\n\n\n224\n\n\n0.875\n\n\nbicubic\n\n\nregnetx_002.pycls_in1k\n\n\n0.000056\n\n\nregnetx\n\n\n\n\n15\n\n\nregnety_002\n\n\n16673.08\n\n\n61.405\n\n\n1024\n\n\n224\n\n\n3.16\n\n\n70.280\n\n\n29.720\n\n\n89.530\n\n\n10.470\n\n\n3.16\n\n\n224\n\n\n0.875\n\n\nbicubic\n\n\nregnety_002.pycls_in1k\n\n\n0.000060\n\n\nregnety\n\n\n\n\n17\n\n\nlevit_128\n\n\n14657.83\n\n\n69.849\n\n\n1024\n\n\n224\n\n\n9.21\n\n\n78.490\n\n\n21.510\n\n\n94.012\n\n\n5.988\n\n\n9.21\n\n\n224\n\n\n0.900\n\n\nbicubic\n\n\nlevit_128.fb_dist_in1k\n\n\n0.000068\n\n\nlevit\n\n\n\n\n18\n\n\nregnetx_004\n\n\n14440.03\n\n\n70.903\n\n\n1024\n\n\n224\n\n\n5.16\n\n\n72.402\n\n\n27.598\n\n\n90.826\n\n\n9.174\n\n\n5.16\n\n\n224\n\n\n0.875\n\n\nbicubic\n\n\nregnetx_004.pycls_in1k\n\n\n0.000069\n\n\nregnetx\n\n\n\n\n\n\n\n\nHere’s the results for inference performance (see the last section for training performance). In this chart:\n\nthe x axis shows how many seconds it takes to process one image (note: it’s a log scale)\nthe y axis is the accuracy on Imagenet\nthe size of each bubble is proportional to the size of images used in testing\nthe color shows what “family” the architecture is from.\n\nHover your mouse over a marker to see details about the model. Double-click in the legend to display just one family. Single-click in the legend to show or hide a family.\nimport plotly.express as px\nw,h = 1000,800\n\ndef show_all(Inference_Data, title, size):\n    return px.scatter(Inference_Data, width=w, height=h, size=Inference_Data[size]**2, title=title,\n        x='secs',  y='top1', log_x=True, color='family', hover_name='model_org', hover_data=[size])\n\nshow_all(Inference_Data, 'Inference', 'infer_img_size')\n\n\n\n\nLet’s create a plot for selected architectures which we would like to use normally\n# Filter data only for convnext, resnet\nkeywords = ['convnext', 'resnet','levit','beit']\n\n# Filter rows based on the exact keywords\nBest_Model_Df = Inference_Data[Inference_Data['family'].isin(keywords)]\n\nshow_all(Best_Model_Df, 'Inference', 'infer_img_size')\n\n\n\n\nLet’s add lines through the points of each family, to help see how they compare – but note that we can see that a linear fit isn’t actually ideal here! It’s just there to help visually see the groups.\nsubs = 'levit|resnetd?|regnetx|vgg|convnext.*|efficientnetv2|beit|swin'\n\ndef show_subs(Inference_Data, title, size):\n    df_subs = Inference_Data[Inference_Data.family.str.fullmatch(subs)]\n    return px.scatter(df_subs, width=w, height=h, size=df_subs[size]**2, title=title,\n        trendline=\"ols\", trendline_options={'log_x':True},\n        x='secs',  y='top1', log_x=True, color='family', hover_name='model_org', hover_data=[size])\nshow_subs(Inference_Data, 'Inference', 'infer_img_size')\n\n\n\n\n\n\n\n\nList of all the basic & tiny version models in Convnext and choose the best.\n[model for model in timm.list_models('convnext*') if 'base' in model or 'tiny' in model]\n['convnext_base',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnextv2_base',\n 'convnextv2_tiny']\nlearn_conv = vision_learner(dls, convnext_base, metrics=error_rate).to_fp16()\nlearn_conv.fine_tune(5)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Base_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Base_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n1.130588\n\n\n0.183650\n\n\n0.045175\n\n\n00:17\n\n\n\n\n\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.306945\n\n\n0.164550\n\n\n0.047228\n\n\n00:20\n\n\n\n\n1\n\n\n0.253462\n\n\n0.118687\n\n\n0.026694\n\n\n00:11\n\n\n\n\n2\n\n\n0.207020\n\n\n0.103058\n\n\n0.024641\n\n\n00:11\n\n\n\n\n3\n\n\n0.175618\n\n\n0.094374\n\n\n0.020534\n\n\n00:11\n\n\n\n\n4\n\n\n0.151438\n\n\n0.092010\n\n\n0.020534\n\n\n00:13\n\n\n\n\n\nCompared to the resnet34 model, which had an error rate of 32%, the convnext_base model demonstrates a significant improvement with an error rate of just 21%\nStructure of the architecture\nlearn_conv.summary()\n\nSequential (Input shape: 64 x 3 x 128 x 128)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     64 x 128 x 32 x 32  \nConv2d                                    6272       True      \nLayerNorm2d                               256        True      \nConv2d                                    6400       True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nPermute                                                        \nLayerNorm                                 256        True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 512  \nLinear                                    66048      True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nLinear                                    65664      True      \n____________________________________________________________________________\n                     64 x 128 x 32 x 32  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    6400       True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nPermute                                                        \nLayerNorm                                 256        True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 512  \nLinear                                    66048      True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nLinear                                    65664      True      \n____________________________________________________________________________\n                     64 x 128 x 32 x 32  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    6400       True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nPermute                                                        \nLayerNorm                                 256        True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 512  \nLinear                                    66048      True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nLinear                                    65664      True      \n____________________________________________________________________________\n                     64 x 128 x 32 x 32  \nPermute                                                        \nStochasticDepth                                                \nLayerNorm2d                               256        True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nConv2d                                    131328     True      \nConv2d                                    12800      True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nPermute                                                        \nLayerNorm                                 512        True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 1024 \nLinear                                    263168     True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nLinear                                    262400     True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    12800      True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nPermute                                                        \nLayerNorm                                 512        True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 1024 \nLinear                                    263168     True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nLinear                                    262400     True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    12800      True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nPermute                                                        \nLayerNorm                                 512        True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 1024 \nLinear                                    263168     True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nLinear                                    262400     True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nPermute                                                        \nStochasticDepth                                                \nLayerNorm2d                               512        True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nConv2d                                    524800     True      \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nLayerNorm2d                               1024       True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nConv2d                                    2098176    True      \nConv2d                                    51200      True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nPermute                                                        \nLayerNorm                                 2048       True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 4096   \nLinear                                    4198400    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nLinear                                    4195328    True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    51200      True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nPermute                                                        \nLayerNorm                                 2048       True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 4096   \nLinear                                    4198400    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nLinear                                    4195328    True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    51200      True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nPermute                                                        \nLayerNorm                                 2048       True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 4096   \nLinear                                    4198400    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nLinear                                    4195328    True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nPermute                                                        \nStochasticDepth                                                \n____________________________________________________________________________\n                     64 x 1024 x 1 x 1   \nAdaptiveAvgPool2d                                              \nAdaptiveMaxPool2d                                              \n____________________________________________________________________________\n                     64 x 2048           \nFlatten                                                        \nBatchNorm1d                               4096       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 512            \nLinear                                    1048576    True      \nReLU                                                           \nBatchNorm1d                               1024       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 10             \nLinear                                    5120       True      \n____________________________________________________________________________\n\nTotal params: 88,605,184\nTotal trainable params: 88,605,184\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam at 0x7b5a37dbbeb0&gt;\nLoss function: FlattenedLoss of CrossEntropyLoss()\n\nModel unfrozen\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - MixedPrecision\n  - Recorder\n  - ProgressCallback\nLet’s downlod the model for future reference\nlearn_conv.export('Big_Cat_Convnext_Model.pkl')\n#learn_conv.export('/content/drive/MyDrive/Colab Notebooks/FastAI Course/Big_Cat_Convnext_Model.pkl')\n\n\n\nLet’s test the model with an image\nfrom fastai.vision.all import *\nimport gradio as gr\nim = PILImage.create('/content/drive/MyDrive/Colab Notebooks/FastAI Course/SnowLeopard.jpg')\nim.thumbnail((224,224))\nim\n\nlearn_conv = load_learner('/content/drive/MyDrive/Colab Notebooks/FastAI Course/Big_Cat_Convnext_Model.pkl')\nlearn_conv.predict(im)\n\n('CHEETAH',\n tensor(2),\n tensor([1.0988e-04, 8.7617e-05, 9.2564e-01, 2.9294e-06, 1.2592e-06, 1.6162e-06,\n         2.6748e-02, 6.5111e-07, 4.7398e-02, 7.3348e-06]))\nlearn_conv.dls.vocab\n['AFRICAN LEOPARD', 'CARACAL', 'CHEETAH', 'CLOUDED LEOPARD', 'JAGUAR', 'LIONS', 'OCELOT', 'PUMA', 'SNOW LEOPARD', 'TIGER']\ncategories = learn_conv.dls.vocab\n\npred, idx, probs = learn_conv.predict(im)\nresult = dict(zip(categories, map(float,probs)))\nresult\n\n{'AFRICAN LEOPARD': 0.00010988322173943743,\n 'CARACAL': 8.761714707361534e-05,\n 'CHEETAH': 0.9256432056427002,\n 'CLOUDED LEOPARD': 2.929433776444057e-06,\n 'JAGUAR': 1.2592141729328432e-06,\n 'LIONS': 1.6162448446266353e-06,\n 'OCELOT': 0.026747871190309525,\n 'PUMA': 6.511066317216319e-07,\n 'SNOW LEOPARD': 0.04739758372306824,\n 'TIGER': 7.334848760365276e-06}\nTop 3 Predicted Cat Names with Highest Probability”\nsorted_result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\ntop_classes = list(sorted_result.keys())[:3]\ntop_classes\n['CHEETAH', 'SNOW LEOPARD', 'OCELOT']\nSo our model predicted CHEETAH with probablity of 93%"
  },
  {
    "objectID": "posts/FastAI_Course_Lect3/index.html#level-1-repeat-last-lesson",
    "href": "posts/FastAI_Course_Lect3/index.html#level-1-repeat-last-lesson",
    "title": "FastAI Course Lecture 3 Notes",
    "section": "",
    "text": "from google.colab import files\n\n# Upload the Kaggle API key JSON file\nuploaded = files.upload()\n\n!pip install kaggle\n\n!mkdir -p ~/.kaggle\n!mv kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\nSaving kaggle.json to kaggle.json\nRequirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\nRequirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach-&gt;kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify-&gt;kaggle) (1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;kaggle) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;kaggle) (3.6)\n\n\nOpen dataset in Kaggle, click on 3 vertical dots (ellipsis) then click on Copy API comamnd, and we are good to go.\n!kaggle datasets download -d gpiosenka/cats-in-the-wild-image-classification\n\n# Create a folder called \"Big Cat\"\n!mkdir -p Big_Cat\n\n# Unzip the dataset into the \"Big Cat\" folder\n!unzip cats-in-the-wild-image-classification.zip -d Big_Cat\n\n# Remove the zip file\n!rm cats-in-the-wild-image-classification.zip\nDownloading cats-in-the-wild-image-classification.zip to /content\n 96% 118M/123M [00:01&lt;00:00, 57.4MB/s]\n100% 123M/123M [00:01&lt;00:00, 65.0MB/s]\nArchive:  cats-in-the-wild-image-classification.zip\n  inflating: Big_Cat/EfficientNetB0-10-(224 X 224)-100.00.h5  \n  inflating: Big_Cat/MobileNetV3 small-10-(224 X 224)-95.96.h5  \n  inflating: Big_Cat/WILDCATS.CSV    \n  inflating: Big_Cat/test/AFRICAN LEOPARD/1.jpg  \n  inflating: Big_Cat/test/AFRICAN LEOPARD/5.jpg  \n  inflating: Big_Cat/test/CARACAL/1.jpg  \n  inflating: Big_Cat/test/CARACAL/5.jpg  \n  inflating: Big_Cat/test/CHEETAH/1.jpg  \n  inflating: Big_Cat/test/CHEETAH/5.jpg  \n  inflating: Big_Cat/test/CLOUDED LEOPARD/1.jpg  \n  inflating: Big_Cat/test/CLOUDED LEOPARD/5.jpg  \n  inflating: Big_Cat/test/JAGUAR/1.jpg  \n  inflating: Big_Cat/test/JAGUAR/5.jpg  \n  inflating: Big_Cat/test/LIONS/1.jpg  \n  inflating: Big_Cat/test/LIONS/5.jpg  \n  inflating: Big_Cat/test/OCELOT/1.jpg  \n  inflating: Big_Cat/test/OCELOT/5.jpg  \n  inflating: Big_Cat/test/PUMA/1.jpg  \n  inflating: Big_Cat/test/PUMA/5.jpg  \n  inflating: Big_Cat/test/SNOW LEOPARD/1.jpg  \n  inflating: Big_Cat/test/SNOW LEOPARD/5.jpg  \n  inflating: Big_Cat/test/TIGER/1.jpg  \n  inflating: Big_Cat/test/TIGER/5.jpg  \n  inflating: Big_Cat/train/AFRICAN LEOPARD/001.jpg  \n  inflating: Big_Cat/train/AFRICAN LEOPARD/236.jpg  \n  inflating: Big_Cat/train/CARACAL/001.jpg  \n  inflating: Big_Cat/train/CARACAL/236.jpg  \n  inflating: Big_Cat/train/CHEETAH/001.jpg  \n  inflating: Big_Cat/train/CHEETAH/235.jpg  \n  inflating: Big_Cat/train/CLOUDED LEOPARD/001.jpg  \n  inflating: Big_Cat/train/CLOUDED LEOPARD/229.jpg  \n  inflating: Big_Cat/train/JAGUAR/001.jpg  \n  inflating: Big_Cat/train/JAGUAR/238.jpg  \n  inflating: Big_Cat/train/LIONS/001.jpg  \n  inflating: Big_Cat/train/LIONS/228.jpg  \n  inflating: Big_Cat/train/OCELOT/001.jpg  \n  inflating: Big_Cat/train/OCELOT/233.jpg  \n  inflating: Big_Cat/train/PUMA/001.jpg  \n  inflating: Big_Cat/train/PUMA/236.jpg  \n  inflating: Big_Cat/train/SNOW LEOPARD/001.jpg  \n  inflating: Big_Cat/train/SNOW LEOPARD/231.jpg  \n  inflating: Big_Cat/train/TIGER/001.jpg  \n  inflating: Big_Cat/train/TIGER/237.jpg  \n  inflating: Big_Cat/valid/AFRICAN LEOPARD/1.jpg  \n  inflating: Big_Cat/valid/AFRICAN LEOPARD/5.jpg  \n  inflating: Big_Cat/valid/CARACAL/1.jpg\n  inflating: Big_Cat/valid/CARACAL/5.jpg  \n  inflating: Big_Cat/valid/CHEETAH/1.jpg  \n  inflating: Big_Cat/valid/CHEETAH/5.jpg  \n  inflating: Big_Cat/valid/CLOUDED LEOPARD/1.jpg  \n  inflating: Big_Cat/valid/CLOUDED LEOPARD/5.jpg  \n  inflating: Big_Cat/valid/JAGUAR/1.jpg  \n  inflating: Big_Cat/valid/JAGUAR/5.jpg  \n  inflating: Big_Cat/valid/LIONS/1.jpg  \n  inflating: Big_Cat/valid/LIONS/5.jpg  \n  inflating: Big_Cat/valid/OCELOT/1.jpg  \n  inflating: Big_Cat/valid/OCELOT/5.jpg  \n  inflating: Big_Cat/valid/PUMA/1.jpg  \n  inflating: Big_Cat/valid/PUMA/5.jpg  \n  inflating: Big_Cat/valid/SNOW LEOPARD/1.jpg  \n  inflating: Big_Cat/valid/SNOW LEOPARD/5.jpg  \n  inflating: Big_Cat/valid/TIGER/1.jpg  \n  inflating: Big_Cat/valid/TIGER/5.jpg  \n\n\n\nimport os\nimport shutil\n\n# Define the absolute paths of main, train and valid folders\nbig_cat_folder = '/content/Big_Cat/'\ntrain_folder = '/content/Big_Cat/train'\nvalid_folder = '/content/Big_Cat/valid'\n\n# Remove all files with \".h5\" extension\n!find {big_cat_folder} -type f -name '*.h5' -delete\n\n# Create a dictionary to track image counts\nimage_counts = {}\n\n# Get a list of subfolders in the train folder\ntrain_subfolders = [f.path for f in os.scandir(train_folder) if f.is_dir()]\n\n# Get a list of subfolders in the valid folder\nvalid_subfolders = [f.path for f in os.scandir(valid_folder) if f.is_dir()]\n\n# Move images from valid to their corresponding subfolders in train\nfor subfolder in valid_subfolders:\n    class_name = os.path.basename(subfolder)\n    train_subfolder = os.path.join(train_folder, class_name)\n\n    # Create the train subfolder if it doesn't exist\n    if not os.path.exists(train_subfolder):\n        os.makedirs(train_subfolder)\n\n    # Initialize counts in the dictionary\n    image_counts[f\"{class_name}_VALID\"] = len(os.listdir(subfolder))\n\n    # Move images from valid to train subfolder and update counts\n    for file in os.listdir(subfolder):\n        file_path = os.path.join(subfolder, file)\n        dest_path = os.path.join(train_subfolder, file)\n        shutil.move(file_path, dest_path)\n\n\n# Remove the empty valid subfolders\nfor subfolder in valid_subfolders:\n    os.rmdir(subfolder)\n\n# Get count of images in train folder so that we can understand on how much we are training\nfor subfolder in train_subfolders:\n    class_name = os.path.basename(subfolder)\n    image_counts[f\"{class_name}_TRAIN\"] = len(os.listdir(subfolder))\n\nsorted_image_counts = dict(sorted(image_counts.items()))\n\n# Print the sorted image counts dictionary\nprint(\"Sorted Image Counts:\")\nfor key, value in sorted_image_counts.items():\n    print(f\"{key}: {value}\")\nSorted Image Counts:\nAFRICAN LEOPARD_TRAIN: 241\nAFRICAN LEOPARD_VALID: 5\nCARACAL_TRAIN: 241\nCARACAL_VALID: 5\nCHEETAH_TRAIN: 240\nCHEETAH_VALID: 5\nCLOUDED LEOPARD_TRAIN: 234\nCLOUDED LEOPARD_VALID: 5\nJAGUAR_TRAIN: 243\nJAGUAR_VALID: 5\nLIONS_TRAIN: 233\nLIONS_VALID: 5\nOCELOT_TRAIN: 238\nOCELOT_VALID: 5\nPUMA_TRAIN: 241\nPUMA_VALID: 5\nSNOW LEOPARD_TRAIN: 236\nSNOW LEOPARD_VALID: 5\nTIGER_TRAIN: 242\nTIGER_VALID: 5\n\n\n\n#hide\n! [ -e /content ] && pip install -Uqq fastbook\n! pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m719.8/719.8 kB[0m [31m7.1 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m510.5/510.5 kB[0m [31m11.6 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m116.3/116.3 kB[0m [31m13.7 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m194.1/194.1 kB[0m [31m2.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m134.8/134.8 kB[0m [31m12.0 MB/s[0m eta [36m0:00:00[0m\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m1.6/1.6 MB[0m [31m19.3 MB/s[0m eta [36m0:00:00[0m\n[?25hCollecting timm\n  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n[2K     [90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m2.2/2.2 MB[0m [31m15.2 MB/s[0m eta [36m0:00:00[0m\n[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (3.13.3)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (2023.6.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (4.66.2)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (4.10.0)\nRequirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub-&gt;timm) (24.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (3.2.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (3.1.3)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;timm) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch-&gt;timm) (12.4.127)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (1.25.2)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-&gt;timm) (9.4.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;timm) (2.1.5)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (2.0.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface_hub-&gt;timm) (2024.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;timm) (1.3.0)\nInstalling collected packages: timm\nSuccessfully installed timm-0.9.16\nMounted at /content/gdrive\nverify_images() will return path of images which are corrupt and using unlink we can remove these files.\npath = Path('Big_Cat')\n\nfns = get_image_files(path)\ntotal_imagelength = len(fns)\nfailed = verify_images(fns)\nfailed_imagelength = len(failed)\n\nfailed.map(Path.unlink)\nImage_Count_Dict = {\"Total_Image_Count\": total_imagelength, \"Failed_Image_Count\": failed_imagelength}\nImage_Count_Dict\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n\n\n\n\n{'Total_Image_Count': 2439, 'Failed_Image_Count': 0}\nWe have good chunk of images to be trained on\n\n\n\n\n\n\nbig_cat = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\ndls = big_cat.dataloaders(path)\n\ndls.valid.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\n\n\n\nbig_cat = big_cat.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\nbig_cat_dls = big_cat.dataloaders(path)\nbig_cat_dls.train.show_batch(max_n=8, nrows=2)\n\n\n\npng\n\n\n\n\n\n\nlearn = vision_learner(big_cat_dls, resnet34, metrics=error_rate)\nlearn.fine_tune(5)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00&lt;00:00, 164MB/s]\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n1.837715\n\n\n0.237122\n\n\n0.088296\n\n\n00:13\n\n\n\n\n\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.565063\n\n\n0.141556\n\n\n0.041068\n\n\n00:18\n\n\n\n\n1\n\n\n0.431256\n\n\n0.147855\n\n\n0.051335\n\n\n00:20\n\n\n\n\n2\n\n\n0.337753\n\n\n0.119496\n\n\n0.036961\n\n\n00:17\n\n\n\n\n3\n\n\n0.268090\n\n\n0.115800\n\n\n0.032854\n\n\n00:14\n\n\n\n\n\nunderstand structure of model\nlearn.summary()\n\nSequential (Input shape: 64 x 3 x 224 x 224)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     64 x 64 x 112 x 112 \nConv2d                                    9408       True      \nBatchNorm2d                               128        True      \nReLU                                                           \n____________________________________________________________________________\n                     64 x 64 x 56 x 56   \nMaxPool2d                                                      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \nReLU                                                           \nConv2d                                    36864      True      \nBatchNorm2d                               128        True      \n____________________________________________________________________________\n                     64 x 128 x 28 x 28  \nConv2d                                    73728      True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    8192       True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \nReLU                                                           \nConv2d                                    147456     True      \nBatchNorm2d                               256        True      \n____________________________________________________________________________\n                     64 x 256 x 14 x 14  \nConv2d                                    294912     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    32768      True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \nReLU                                                           \nConv2d                                    589824     True      \nBatchNorm2d                               512        True      \n____________________________________________________________________________\n                     64 x 512 x 7 x 7    \nConv2d                                    1179648    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nConv2d                                    131072     True      \nBatchNorm2d                               1024       True      \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \nReLU                                                           \nConv2d                                    2359296    True      \nBatchNorm2d                               1024       True      \n____________________________________________________________________________\n                     64 x 512 x 1 x 1    \nAdaptiveAvgPool2d                                              \nAdaptiveMaxPool2d                                              \n____________________________________________________________________________\n                     64 x 1024           \nFlatten                                                        \nBatchNorm1d                               2048       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 512            \nLinear                                    524288     True      \nReLU                                                           \nBatchNorm1d                               1024       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 10             \nLinear                                    5120       True      \n____________________________________________________________________________\n\nTotal params: 21,817,152\nTotal trainable params: 21,817,152\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam at 0x7b5a37dbbeb0&gt;\nLoss function: FlattenedLoss of CrossEntropyLoss()\n\nModel unfrozen\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - Recorder\n  - ProgressCallback\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\npng\n\n\n\n\n\ninterp.plot_top_losses(6, nrows=2, figsize=(18,4))\n\n\n\n\npng\n\n\nWe can observe from both the confusion matrix and visual representation that the model is having difficulty differentiating between the Jaguar and the African Leopard. Even I find it challenging to distinguish between the two. 😵 So, we can let it be.\n\n\n\n\n#hide_output\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\nVBox(children=(Dropdown(options=('AFRICAN LEOPARD', 'CARACAL', 'CHEETAH', 'CLOUDED LEOPARD', 'JAGUAR', 'LIONS'…\n\n\nfor idx in cleaner.delete(): cleaner.fns[idx].unlink()\nfor idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)"
  },
  {
    "objectID": "posts/FastAI_Course_Lect3/index.html#level-2-understand-computer-vision-architectures",
    "href": "posts/FastAI_Course_Lect3/index.html#level-2-understand-computer-vision-architectures",
    "title": "FastAI Course Lecture 3 Notes",
    "section": "",
    "text": "Let’s download Ross’s GitHub repository, which is regularly updated with benchmark data for computer vision architectures. These benchmark are created on Imagenet.\n! git clone --depth 1 https://github.com/rwightman/pytorch-image-models.git\n%cd pytorch-image-models/results\nCloning into 'pytorch-image-models'...\nremote: Enumerating objects: 572, done.[K\nremote: Counting objects: 100% (572/572), done.[K\nremote: Compressing objects: 100% (403/403), done.[K\nremote: Total 572 (delta 222), reused 341 (delta 163), pack-reused 0[K\nReceiving objects: 100% (572/572), 2.59 MiB | 4.87 MiB/s, done.\nResolving deltas: 100% (222/222), done.\n/content/pytorch-image-models/results/pytorch-image-models/results\nimport pandas as pd\n\nBenchmark_Result = pd.read_csv('results-imagenet.csv')\nBenchmark_Result['model_org'] = Benchmark_Result['model']\nBenchmark_Result['model'] = Benchmark_Result['model'].str.split('.').str[0]\nBenchmark_Result.head(5)\n\n\n\n\n\n\n\nmodel\n\n\ntop1\n\n\ntop1_err\n\n\ntop5\n\n\ntop5_err\n\n\nparam_count\n\n\nimg_size\n\n\ncrop_pct\n\n\ninterpolation\n\n\nmodel_org\n\n\n\n\n\n\n0\n\n\neva02_large_patch14_448\n\n\n90.052\n\n\n9.948\n\n\n99.048\n\n\n0.952\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_m38m_ft_in22k_in1k\n\n\n\n\n1\n\n\neva02_large_patch14_448\n\n\n89.970\n\n\n10.030\n\n\n99.012\n\n\n0.988\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_in22k_ft_in22k_in1k\n\n\n\n\n2\n\n\neva_giant_patch14_560\n\n\n89.786\n\n\n10.214\n\n\n98.992\n\n\n1.008\n\n\n1,014.45\n\n\n560\n\n\n1.0\n\n\nbicubic\n\n\neva_giant_patch14_560.m30m_ft_in22k_in1k\n\n\n\n\n3\n\n\neva02_large_patch14_448\n\n\n89.622\n\n\n10.378\n\n\n98.950\n\n\n1.050\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_in22k_ft_in1k\n\n\n\n\n4\n\n\neva02_large_patch14_448\n\n\n89.574\n\n\n10.426\n\n\n98.924\n\n\n1.076\n\n\n305.08\n\n\n448\n\n\n1.0\n\n\nbicubic\n\n\neva02_large_patch14_448.mim_m38m_ft_in1k\n\n\n\n\n\nLet’s add a “family” column that will allow us to group architectures into categories with similar characteristics:\ndef get_data(part, col):\n    df = pd.read_csv(f'benchmark-{part}-amp-nhwc-pt111-cu113-rtx3090.csv').merge(Benchmark_Result, on='model')\n    df['secs'] = 1. / df[col]\n    df['family'] = df.model.str.extract('^([a-z]+?(?:v2)?)(?:\\d|_|$)')\n    df = df[~df.model.str.endswith('gn')]\n    df.loc[df.model.str.contains('in22'),'family'] = df.loc[df.model.str.contains('in22'),'family'] + '_in22'\n    df.loc[df.model.str.contains('resnet.*d'),'family'] = df.loc[df.model.str.contains('resnet.*d'),'family'] + 'd'\n    return df[df.family.str.contains('^re[sg]netd?|beit|convnext|levit|efficient|vit|vgg|swin')]\n\nInference_Data = get_data('infer', 'infer_samples_per_sec')\nInference_Data.head(5)\n\n\n\n\n\n\n\nmodel\n\n\ninfer_samples_per_sec\n\n\ninfer_step_time\n\n\ninfer_batch_size\n\n\ninfer_img_size\n\n\nparam_count_x\n\n\ntop1\n\n\ntop1_err\n\n\ntop5\n\n\ntop5_err\n\n\nparam_count_y\n\n\nimg_size\n\n\ncrop_pct\n\n\ninterpolation\n\n\nmodel_org\n\n\nsecs\n\n\nfamily\n\n\n\n\n\n\n12\n\n\nlevit_128s\n\n\n21485.80\n\n\n47.648\n\n\n1024\n\n\n224\n\n\n7.78\n\n\n76.526\n\n\n23.474\n\n\n92.872\n\n\n7.128\n\n\n7.78\n\n\n224\n\n\n0.900\n\n\nbicubic\n\n\nlevit_128s.fb_dist_in1k\n\n\n0.000047\n\n\nlevit\n\n\n\n\n13\n\n\nregnetx_002\n\n\n17821.98\n\n\n57.446\n\n\n1024\n\n\n224\n\n\n2.68\n\n\n68.752\n\n\n31.248\n\n\n88.542\n\n\n11.458\n\n\n2.68\n\n\n224\n\n\n0.875\n\n\nbicubic\n\n\nregnetx_002.pycls_in1k\n\n\n0.000056\n\n\nregnetx\n\n\n\n\n15\n\n\nregnety_002\n\n\n16673.08\n\n\n61.405\n\n\n1024\n\n\n224\n\n\n3.16\n\n\n70.280\n\n\n29.720\n\n\n89.530\n\n\n10.470\n\n\n3.16\n\n\n224\n\n\n0.875\n\n\nbicubic\n\n\nregnety_002.pycls_in1k\n\n\n0.000060\n\n\nregnety\n\n\n\n\n17\n\n\nlevit_128\n\n\n14657.83\n\n\n69.849\n\n\n1024\n\n\n224\n\n\n9.21\n\n\n78.490\n\n\n21.510\n\n\n94.012\n\n\n5.988\n\n\n9.21\n\n\n224\n\n\n0.900\n\n\nbicubic\n\n\nlevit_128.fb_dist_in1k\n\n\n0.000068\n\n\nlevit\n\n\n\n\n18\n\n\nregnetx_004\n\n\n14440.03\n\n\n70.903\n\n\n1024\n\n\n224\n\n\n5.16\n\n\n72.402\n\n\n27.598\n\n\n90.826\n\n\n9.174\n\n\n5.16\n\n\n224\n\n\n0.875\n\n\nbicubic\n\n\nregnetx_004.pycls_in1k\n\n\n0.000069\n\n\nregnetx\n\n\n\n\n\n\n\n\nHere’s the results for inference performance (see the last section for training performance). In this chart:\n\nthe x axis shows how many seconds it takes to process one image (note: it’s a log scale)\nthe y axis is the accuracy on Imagenet\nthe size of each bubble is proportional to the size of images used in testing\nthe color shows what “family” the architecture is from.\n\nHover your mouse over a marker to see details about the model. Double-click in the legend to display just one family. Single-click in the legend to show or hide a family.\nimport plotly.express as px\nw,h = 1000,800\n\ndef show_all(Inference_Data, title, size):\n    return px.scatter(Inference_Data, width=w, height=h, size=Inference_Data[size]**2, title=title,\n        x='secs',  y='top1', log_x=True, color='family', hover_name='model_org', hover_data=[size])\n\nshow_all(Inference_Data, 'Inference', 'infer_img_size')\n\n\n\n\nLet’s create a plot for selected architectures which we would like to use normally\n# Filter data only for convnext, resnet\nkeywords = ['convnext', 'resnet','levit','beit']\n\n# Filter rows based on the exact keywords\nBest_Model_Df = Inference_Data[Inference_Data['family'].isin(keywords)]\n\nshow_all(Best_Model_Df, 'Inference', 'infer_img_size')\n\n\n\n\nLet’s add lines through the points of each family, to help see how they compare – but note that we can see that a linear fit isn’t actually ideal here! It’s just there to help visually see the groups.\nsubs = 'levit|resnetd?|regnetx|vgg|convnext.*|efficientnetv2|beit|swin'\n\ndef show_subs(Inference_Data, title, size):\n    df_subs = Inference_Data[Inference_Data.family.str.fullmatch(subs)]\n    return px.scatter(df_subs, width=w, height=h, size=df_subs[size]**2, title=title,\n        trendline=\"ols\", trendline_options={'log_x':True},\n        x='secs',  y='top1', log_x=True, color='family', hover_name='model_org', hover_data=[size])\nshow_subs(Inference_Data, 'Inference', 'infer_img_size')"
  },
  {
    "objectID": "posts/FastAI_Course_Lect3/index.html#level-3-build-a-model-using-convnextbasic-or-tiny",
    "href": "posts/FastAI_Course_Lect3/index.html#level-3-build-a-model-using-convnextbasic-or-tiny",
    "title": "FastAI Course Lecture 3 Notes",
    "section": "",
    "text": "List of all the basic & tiny version models in Convnext and choose the best.\n[model for model in timm.list_models('convnext*') if 'base' in model or 'tiny' in model]\n['convnext_base',\n 'convnext_tiny',\n 'convnext_tiny_hnf',\n 'convnextv2_base',\n 'convnextv2_tiny']\nlearn_conv = vision_learner(dls, convnext_base, metrics=error_rate).to_fp16()\nlearn_conv.fine_tune(5)\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Base_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Base_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n1.130588\n\n\n0.183650\n\n\n0.045175\n\n\n00:17\n\n\n\n\n\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\n\n\n\n\n\nepoch\n\n\ntrain_loss\n\n\nvalid_loss\n\n\nerror_rate\n\n\ntime\n\n\n\n\n\n\n0\n\n\n0.306945\n\n\n0.164550\n\n\n0.047228\n\n\n00:20\n\n\n\n\n1\n\n\n0.253462\n\n\n0.118687\n\n\n0.026694\n\n\n00:11\n\n\n\n\n2\n\n\n0.207020\n\n\n0.103058\n\n\n0.024641\n\n\n00:11\n\n\n\n\n3\n\n\n0.175618\n\n\n0.094374\n\n\n0.020534\n\n\n00:11\n\n\n\n\n4\n\n\n0.151438\n\n\n0.092010\n\n\n0.020534\n\n\n00:13\n\n\n\n\n\nCompared to the resnet34 model, which had an error rate of 32%, the convnext_base model demonstrates a significant improvement with an error rate of just 21%\nStructure of the architecture\nlearn_conv.summary()\n\nSequential (Input shape: 64 x 3 x 128 x 128)\n============================================================================\nLayer (type)         Output Shape         Param #    Trainable \n============================================================================\n                     64 x 128 x 32 x 32  \nConv2d                                    6272       True      \nLayerNorm2d                               256        True      \nConv2d                                    6400       True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nPermute                                                        \nLayerNorm                                 256        True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 512  \nLinear                                    66048      True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nLinear                                    65664      True      \n____________________________________________________________________________\n                     64 x 128 x 32 x 32  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    6400       True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nPermute                                                        \nLayerNorm                                 256        True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 512  \nLinear                                    66048      True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nLinear                                    65664      True      \n____________________________________________________________________________\n                     64 x 128 x 32 x 32  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    6400       True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nPermute                                                        \nLayerNorm                                 256        True      \n____________________________________________________________________________\n                     64 x 32 x 32 x 512  \nLinear                                    66048      True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 32 x 32 x 128  \nLinear                                    65664      True      \n____________________________________________________________________________\n                     64 x 128 x 32 x 32  \nPermute                                                        \nStochasticDepth                                                \nLayerNorm2d                               256        True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nConv2d                                    131328     True      \nConv2d                                    12800      True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nPermute                                                        \nLayerNorm                                 512        True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 1024 \nLinear                                    263168     True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nLinear                                    262400     True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    12800      True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nPermute                                                        \nLayerNorm                                 512        True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 1024 \nLinear                                    263168     True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nLinear                                    262400     True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    12800      True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nPermute                                                        \nLayerNorm                                 512        True      \n____________________________________________________________________________\n                     64 x 16 x 16 x 1024 \nLinear                                    263168     True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 16 x 16 x 256  \nLinear                                    262400     True      \n____________________________________________________________________________\n                     64 x 256 x 16 x 16  \nPermute                                                        \nStochasticDepth                                                \nLayerNorm2d                               512        True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nConv2d                                    524800     True      \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    25600      True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nPermute                                                        \nLayerNorm                                 1024       True      \n____________________________________________________________________________\n                     64 x 8 x 8 x 2048   \nLinear                                    1050624    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 8 x 8 x 512    \nLinear                                    1049088    True      \n____________________________________________________________________________\n                     64 x 512 x 8 x 8    \nPermute                                                        \nStochasticDepth                                                \nLayerNorm2d                               1024       True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nConv2d                                    2098176    True      \nConv2d                                    51200      True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nPermute                                                        \nLayerNorm                                 2048       True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 4096   \nLinear                                    4198400    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nLinear                                    4195328    True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    51200      True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nPermute                                                        \nLayerNorm                                 2048       True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 4096   \nLinear                                    4198400    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nLinear                                    4195328    True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nPermute                                                        \nStochasticDepth                                                \nConv2d                                    51200      True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nPermute                                                        \nLayerNorm                                 2048       True      \n____________________________________________________________________________\n                     64 x 4 x 4 x 4096   \nLinear                                    4198400    True      \nGELU                                                           \n____________________________________________________________________________\n                     64 x 4 x 4 x 1024   \nLinear                                    4195328    True      \n____________________________________________________________________________\n                     64 x 1024 x 4 x 4   \nPermute                                                        \nStochasticDepth                                                \n____________________________________________________________________________\n                     64 x 1024 x 1 x 1   \nAdaptiveAvgPool2d                                              \nAdaptiveMaxPool2d                                              \n____________________________________________________________________________\n                     64 x 2048           \nFlatten                                                        \nBatchNorm1d                               4096       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 512            \nLinear                                    1048576    True      \nReLU                                                           \nBatchNorm1d                               1024       True      \nDropout                                                        \n____________________________________________________________________________\n                     64 x 10             \nLinear                                    5120       True      \n____________________________________________________________________________\n\nTotal params: 88,605,184\nTotal trainable params: 88,605,184\nTotal non-trainable params: 0\n\nOptimizer used: &lt;function Adam at 0x7b5a37dbbeb0&gt;\nLoss function: FlattenedLoss of CrossEntropyLoss()\n\nModel unfrozen\n\nCallbacks:\n  - TrainEvalCallback\n  - CastToTensor\n  - MixedPrecision\n  - Recorder\n  - ProgressCallback\nLet’s downlod the model for future reference\nlearn_conv.export('Big_Cat_Convnext_Model.pkl')\n#learn_conv.export('/content/drive/MyDrive/Colab Notebooks/FastAI Course/Big_Cat_Convnext_Model.pkl')"
  },
  {
    "objectID": "posts/FastAI_Course_Lect3/index.html#level-4.-live-model",
    "href": "posts/FastAI_Course_Lect3/index.html#level-4.-live-model",
    "title": "FastAI Course Lecture 3 Notes",
    "section": "",
    "text": "Let’s create a data frame to have info of Big_Cat like there scientific name, Where they are found, there official count, there average life span.\nimport pandas as pd\n\n# Names of Big Cats\nbig_cat_names = learn_conv.dls.vocab\n\n# Sample data for the DataFrame\ndata = {\n    'Big_Cat_Name': big_cat_names,\n    'Scientific Name': [\n        \"Panthera pardus\",\n        \"Caracal caracal\",\n        \"Acinonyx jubatus\",\n        \"Neofelis nebulosa\",\n        \"Panthera onca\",\n        \"Panthera leo\",\n        \"Leopardus pardalis\",\n        \"Puma concolor\",\n        \"Panthera uncia\",\n        \"Panthera tigris\"\n    ],\n    'Where this cat is found normally': [\n        \"Africa and parts of Asia\",\n        \"Africa, Middle East, and parts of Asia\",\n        \"Africa and parts of Iran\",\n        \"Southeast Asia, China, and parts of India\",\n        \"Americas, particularly in rainforests\",\n        \"Africa, particularly in savannas\",\n        \"Americas, from Texas to Argentina\",\n        \"Americas, Canada to South America\",\n        \"Central Asia, Himalayas, and Siberia\",\n        \"Asia, particularly in forests and grasslands\"\n    ],\n    'Official Count': [\n        \"7,100\",\n        \"50,000\",\n        \"7,000\",\n        \"10,000\",\n        \"64,000\",\n        \"20,000\",\n        \"40,000\",\n        \"30,000\",\n        \"4,000\",\n        \"5,574\"\n    ],\n    'Average Life Span': [\n        \"10-12\",\n        \"10-12\",\n        \"10-12\",\n        \"11\",\n        \"12-15\",\n        \"8-16\",\n        \"8-11\",\n        \"8-13\",\n        \"10-13 years\",\n        \"10-15 years\"\n    ]\n}\n\n# Create the DataFrame\ndf_info = pd.DataFrame(data)\n\n# Display the DataFrame\nprint(df_info)\n      Big_Cat_Name     Scientific Name  \\\n0  AFRICAN LEOPARD     Panthera pardus   \n1          CARACAL     Caracal caracal   \n2          CHEETAH    Acinonyx jubatus   \n3  CLOUDED LEOPARD   Neofelis nebulosa   \n4           JAGUAR       Panthera onca   \n5            LIONS        Panthera leo   \n6           OCELOT  Leopardus pardalis   \n7             PUMA       Puma concolor   \n8     SNOW LEOPARD      Panthera uncia   \n9            TIGER     Panthera tigris   \n\n               Where this cat is found normally Official Count  \\\n0                      Africa and parts of Asia          7,100   \n1        Africa, Middle East, and parts of Asia         50,000   \n2                      Africa and parts of Iran          7,000   \n3     Southeast Asia, China, and parts of India         10,000   \n4         Americas, particularly in rainforests         64,000   \n5              Africa, particularly in savannas         20,000   \n6             Americas, from Texas to Argentina         40,000   \n7             Americas, Canada to South America         30,000   \n8          Central Asia, Himalayas, and Siberia          4,000   \n9  Asia, particularly in forests and grasslands          5,574   \n\n  Average Life Span  \n0             10-12  \n1             10-12  \n2             10-12  \n3                11  \n4             12-15  \n5              8-16  \n6              8-11  \n7              8-13  \n8       10-13 years  \n9       10-15 years  \n! pip install gradio\nimport gradio as gr\n\n# Function to fetch additional information from df_info\ndef get_additional_info(cat_name):\n    info_row = df_info[df_info['Big_Cat_Name'] == cat_name].iloc[0]\n    return {\n        'Scientific Name': info_row['Scientific Name'],\n        'Where this cat is found normally': info_row['Where this cat is found normally'],\n        'Official Count': info_row['Official Count']\n    }\ncategories = learn_conv.dls.vocab\n\n# Modified classify_image function\ndef classify_image(img):\n    pred, idx, probs = learn_conv.predict(img)\n    result = dict(zip(categories, map(float,probs)))\n\n    # Sort the result dictionary by probabilities in descending order\n    sorted_result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\n\n    # Extract the top three classes and their probabilities\n    top_classes = list(sorted_result.keys())[:3]\n    top_probabilities = [sorted_result[class_name] for class_name in top_classes]\n\n    # Get additional information for each top class from df_info\n    additional_info = {cat_name: get_additional_info(cat_name) for cat_name in top_classes}\n\n    # Create a string representation of the top predictions along with their probabilities\n    prediction_str = \"\"\n    for cat_name, prob in zip(top_classes, top_probabilities):\n        prediction_str += f\"{cat_name}: {prob:.2%}\\n\"\n        prediction_str += f\"Scientific Name: {additional_info[cat_name]['Scientific Name']}\\n\"\n        prediction_str += f\"Where this cat is found normally: {additional_info[cat_name]['Where this cat is found normally']}\\n\"\n        prediction_str += f\"Official Count: {additional_info[cat_name]['Official Count']}\\n\\n\"\n\n    return prediction_str\n#export\ntitle = \"&lt;div style='font-size: 40px; text-align: center;'&gt;Big Cat Type&lt;/div&gt;\"\ndescription = \"&lt;div style='font-size: 38px;'&gt;Upload a photo of a Big Cat and get to know which breed it is!!&lt;/div&gt;\"\n\nimage = gr.Image()\nlabel = gr.Label()\nexamples = ['/content/drive/MyDrive/Colab Notebooks/FastAI Course/SnowLeopard.jpg']\n#export\nintf = gr.Interface(\n    fn=classify_image,\n    inputs=image, outputs=label,\n    title=title,\n    description=description,\n    examples=examples)\nintf.launch(share=True, debug=True, inline=False)\nColab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\nRunning on public URL: https://050583c79cdad7a9e1.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)"
  },
  {
    "objectID": "posts/FastAI_Course_Lect3/index.html#level-4.-test-the-model",
    "href": "posts/FastAI_Course_Lect3/index.html#level-4.-test-the-model",
    "title": "FastAI Course Lecture 3 Notes",
    "section": "",
    "text": "Let’s test the model with an image\nfrom fastai.vision.all import *\nimport gradio as gr\nim = PILImage.create('/content/drive/MyDrive/Colab Notebooks/FastAI Course/SnowLeopard.jpg')\nim.thumbnail((224,224))\nim\n\nlearn_conv = load_learner('/content/drive/MyDrive/Colab Notebooks/FastAI Course/Big_Cat_Convnext_Model.pkl')\nlearn_conv.predict(im)\n\n('CHEETAH',\n tensor(2),\n tensor([1.0988e-04, 8.7617e-05, 9.2564e-01, 2.9294e-06, 1.2592e-06, 1.6162e-06,\n         2.6748e-02, 6.5111e-07, 4.7398e-02, 7.3348e-06]))\nlearn_conv.dls.vocab\n['AFRICAN LEOPARD', 'CARACAL', 'CHEETAH', 'CLOUDED LEOPARD', 'JAGUAR', 'LIONS', 'OCELOT', 'PUMA', 'SNOW LEOPARD', 'TIGER']\ncategories = learn_conv.dls.vocab\n\npred, idx, probs = learn_conv.predict(im)\nresult = dict(zip(categories, map(float,probs)))\nresult\n\n{'AFRICAN LEOPARD': 0.00010988322173943743,\n 'CARACAL': 8.761714707361534e-05,\n 'CHEETAH': 0.9256432056427002,\n 'CLOUDED LEOPARD': 2.929433776444057e-06,\n 'JAGUAR': 1.2592141729328432e-06,\n 'LIONS': 1.6162448446266353e-06,\n 'OCELOT': 0.026747871190309525,\n 'PUMA': 6.511066317216319e-07,\n 'SNOW LEOPARD': 0.04739758372306824,\n 'TIGER': 7.334848760365276e-06}\nTop 3 Predicted Cat Names with Highest Probability”\nsorted_result = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\ntop_classes = list(sorted_result.keys())[:3]\ntop_classes\n['CHEETAH', 'SNOW LEOPARD', 'OCELOT']\nSo our model predicted CHEETAH with probablity of 93%"
  },
  {
    "objectID": "posts/FastAI_Course_Lect5/index.html",
    "href": "posts/FastAI_Course_Lect5/index.html",
    "title": "FastAI Course Lecture 5 Notes",
    "section": "",
    "text": "Focusing on Computer Vision and Tabular Data\nMy primary focus is to write on the lessons and techniques related to building and training models for Computer Vision tasks, such as image classification, object detection, and segmentation. Additionally, I’ll be exploring the methods and best practices for working with Tabular Data for this lecture only.\n\n\nThis chapter focuses on Tabular Data\nfrom fastai.tabular.all import *\nset_seed(42)\n\n\nRead & Prepare the data\ndf = pd.read_csv('../input/titanic/train.csv')\ndf.head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.00\n1\n0\nA/5 21171\n7.25\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nfemale\n38.00\n1\n0\nPC 17599\n71.28\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.00\n0\n0\nSTON/O2. 3101282\n7.92\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.00\n1\n0\n113803\n53.10\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.00\n0\n0\n373450\n8.05\nNaN\nS\n\n\n5\n6\n0\n3\nMoran, Mr. James\nmale\nNaN\n0\n0\n330877\n8.46\nNaN\nQ\n\n\n6\n7\n0\n1\nMcCarthy, Mr. Timothy J\nmale\n54.00\n0\n0\n17463\n51.86\nE46\nS\n\n\n7\n8\n0\n3\nPalsson, Master. Gosta Leonard\nmale\n2.00\n3\n1\n349909\n21.07\nNaN\nS\n\n\n8\n9\n1\n3\nJohnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)\nfemale\n27.00\n0\n2\n347742\n11.13\nNaN\nS\n\n\n9\n10\n1\n2\nNasser, Mrs. Nicholas (Adele Achem)\nfemale\n14.00\n1\n0\n237736\n30.07\nNaN\nC\n\n\n\n\ndf.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0].unique()\narray(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n       'Jonkheer'], dtype=object)\ndef add_features(df):\n    df['LogFare'] = np.log1p(df['Fare'])\n    df['Deck'] = df.Cabin.str[0].map(dict(A=\"ABC\", B=\"ABC\", C=\"ABC\", D=\"DE\", E=\"DE\", F=\"FG\", G=\"FG\"))\n    df['Family'] = df.SibSp+df.Parch\n    df['Alone'] = df.Family==0\n    df['TicketFreq'] = df.groupby('Ticket')['Ticket'].transform('count')\n    df['Title'] = df.Name.str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n    df['Title'] = df.Title.map(dict(Mr=\"Mr\",Miss=\"Miss\",Mrs=\"Mrs\",Master=\"Master\"))\n\nadd_features(df)\n\ndf[‘LogFare’] = np.log1p(df[‘Fare’]) It will create a column LogFare with Log() value of Fare column\ndf[‘Deck’] = df.Cabin.str[0].map(dict(A=“ABC”, B=“ABC”, C=“ABC”, D=“DE”, E=“DE”, F=“FG”, G=“FG”)) It will create a new ‘Deck’ column based on the first letter of the ‘Cabin’ column. The mapping is done to categorize cabins into groups (ABC, DE, FG).\ndf[‘Family’] = df.SibSp+df.Parch It will create a new column ‘Family’ which is the sum of the ‘SibSp’ (number of siblings/spouses) and ‘Parch’ (number of parents/children) columns.\ndf[‘Alone’] = df.Family == 0 It will create a column ‘Alone’ for those who don’t have family.\ndf[‘TicketFreq’] = df.groupby(‘Ticket’)[‘Ticket’].transform(‘count’) Adds a ‘TicketFreq’ column, representing the frequency of each ticket in the dataset.\ndf[‘Title’] = df.Name.str.split(‘,’, expand=True)[1].str.split(‘.’, expand=True)[0] Extracts the title from the ‘Name’ column (e.g., Mr, Miss, Mrs) and assigns it to a new ‘Title’ column.\ndf[‘Title’] = df.Title.map(dict(Mr=“Mr”,Miss=“Miss”,Mrs=“Mrs”,Master=“Master”)) Will take into account only these 3 titles anything else will be labelled as “NAN”.\n\n#we can use RandomSplitter to separate out the training and validation sets:\n    \nsplits = RandomSplitter(seed=42)(df)\ndls = TabularPandas(\n    df, splits=splits,\n    procs = [Categorify, FillMissing, Normalize],\n    cat_names=[\"Sex\",\"Pclass\",\"Embarked\",\"Deck\", \"Title\"],\n    cont_names=['Age', 'SibSp', 'Parch', 'LogFare', 'Alone', 'TicketFreq', 'Family'],\n    y_names=\"Survived\", y_block = CategoryBlock(),\n).dataloaders(path=\".\")\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n  to[n].fillna(self.na_dict[n], inplace=True)\nTabular Pandas\n\nsplits=splits Use splits for indices of training and validation sets\nprocs = [Categorify, FillMissing, Normalize] Turn strings into categories, fill missing values in numeric columns with the median, normalise all numeric columns\ncat_names will have all categorical columns\ncont_names will have all continuous columns\ny_names will have dependent variable\ny_block() The dependent variable is categorical (so build a classification model, not a regression model) possible values RegressionBlock(), CategoryBlock(),MultiCategoryBlock()\n\n\n\nTrain the model\nCall dataloader(dls) in tabular_learner & set size of hidden layer = [15,19] defualt is [200,100] layers parameter defines number of neurons in particular neural network.\nArchitecure of Shallow Neural network: 1. Input Layer 2. First Hidden Layer (15 in our case) 3. Second Hidden Layer (19 in our case) 4. Output Layer\n\nSource\nlearn = tabular_learner(dls, metrics=accuracy, layers=[15,19])\n\n\nLearning Rate\nNew Lr Finder Output\nlr_min, lr_steep, lr_valley, lr_slide = learn.lr_find(suggest_funcs=(minimum, steep, valley, slide))\nLr_find(suggest_func= (slide, valley)) is great way to find learning rate for any model. There are multiple ways of do this, and in this case, we are using slide& valley methods. By picking one value among these two values we will get pretty good learning rate value\nGenerally it is established that: Valley &gt; Slide &gt; Steep &gt; Minimum. Hence by defualt we use valley & slide to get best of both.\nlearn.lr_find(suggest_funcs=(slide, valley))\n\nSuggestedLRs(slide=0.05754399299621582, valley=0.009120108559727669)\n\nThe two colored points are both reasonable choices for a learning rate. I’ll pick somewhere between the two (0.04) and train for a few epochs:\nlearn.fit(20, lr=0.04)  # 20 will define no of epoch\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.594998\n0.572238\n0.679775\n00:00\n\n\n1\n0.515863\n0.466670\n0.803371\n00:00\n\n\n2\n0.476732\n0.433698\n0.825843\n00:00\n\n\n3\n0.446953\n0.415818\n0.848315\n00:00\n\n\n4\n0.434874\n0.434143\n0.831461\n00:00\n\n\n5\n0.421784\n0.410992\n0.820225\n00:00\n\n\n6\n0.412457\n0.430165\n0.831461\n00:00\n\n\n7\n0.407657\n0.404660\n0.820225\n00:00\n\n\n8\n0.403021\n0.412289\n0.825843\n00:00\n\n\n9\n0.397732\n0.416126\n0.837079\n00:00\n\n\n10\n0.394886\n0.422662\n0.842697\n00:00\n\n\n11\n0.393001\n0.441775\n0.814607\n00:00\n\n\n12\n0.391272\n0.431170\n0.842697\n00:00\n\n\n13\n0.388350\n0.409692\n0.831461\n00:00\n\n\n14\n0.382384\n0.416130\n0.837079\n00:00\n\n\n15\n0.379093\n0.426817\n0.820225\n00:00\n\n\n16\n0.374646\n0.428383\n0.820225\n00:00\n\n\n17\n0.375685\n0.453301\n0.808989\n00:00\n\n\n18\n0.376625\n0.411430\n0.820225\n00:00\n\n\n19\n0.374332\n0.463273\n0.825843\n00:00\n\n\n\n\n\nSubmit to Kaggle\nTo submit to Kaggle, we’ll need to read in the test set, and do the same feature engineering we did for the training set:\ntst_df = pd.read_csv('../input/titanic/test.csv')\ntst_df['Fare'] = tst_df.Fare.fillna(0)\nadd_features(tst_df)\nWe don’t have to worry about pre-processing in our test dataset , we can call test_dl(), but we have to take care of NA value in target column if it didn’t existed in training because NA in target column wasn’t pre-processed so our function test_dl() do not have it’s recollection.\ntst_dl = learn.dls.test_dl(tst_df)\n/opt/conda/lib/python3.10/site-packages/fastai/tabular/core.py:312: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\nto[n].fillna(self.na_dict[n], inplace=True)\nNow we can use get_preds to get the predictions for the test set:\npreds,_ = learn.get_preds(dl=tst_dl)\n\nLet’s get our predictions\ntst_df['Survived'] = (preds[:,1]&gt;0.6).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df\n\n\n\nEnsembling\nWe can create five separate models, each trained from different random starting points, and average them. This is the simplest approach of ensemble model\ndef ensemble():\n    learn = tabular_learner(dls, metrics=accuracy, layers=[20,18])\n    with learn.no_bar(),learn.no_logging(): learn.fit(12, lr=0.05)\n    return learn.get_preds(dl=tst_dl)[0]\nNow we run this five times, and collect the results into a list:\nlearns = [ensemble() for _ in range(5)]\n\n\n\n\n\nWe stack this predictions together and take their average predictions:\nens_preds = torch.stack(learns).mean(0)\nFinally, use the same code as before to generate a submission file, which we can submit to Kaggle after the notebook is saved and run:\ntst_df['Survived'] = (ens_preds[:,1]&gt;0.55).int()\nsub_df = tst_df[['PassengerId','Survived']]\nsub_df"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part1/index.html",
    "href": "posts/FastAI_Course_Lect6_Part1/index.html",
    "title": "FastAI Course Lecture 6 Part 1 Notes",
    "section": "",
    "text": "In previous lecture , we referred to Which Image models are best? to understand computer vision models in general and which among them works best.\nBut this time, we will be deep diving into these models : Best Vision Model for fine-tuning. We have divided our testing in 2 parts :\n\nExisting Images : Our models, such as ConvNext and ResNet, have been trained on a set of 22,000 images from the ImageNet dataset. It is highly probable that our model has already been exposed to commonly encountered categories such as cats, cars, musical instruments, and more during its training.\n\nNew Images : Here we are using Images that most probably are not in ImagNet dataset, like satellite images, medical images etc.\n\nOur key findings :\n\nIn Case 1, both convnext_tiny_in22k and convnext_tiny emerged as go-to models, selected based on their impressive accuracy and efficient training times.\nIn Case 2, models like ViT (Vision Transformer) and Swin demonstrated excellent performance. Their transformer architecture proved beneficial in understanding patterns from the data they were not trained on previously, namely - vit_small_patch32_224, vit_small_patch16_224, swin_base_patch4_window7_224_in22k.\n\nTip - ViT model work only on 224 pixel image, so to train our image data on ViT, images should be of 224*224 pixels.\n\n\n\n\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (3.13.1)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.66.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.9.0)\nRequirement already satisfied: packaging&gt;=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&gt;=20.9-&gt;huggingface_hub-&gt;timm) (3.1.1)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2-&gt;torch-&gt;timm) (2.1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (2024.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy-&gt;torch-&gt;timm) (1.3.0)\n\n\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n\n\n\n100.00% [5686607872/5686607260 01:54&lt;00:00]\n\nPath('/content/food-101')"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part1/index.html#computer-vision-models-understanding",
    "href": "posts/FastAI_Course_Lect6_Part1/index.html#computer-vision-models-understanding",
    "title": "FastAI Course Lecture 6 Part 1 Notes",
    "section": "",
    "text": "In previous lecture , we referred to Which Image models are best? to understand computer vision models in general and which among them works best.\nBut this time, we will be deep diving into these models : Best Vision Model for fine-tuning. We have divided our testing in 2 parts :\n\nExisting Images : Our models, such as ConvNext and ResNet, have been trained on a set of 22,000 images from the ImageNet dataset. It is highly probable that our model has already been exposed to commonly encountered categories such as cats, cars, musical instruments, and more during its training.\n\nNew Images : Here we are using Images that most probably are not in ImagNet dataset, like satellite images, medical images etc.\n\nOur key findings :\n\nIn Case 1, both convnext_tiny_in22k and convnext_tiny emerged as go-to models, selected based on their impressive accuracy and efficient training times.\nIn Case 2, models like ViT (Vision Transformer) and Swin demonstrated excellent performance. Their transformer architecture proved beneficial in understanding patterns from the data they were not trained on previously, namely - vit_small_patch32_224, vit_small_patch16_224, swin_base_patch4_window7_224_in22k.\n\nTip - ViT model work only on 224 pixel image, so to train our image data on ViT, images should be of 224*224 pixels.\n\n\n\n\n#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (3.13.1)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.66.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.9.0)\nRequirement already satisfied: packaging&gt;=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&gt;=20.9-&gt;huggingface_hub-&gt;timm) (3.1.1)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2-&gt;torch-&gt;timm) (2.1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (2024.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy-&gt;torch-&gt;timm) (1.3.0)\n\n\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n\n\n\n100.00% [5686607872/5686607260 01:54&lt;00:00]\n\nPath('/content/food-101')"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part1/index.html#create-test-dataset",
    "href": "posts/FastAI_Course_Lect6_Part1/index.html#create-test-dataset",
    "title": "FastAI Course Lecture 6 Part 1 Notes",
    "section": "1. Create Test Dataset",
    "text": "1. Create Test Dataset\nWe don’t have test dataset, so let’s randomly create a test folder containing 15% of the images from train folder. Our model will not be trained on these images.\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    train_path = Path('/content/food-101/images')\n    test_path = Path('/content/food-101/test')\n    move_images_to_test(train_path, test_path, percentage=0.15)\ndf_train_json = pd.read_json('/content/food-101/train.json')\ndf_train_json.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nchurros\nhot_and_sour_soup\nsamosa\nsashimi\npork_chop\nspring_rolls\npanna_cotta\nbeef_tartare\ngreek_salad\nfoie_gras\ntacos\npad_thai\npoutine\nramen\npulled_pork_sandwich\nbibimbap\nbeignets\napple_pie\ncrab_cakes\nrisotto\npaella\nsteak\nbaby_back_ribs\nmiso_soup\nfrozen_yogurt\nclub_sandwich\ncarrot_cake\nfalafel\nbread_pudding\nchicken_wings\ngnocchi\ncaprese_salad\ncreme_brulee\nescargots\nchocolate_cake\ntiramisu\nspaghetti_bolognese\nmussels\nscallops\nbaklava\nedamame\nmacaroni_and_cheese\npancakes\ngarlic_bread\nbeet_salad\nonion_rings\nred_velvet_cake\ngrilled_salmon\nchicken_curry\ndeviled_eggs\ncaesar_salad\nhummus\nfish_and_chips\nlasagna\npeking_duck\nguacamole\nstrawberry_shortcake\nclam_chowder\ncroque_madame\nfrench_onion_soup\nbeef_carpaccio\nfried_rice\ndonuts\ngyoza\nravioli\nfried_calamari\nspaghetti_carbonara\nfrench_toast\nlobster_bisque\nceviche\nbruschetta\nfrench_fries\nshrimp_and_grits\nfilet_mignon\nhamburger\ndumplings\ntuna_tartare\nsushi\ncheese_plate\neggs_benedict\ncup_cakes\ntakoyaki\nchocolate_mousse\nbreakfast_burrito\nhot_dog\nmacarons\nwaffles\nseaweed_salad\ncannoli\nhuevos_rancheros\npizza\nchicken_quesadilla\npho\nprime_rib\ncheesecake\nice_cream\nomelette\ngrilled_cheese_sandwich\nlobster_roll_sandwich\nnachos\noysters\n\n\n\n\n0\nchurros/1004234\nhot_and_sour_soup/1002782\nsamosa/1008131\nsashimi/1001239\npork_chop/1000802\nspring_rolls/1002160\npanna_cotta/1001332\nbeef_tartare/1000431\ngreek_salad/1007149\nfoie_gras/1004944\ntacos/1002217\npad_thai/1004763\npoutine/1005364\nramen/1002305\npulled_pork_sandwich/1004064\nbibimbap/1002297\nbeignets/1000911\napple_pie/1005649\ncrab_cakes/100038\nrisotto/1004412\npaella/1000388\nsteak/1000205\nbaby_back_ribs/1005293\nmiso_soup/1032814\nfrozen_yogurt/1000735\nclub_sandwich/1017761\ncarrot_cake/1000447\nfalafel/1003181\nbread_pudding/1004499\nchicken_wings/1003533\ngnocchi/100409\ncaprese_salad/1001946\ncreme_brulee/1000711\nescargots/1011707\nchocolate_cake/1001084\ntiramisu/1002946\nspaghetti_bolognese/100127\nmussels/1015628\nscallops/1002727\nbaklava/1006121\nedamame/1000653\nmacaroni_and_cheese/1004059\npancakes/1009131\ngarlic_bread/100478\nbeet_salad/1003501\nonion_rings/1017468\nred_velvet_cake/1012312\ngrilled_salmon/1002334\nchicken_curry/1004867\ndeviled_eggs/1008777\ncaesar_salad/1000016\nhummus/1000314\nfish_and_chips/1001881\nlasagna/1004570\npeking_duck/10055\nguacamole/1005906\nstrawberry_shortcake/1009217\nclam_chowder/1000678\ncroque_madame/1009085\nfrench_onion_soup/1006274\nbeef_carpaccio/1011469\nfried_rice/1004221\ndonuts/100076\ngyoza/1003912\nravioli/1008464\nfried_calamari/100411\nspaghetti_carbonara/1005482\nfrench_toast/100223\nlobster_bisque/1022294\nceviche/1006106\nbruschetta/1003796\nfrench_fries/100148\nshrimp_and_grits/1002860\nfilet_mignon/1001477\nhamburger/100057\ndumplings/1000786\ntuna_tartare/1010528\nsushi/100332\ncheese_plate/100370\neggs_benedict/1000104\ncup_cakes/1005580\ntakoyaki/1002167\nchocolate_mousse/1013482\nbreakfast_burrito/1000351\nhot_dog/1000288\nmacarons/1001193\nwaffles/100242\nseaweed_salad/1007167\ncannoli/1007970\nhuevos_rancheros/100439\npizza/1008104\nchicken_quesadilla/1004279\npho/1005681\nprime_rib/1001089\ncheesecake/1001446\nice_cream/1012277\nomelette/1001719\ngrilled_cheese_sandwich/1003153\nlobster_roll_sandwich/100009\nnachos/100284\noysters/1008124\n\n\n1\nchurros/1013460\nhot_and_sour_soup/1003688\nsamosa/1011601\nsashimi/1001363\npork_chop/1006233\nspring_rolls/1003056\npanna_cotta/1003460\nbeef_tartare/1005746\ngreek_salad/1009138\nfoie_gras/1008577\ntacos/1005454\npad_thai/1009595\npoutine/1019904\nramen/1002843\npulled_pork_sandwich/1005662\nbibimbap/1006709\nbeignets/1002569\napple_pie/1014775\ncrab_cakes/1003375\nrisotto/1009354\npaella/1000412\nsteak/100135\nbaby_back_ribs/1007102\nmiso_soup/1038398\nfrozen_yogurt/100093\nclub_sandwich/1020435\ncarrot_cake/1003032\nfalafel/1008896\nbread_pudding/1004540\nchicken_wings/1008504\ngnocchi/100680\ncaprese_salad/1024778\ncreme_brulee/1004352\nescargots/1014257\nchocolate_cake/1007122\ntiramisu/100504\nspaghetti_bolognese/1004943\nmussels/102234\nscallops/1007089\nbaklava/1014880\nedamame/1006400\nmacaroni_and_cheese/1012508\npancakes/1010075\ngarlic_bread/1012618\nbeet_salad/1005864\nonion_rings/1019009\nred_velvet_cake/1027041\ngrilled_salmon/1018852\nchicken_curry/1014843\ndeviled_eggs/1010482\ncaesar_salad/1000435\nhummus/1000605\nfish_and_chips/1003726\nlasagna/1005119\npeking_duck/101235\nguacamole/1014777\nstrawberry_shortcake/1013981\nclam_chowder/100792\ncroque_madame/1009303\nfrench_onion_soup/1008414\nbeef_carpaccio/1013939\nfried_rice/1008935\ndonuts/100576\ngyoza/1020354\nravioli/1010610\nfried_calamari/10044\nspaghetti_carbonara/1007514\nfrench_toast/100344\nlobster_bisque/102237\nceviche/1013481\nbruschetta/1031947\nfrench_fries/1008945\nshrimp_and_grits/1003400\nfilet_mignon/1002767\nhamburger/100517\ndumplings/100251\ntuna_tartare/1010786\nsushi/1005352\ncheese_plate/1003804\neggs_benedict/1002786\ncup_cakes/1008351\ntakoyaki/1002237\nchocolate_mousse/1018802\nbreakfast_burrito/1000669\nhot_dog/1011661\nmacarons/1001527\nwaffles/100353\nseaweed_salad/1014295\ncannoli/1008331\nhuevos_rancheros/100486\npizza/1008144\nchicken_quesadilla/1009225\npho/1011443\nprime_rib/1006320\ncheesecake/1004515\nice_cream/101858\nomelette/1007843\ngrilled_cheese_sandwich/10060\nlobster_roll_sandwich/1001432\nnachos/1009513\noysters/1016229\n\n\n2\nchurros/1016791\nhot_and_sour_soup/1008185\nsamosa/101365\nsashimi/1002556\npork_chop/1019530\nspring_rolls/1003507\npanna_cotta/1011097\nbeef_tartare/1009672\ngreek_salad/1010520\nfoie_gras/1011711\ntacos/1007867\npad_thai/1011059\npoutine/1028984\nramen/1004562\npulled_pork_sandwich/1008770\nbibimbap/1009730\nbeignets/1005233\napple_pie/1026328\ncrab_cakes/1006485\nrisotto/1014631\npaella/1004897\nsteak/101312\nbaby_back_ribs/1007272\nmiso_soup/1043862\nfrozen_yogurt/1014166\nclub_sandwich/102978\ncarrot_cake/1011021\nfalafel/1016116\nbread_pudding/1006034\nchicken_wings/1009927\ngnocchi/1011446\ncaprese_salad/1030908\ncreme_brulee/1008678\nescargots/1017301\nchocolate_cake/1007412\ntiramisu/1015080\nspaghetti_bolognese/1005431\nmussels/102600\nscallops/101158\nbaklava/1021344\nedamame/1018242\nmacaroni_and_cheese/101810\npancakes/101450\ngarlic_bread/1030410\nbeet_salad/1006123\nonion_rings/1020126\nred_velvet_cake/1041227\ngrilled_salmon/1019062\nchicken_curry/1022681\ndeviled_eggs/101298\ncaesar_salad/1011441\nhummus/1010716\nfish_and_chips/100968\nlasagna/1015789\npeking_duck/1015952\nguacamole/1016594\nstrawberry_shortcake/1017466\nclam_chowder/1019961\ncroque_madame/1013932\nfrench_onion_soup/1012354\nbeef_carpaccio/1021977\nfried_rice/1015700\ndonuts/100786\ngyoza/1024150\nravioli/1012118\nfried_calamari/100736\nspaghetti_carbonara/1012273\nfrench_toast/1006538\nlobster_bisque/1030246\nceviche/1014769\nbruschetta/1033851\nfrench_fries/1009455\nshrimp_and_grits/100346\nfilet_mignon/100639\nhamburger/100719\ndumplings/100262\ntuna_tartare/101595\nsushi/1012499\ncheese_plate/10057\neggs_benedict/1008725\ncup_cakes/1009501\ntakoyaki/1003289\nchocolate_mousse/1026492\nbreakfast_burrito/1002929\nhot_dog/1013916\nmacarons/1003207\nwaffles/1005295\nseaweed_salad/101671\ncannoli/1015289\nhuevos_rancheros/1005451\npizza/1008844\nchicken_quesadilla/1011413\npho/1012513\nprime_rib/100945\ncheesecake/1004807\nice_cream/102595\nomelette/1015300\ngrilled_cheese_sandwich/1007544\nlobster_roll_sandwich/100646\nnachos/1011394\noysters/1023832\n\n\n3\nchurros/102100\nhot_and_sour_soup/1008701\nsamosa/1015943\nsashimi/1007253\npork_chop/1019569\nspring_rolls/1008736\npanna_cotta/1013000\nbeef_tartare/1012128\ngreek_salad/1011665\nfoie_gras/1017233\ntacos/1015285\npad_thai/1011238\npoutine/102911\nramen/101297\npulled_pork_sandwich/1037387\nbibimbap/1011217\nbeignets/1011780\napple_pie/1028787\ncrab_cakes/1013559\nrisotto/1017141\npaella/1018124\nsteak/1021458\nbaby_back_ribs/1008749\nmiso_soup/1046478\nfrozen_yogurt/1017177\nclub_sandwich/102996\ncarrot_cake/1024932\nfalafel/102463\nbread_pudding/100939\nchicken_wings/101104\ngnocchi/1029180\ncaprese_salad/103421\ncreme_brulee/1010919\nescargots/1019707\nchocolate_cake/1009391\ntiramisu/1023537\nspaghetti_bolognese/1016511\nmussels/1026090\nscallops/1012281\nbaklava/1024334\nedamame/102048\nmacaroni_and_cheese/1018941\npancakes/1014974\ngarlic_bread/1031308\nbeet_salad/1011225\nonion_rings/102531\nred_velvet_cake/1043495\ngrilled_salmon/1026062\nchicken_curry/1027623\ndeviled_eggs/1025242\ncaesar_salad/1013504\nhummus/1014424\nfish_and_chips/1010511\nlasagna/1019253\npeking_duck/101675\nguacamole/1017481\nstrawberry_shortcake/1022070\nclam_chowder/1020283\ncroque_madame/1015306\nfrench_onion_soup/1020156\nbeef_carpaccio/102840\nfried_rice/1019981\ndonuts/1008454\ngyoza/103201\nravioli/1014283\nfried_calamari/1018068\nspaghetti_carbonara/1012528\nfrench_toast/1025962\nlobster_bisque/1030273\nceviche/1015455\nbruschetta/1034274\nfrench_fries/1020588\nshrimp_and_grits/1006712\nfilet_mignon/1007877\nhamburger/1007277\ndumplings/1002996\ntuna_tartare/1016519\nsushi/1013418\ncheese_plate/1008229\neggs_benedict/1010197\ncup_cakes/1010744\ntakoyaki/1012802\nchocolate_mousse/1027823\nbreakfast_burrito/1006144\nhot_dog/101571\nmacarons/1003224\nwaffles/1011635\nseaweed_salad/1019344\ncannoli/1019714\nhuevos_rancheros/1008025\npizza/1008941\nchicken_quesadilla/1023828\npho/1019401\nprime_rib/10120\ncheesecake/1017408\nice_cream/1044117\nomelette/1029915\ngrilled_cheese_sandwich/1013343\nlobster_roll_sandwich/100655\nnachos/1013641\noysters/103236\n\n\n4\nchurros/1025494\nhot_and_sour_soup/1008924\nsamosa/1016296\nsashimi/1010510\npork_chop/1025391\nspring_rolls/1012525\npanna_cotta/1020036\nbeef_tartare/1027680\ngreek_salad/1012989\nfoie_gras/1023512\ntacos/1023154\npad_thai/1013966\npoutine/1036670\nramen/1014141\npulled_pork_sandwich/1040750\nbibimbap/1014434\nbeignets/1019643\napple_pie/1043283\ncrab_cakes/1026455\nrisotto/1018227\npaella/1028277\nsteak/1032846\nbaby_back_ribs/1009028\nmiso_soup/1050730\nfrozen_yogurt/1017511\nclub_sandwich/1040746\ncarrot_cake/1038934\nfalafel/1033721\nbread_pudding/1018769\nchicken_wings/1012615\ngnocchi/1034178\ncaprese_salad/103452\ncreme_brulee/1015138\nescargots/1020134\nchocolate_cake/1012239\ntiramisu/1026043\nspaghetti_bolognese/102916\nmussels/1032420\nscallops/1025170\nbaklava/1031470\nedamame/1021273\nmacaroni_and_cheese/1024001\npancakes/101644\ngarlic_bread/1038093\nbeet_salad/1015901\nonion_rings/1037898\nred_velvet_cake/104733\ngrilled_salmon/1053214\nchicken_curry/102896\ndeviled_eggs/102827\ncaesar_salad/1019118\nhummus/1014861\nfish_and_chips/1012859\nlasagna/1028961\npeking_duck/1019978\nguacamole/1023237\nstrawberry_shortcake/1030449\nclam_chowder/1023442\ncroque_madame/1016269\nfrench_onion_soup/1020179\nbeef_carpaccio/1028573\nfried_rice/1021229\ndonuts/101905\ngyoza/1036466\nravioli/1019632\nfried_calamari/1021250\nspaghetti_carbonara/1014928\nfrench_toast/102612\nlobster_bisque/1033811\nceviche/1027751\nbruschetta/1034665\nfrench_fries/1026314\nshrimp_and_grits/1011064\nfilet_mignon/1015486\nhamburger/100930\ndumplings/100410\ntuna_tartare/1052688\nsushi/1018953\ncheese_plate/1008347\neggs_benedict/1018581\ncup_cakes/1027241\ntakoyaki/1016334\nchocolate_mousse/1034251\nbreakfast_burrito/1010145\nhot_dog/1017226\nmacarons/1004903\nwaffles/1013333\nseaweed_salad/1019648\ncannoli/1021048\nhuevos_rancheros/1014671\npizza/1011404\nchicken_quesadilla/1024740\npho/1021371\nprime_rib/1016126\ncheesecake/1021942\nice_cream/104465\nomelette/1038109\ngrilled_cheese_sandwich/1016030\nlobster_roll_sandwich/100702\nnachos/1014846\noysters/1038150\n\n\n\n\ndf_train_txt = pd.read_csv('/content/food-101/train.txt')\ndf_train_txt.head(10)\n\n\n\n\n\n\napple_pie/1005649\n\n\n\n\n0\napple_pie/1014775\n\n\n1\napple_pie/1026328\n\n\n2\napple_pie/1028787\n\n\n3\napple_pie/1043283\n\n\n4\napple_pie/1050519\n\n\n5\napple_pie/1057749\n\n\n6\napple_pie/1057810\n\n\n7\napple_pie/1072416\n\n\n8\napple_pie/1074856\n\n\n9\napple_pie/1074942\n\n\n\n\nWe can see that .txt file is of no use\n\nLet’s view 5 random food items\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# actual path to train image folder\ntrain_path = '/content/food-101/images'\n\n# Function to get a list of all image paths in the specified folder\ndef get_image_paths(folder):\n    image_paths = []\n    for root, dirs, files in os.walk(folder):\n        for file in files:\n            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n                image_paths.append(os.path.join(root, file))\n    return image_paths\n\n# Function to randomly select and display 5 larger images\ndef show_random_images(image_paths, num_images=5, display_size=(25, 25)):\n    selected_images = random.sample(image_paths, min(num_images, len(image_paths)))\n\n    fig, axes = plt.subplots(1, num_images, figsize=display_size)\n\n    for ax, image_path in zip(axes, selected_images):\n        img = Image.open(image_path)\n        img = img.resize((display_size[0]*50, display_size[1]*50))  # Increase size\n        ax.imshow(img)\n        ax.axis('off')\n\n    plt.show()\n\n# Get a list of all image paths in the specified folder\nall_image_paths = get_image_paths(train_path)\n\n# Show 5 random larger images\nshow_random_images(all_image_paths, num_images=5, display_size=(25, 25))\n\n\n\nRemove images that are corrupt\nverify_images() will return the paths of images that are corrupt, and we can use unlink to remove these files.\nfns_train = get_image_files(train_path)\nfns_test = get_image_files(test_path)\n\n\ntotal_train_imagelength = len(fns_train)\ntotal_test_imagelength = len(fns_test)\n\nfailed = verify_images(fns_train)\nfailed_imagelength = len(failed)\n\n# remove images that are corrupt\nfailed.map(Path.unlink)\n\n# The images are in train_images, so let's grab a list of all of them:\n# trn_path = path/'train'\n# files = get_image_files(trn_path)\n\nImage_Count_Dict = {\"Total_Train_Image_Count\": total_train_imagelength, \n                    \"Failed_Train_Image_Count\": failed_imagelength,\n                   \"Total_Test_Image_Count\": total_test_imagelength}\nImage_Count_Dict\n{'Total_Train_Image_Count': 85850,\n 'Failed_Train_Image_Count': 0,\n 'Total_Test_Image_Count': 15150}\n\n\nStandardize the size of Images\nLet’s check all their sizes. This is faster if we do it in parallel, it helps in executing function in parallel.\nfrom fastcore.parallel import *\n\ndef f(o): return PILImage.create(o).size\nsizes = parallel(f, fns_train, n_workers=8)\npd.Series(sizes).value_counts()\n(512, 512)    52962\n(512, 384)    12531\n(384, 512)     5522\n(382, 512)     2431\n(512, 382)     2118\n              ...  \n(489, 512)        1\n(469, 512)        1\n(405, 512)        1\n(407, 512)        1\n(279, 512)        1\nName: count, Length: 453, dtype: int64\nWe can see that we have lots of images with different sizes. We need to standardize it."
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part1/index.html#data-loader",
    "href": "posts/FastAI_Course_Lect6_Part1/index.html#data-loader",
    "title": "FastAI Course Lecture 6 Part 1 Notes",
    "section": "2. Data Loader",
    "text": "2. Data Loader\nOur images are of size of 512(multiple of 32) , let’s resize it to 480( multiple of 32) .\n\nTip If an image is in a rectangular format such as (640,480) with an aspect ratio (4:3), maintain the same aspect ratio when resizing the images. For example, resize it to (256,192). Additionally, if possible set new size to be multiple of 32. CNN works great with 32* size.\n\ndls = ImageDataLoaders.from_folder(train_path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(480, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n\nReferring Best Vision models for fine-tuning we can make a case that resnet26d is the fastest resolution-independent model, which make it into the top-15 lists there\n\nGoal is not to achieve the best possible results, but rather to get things going with simple models & then improve upon them."
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part1/index.html#model-building",
    "href": "posts/FastAI_Course_Lect6_Part1/index.html#model-building",
    "title": "FastAI Course Lecture 6 Part 1 Notes",
    "section": "3. Model Building",
    "text": "3. Model Building\nHalf-precision floating-point [.to_fp16()] uses 16 bits to store a number, while single precision (float32) uses 32 bits and double precision (float64) uses 64 bits. It is useful in deep learning for its reduced memory usage.\nFurthermore, it is great tool to be utilized during the inference phase to save memory and computational resources.\n\nWith floating point\nlearn_with_fp = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.').to_fp16()\nlearn_with_fp.fine_tune(4)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.790304\n2.355953\n0.580431\n06:11\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.105901\n1.847007\n0.469715\n06:12\n\n\n1\n1.867976\n1.591036\n0.411415\n06:14\n\n\n2\n1.614650\n1.446619\n0.375655\n06:16\n\n\n3\n1.456076\n1.420436\n0.368957\n06:15\n\n\n\n\n\nWithout floating point\nlearn_without_fp = vision_learner(dls, 'resnet26d', metrics=error_rate, path='.')\nlearn_without_fp.fine_tune(4)\nmodel.safetensors:   0%|          | 0.00/64.2M [00:00&lt;?, ?B/s]\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.788730\n2.332079\n0.579849\n06:15\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.188421\n1.854993\n0.471870\n06:26\n\n\n1\n1.821760\n1.596297\n0.414735\n06:32\n\n\n2\n1.586775\n1.457398\n0.379907\n06:45\n\n\n3\n1.483222\n1.437040\n0.376878\n06:35\n\n\n\n\nComparing both, we can observe that floating point arithmetic didn’t prove as handy as it should have been, accuracy and time remain the same.\nAdditionally, let’s recall our first task on classification of Big Cats with very little data, we achieved significantly higher accuracy. However, despite the abundance of images (85,850) in this case, we still encounter significant inaccuracies. This discrepancy suggests that the model is encountering learning challenges, possibly due to issues with the training data or the images being too similar. For instance, there may be minimal variation in certain dishes despite being categorized differently, such as Veg Pulao & Briyani.\n\n\n\nLearning Rate\nLearning Rate blog\nAs discussed earlier, Valley & Slide yield the best results. So, we don’t need to call the other two functions. Our default value for learning rate is 0.02.\nlearn_without_fp.lr_find(suggest_funcs=(valley, slide))\n\nSuggestedLRs(valley=1.2022644114040304e-05, slide=0.019054606556892395)\n\nSo it was the learning rate that caused such a high error rate as we can see in our plot. Let’s reduce it near to valley point.\n\n\nFinal Model\nlearn_without_fp.fit(4, lr=0.0002)\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.489364\n1.298432\n0.340885\n06:29\n\n\n1\n1.253947\n1.154729\n0.307047\n06:29\n\n\n2\n1.164939\n1.070023\n0.283518\n06:33\n\n\n3\n1.037511\n1.050543\n0.275713\n06:34\n\n\n\n\n\nLet’s Export the model\nlearn_without_fp.export('Lecture6_Part1_Food_Resnet_Model.pkl')"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part1/index.html#run-of-test-data",
    "href": "posts/FastAI_Course_Lect6_Part1/index.html#run-of-test-data",
    "title": "FastAI Course Lecture 6 Part 1 Notes",
    "section": "4. Run of Test Data",
    "text": "4. Run of Test Data\n\nRead test data\nNow, we can obtain the probabilities of each class and the index of the most likely class from this test set. The second object returned by get_preds contains the targets, which are blank for a test set, so we discard them.\ntest_files = get_image_files(test_path).sorted()\ntest_dl = dls.test_dl(test_files)\n\nprobs,_,idxs = learn_without_fp.get_preds(dl=test_dl, with_decoded=True)\nidxs\n\ntensor([54, 80, 44,  ..., 73, 78, 92])\nThese need to be mapped to the names of each type. These names are automatically stored by FastAI in the vocab.\ndls.vocab\n['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n\n\nMap the number with name\nLet’s create a mapping using pandas:\nfilenames = [path.name for path in test_files]\nss = pd.DataFrame({'image_id': filenames})\nss\n\n\n\n\n\n\nimage_id\n\n\n\n\n0\n1000486.jpg\n\n\n1\n100057.jpg\n\n\n2\n1000605.jpg\n\n\n3\n100093.jpg\n\n\n4\n1001084.jpg\n\n\n…\n…\n\n\n15145\n999449.jpg\n\n\n15146\n999550.jpg\n\n\n15147\n999858.jpg\n\n\n15148\n999875.jpg\n\n\n15149\n999961.jpg\n\n\n\n\n15150 rows × 1 columns\n\n\nmapping = dict(enumerate(dls.vocab))\nresults = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\nresults\n0           hot_and_sour_soup\n1        pulled_pork_sandwich\n2                  fried_rice\n3               frozen_yogurt\n4              chocolate_cake\n                 ...         \n15145     macaroni_and_cheese\n15146           chicken_curry\n15147             panna_cotta\n15148                 poutine\n15149            spring_rolls\nName: idxs, Length: 15150, dtype: object\nss['label'] = results\nss.to_csv('/kaggle/working/Lecture6_Part1_Food_Resnet_Submit.csv', index=False)\n!head Lecture6_Part1_Food_Resnet_Submit.csv\nimage_id,label\n1000486.jpg,hot_and_sour_soup\n100057.jpg,pulled_pork_sandwich\n1000605.jpg,fried_rice\n100093.jpg,frozen_yogurt\n1001084.jpg,chocolate_cake\n1001089.jpg,baby_back_ribs\n1001113.jpg,bibimbap\n100148.jpg,french_fries\n1002334.jpg,baklava"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "",
    "text": "In Lecture6-Part1 we build our model using resent26d architecture with best accuracy 73%. In this notebook we will be using ConvNeXt model and aiming towards higher accuracy."
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#lets-download-fastai-food-data",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#lets-download-fastai-food-data",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "Let’s download FastAI Food data",
    "text": "Let’s download FastAI Food data\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = '/content/food-101/images'\ntest_path = '/content/food-101/test'\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n\n\n\n\n100.00% [5686607872/5686607260 02:31&lt;00:00]"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#lets-make-it-faster",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#lets-make-it-faster",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "Let’s make it faster",
    "text": "Let’s make it faster\nLast time, we encountered a problem even though we were using the fastest architecture. It was still taking too long. For a change, let’s resize the images to 256 pixels. This will decrease the size of each pixel and allow us to train our model faster.\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n\n\nMake it into a function\nIn this notebook, we will be experimenting with lots of models, data(image) augmentation, and other techniques. So instead of repeating the same code every time, let’s create a function that can be called whenever needed.\ndef train(arch, item, batch, epochs=4, learning_rate=0.0002):\n    dls = ImageDataLoaders.from_folder(path, seed=42, valid_pct=0.2, item_tfms=item, batch_tfms=batch)\n    learn = vision_learner(dls, arch, metrics=error_rate)\n    learn.fine_tune(epochs, learning_rate)\n    return learn\nTo ensure consistent function behavior, we have rigidly set the number of epochs and the learning rate value.\n\n\nCall the function\nlearn = train('resnet26d', item=Resize(256),batch=aug_transforms(size=128, min_scale=0.75))\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.727076\n2.929649\n0.664554\n04:58\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.250653\n2.632962\n0.618911\n05:03\n\n\n1\n2.837729\n2.394110\n0.584109\n05:09\n\n\n2\n2.680722\n2.286321\n0.563812\n05:10\n\n\n3\n2.653321\n2.266845\n0.560149\n05:08\n\n\n\nThough we were able to reduce the time but we got higher error rate."
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#convnext-model",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#convnext-model",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "ConvNeXt model",
    "text": "ConvNeXt model\nIn our previous notebook, we discussed how the convnext_tiny_in22k is go-to model. We would like to reduce image size to 192(multiple 32) & use squish method for data augmentation.\narch = 'convnext_tiny_in22k'\n\nlearn_squish = train(arch, item=Resize(192, method='squish'),batch=aug_transforms(size=128, min_scale=0.75))\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/178M [00:00&lt;?, ?B/s]\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.464850\n1.882828\n0.412178\n17:27\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.082745\n1.638774\n0.375693\n21:36\n\n\n1\n1.828319\n1.418455\n0.350842\n21:36\n\n\n2\n1.719477\n1.355143\n0.342327\n21:34\n\n\n3\n1.633262\n1.351079\n0.340000\n21:38"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#data-augmentation",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#data-augmentation",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "Data Augmentation",
    "text": "Data Augmentation\n\nCrop\nSquish has already been performed in the last scenario, so let’s check on crop method, which is default in Fastai.\nlearn_crop = train(arch, item=Resize(192),batch=aug_transforms(size=128, min_scale=0.75))\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.491307\n1.843047\n0.401188\n17:40\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.034851\n1.604407\n0.364554\n21:32\n\n\n1\n1.804160\n1.384419\n0.342921\n21:39\n\n\n2\n1.620802\n1.324999\n0.334158\n21:28\n\n\n3\n1.583603\n1.313850\n0.331733\n21:29\n\n\n\nlearn_crop.export('Lecture6_Part2_Food_Convnext_Tiny_Crop.pkl')\n\n\nPadding\nIt keeps all the original images without transforming them, unlike squish & crop, which change size of the images.\nlearn_padding = train(arch, item=Resize((192), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),\n      batch=aug_transforms(size=(128), min_scale=0.75))\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.619984\n1.938507\n0.432228\n17:25\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.151396\n1.702708\n0.392723\n21:27\n\n\n1\n1.879488\n1.477281\n0.369158\n21:37\n\n\n2\n1.783989\n1.412986\n0.354554\n21:28\n\n\n3\n1.738043\n1.404341\n0.354356\n21:25\n\n\n\nlearn_padding.export('Lecture6_Part2_Food_Convnext_Tiny_Padding.pkl')\n\nBest among these three is Padding method. Let’s obtain it’s learning rate & see if that needs to be changed.\nlearn_crop.lr_find(suggest_funcs=(valley, slide))\n\nSuggestedLRs(valley=4.365158383734524e-05, slide=0.019054606556892395)\n\nAs far as learning rate is concerned we are good to go.\n\n\n\nTest time augmentation\nInstead of making predictions on the original validation image, the model makes predictions on multiple augmented versions of the test image and combines these predictions.\nFor more refer : Test Time Augmentation.\ntta_preds,targs = learn_crop.tta(dl=learn_crop.dls.valid)\nerror_rate(tta_preds, targs)\n\n\n\n\n\n\nTensorBase(0.3120)"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#scaling-up",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#scaling-up",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "Scaling Up",
    "text": "Scaling Up\nNow that we have identified the best possible model and data augmentation type, let’s scale it up by increasing the image size back to 512 & number of epoch to 6.\nWith more than 5 epochs, we are in danger of overfitting. (10 is certainly overfitting because our model has seen every image 10 times by now).\nlearn = train(arch,item=Resize(512),batch=aug_transforms(size=(256), min_scale=0.75), epochs=10)\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_tiny_in22k to current convnext_tiny.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/178M [00:00&lt;?, ?B/s]\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.119423\n1.545519\n0.324604\n31:25\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.857518\n1.425361\n0.301139\n35:32\n\n\n1\n1.573771\n1.231033\n0.280644\n35:34\n\n\n2\n1.429572\n1.093103\n0.265149\n35:35\n\n\n3\n1.246169\n1.031862\n0.256931\n35:35\n\n\n4\n1.202549\n1.000573\n0.249356\n35:35\n\n\n5\n1.172318\n0.974019\n0.246089\n35:34\n\n\n6\n1.095220\n0.961513\n0.242673\n35:36\n\n\n7\n1.071022\n0.952826\n0.242079\n35:40\n\n\n8\n1.101088\n0.950712\n0.241139\n35:38\n\n\n9\n1.096281\n0.950866\n0.240545\n35:35\n\n\n\nThis is far more accurate than our previous model."
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#conclusion",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#conclusion",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "Conclusion",
    "text": "Conclusion\nWe achieved higher accuracy compared to our Part 1 version, but it put too much strain on our GPU. It even crashed at times during the execution of the ‘Scale Up!’ part. In the next notebook, we will learn how to optimize the GPU for better performance."
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part2/index.html#lets-download-food-data-from-fastai",
    "href": "posts/FastAI_Course_Lect6_Part2/index.html#lets-download-food-data-from-fastai",
    "title": "FastAI Course Lecture 6 Part 2 Notes",
    "section": "Let’s download food data from FastAI",
    "text": "Let’s download food data from FastAI\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = '/content/food-101/images'\ntest_path = '/content/food-101/test'\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\n\n\n\n\n100.00% [5686607872/5686607260 02:31&lt;00:00]"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "",
    "text": "#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = Path('/content/food-101/images')\ntest_path = Path('/content/food-101/test')\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (3.13.1)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.66.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.9.0)\nRequirement already satisfied: packaging&gt;=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&gt;=20.9-&gt;huggingface_hub-&gt;timm) (3.1.1)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2-&gt;torch-&gt;timm) (2.1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (2024.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy-&gt;torch-&gt;timm) (1.3.0)\n\n\n\n\n100.00% [5686607872/5686607260 02:04&lt;00:00]\n\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n\n\n\nPreviously, we had very big data to be trained on, which is why it took so long to train our model. Learning from that, we can undersample our training dataset so that we can get a picture of which model works best. Generally, if a model is performing well proportion of dataset, it will likely perform well on the whole dataset.\nThere are two ways of doing this :\n\nWe can take 5-10% of all types of food & then train our model\nWe can target 1 food type and train our model on it.\n\nProblem with case 1 is that we would have so little that from every type of food that our model might not be able to understand it well. In case 2, we can significantly reduce the training time and computational resources required.\nsubfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]\nsubfolder_count = len(subfolders)\nprint(subfolders)\n['fish_and_chips', 'caprese_salad', 'strawberry_shortcake', 'pork_chop', 'edamame', 'macaroni_and_cheese', 'gnocchi', 'lobster_roll_sandwich', 'takoyaki', 'baklava', 'sushi', 'beef_tartare', 'miso_soup', 'steak', 'hot_dog', 'grilled_cheese_sandwich', 'greek_salad', 'crab_cakes', 'falafel', 'beet_salad', 'apple_pie', 'onion_rings', 'chocolate_mousse', 'risotto', 'chicken_wings', 'french_fries', 'pancakes', 'paella', 'chicken_quesadilla', 'gyoza', 'bread_pudding', 'beignets', 'carrot_cake', 'waffles', 'ceviche', 'huevos_rancheros', 'ravioli', 'sashimi', 'bibimbap', 'creme_brulee', 'spaghetti_bolognese', 'cheese_plate', 'oysters', 'filet_mignon', 'baby_back_ribs', 'fried_rice', 'ice_cream', 'tacos', 'cheesecake', 'foie_gras', 'shrimp_and_grits', 'macarons', 'poutine', 'french_onion_soup', 'deviled_eggs', 'grilled_salmon', 'eggs_benedict', 'croque_madame', 'seaweed_salad', 'churros', 'hummus', 'bruschetta', 'club_sandwich', 'ramen', 'clam_chowder', 'cup_cakes', 'hot_and_sour_soup', 'garlic_bread', 'breakfast_burrito', 'guacamole', 'lobster_bisque', 'spring_rolls', 'samosa', 'red_velvet_cake', 'pulled_pork_sandwich', 'escargots', 'chocolate_cake', 'spaghetti_carbonara', 'caesar_salad', 'hamburger', 'tuna_tartare', 'donuts', 'fried_calamari', 'mussels', 'omelette', 'panna_cotta', 'pad_thai', 'beef_carpaccio', 'pizza', 'nachos', 'chicken_curry', 'pho', 'tiramisu', 'frozen_yogurt', 'peking_duck', 'prime_rib', 'cannoli', 'dumplings', 'french_toast', 'lasagna', 'scallops']\n# let's randomly take baby_back_ribs folder for training\ntrn_path = train_path/'baby_back_ribs'\ntst_files = get_image_files(test_path).sorted()"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#call-library-download-data-create-folder-blah-blah..",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#call-library-download-data-create-folder-blah-blah..",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "",
    "text": "#hide\n!pip install -Uqq fastbook\n!pip install timm\n\nimport fastbook\nfastbook.setup_book()\nimport timm\n\n#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nfrom fastai.vision.all import *\n\npath = Path('/content')\nuntar_data(URLs.FOOD, data=path)\n\n# actual path to train image folder\ntrain_path = Path('/content/food-101/images')\ntest_path = Path('/content/food-101/test')\n\n# Create Test folder\n\nimport os\nimport random\nimport shutil\n\ndef move_images_to_test(source_folder, test_folder, percentage=0.1):\n    # Create the test folder if it doesn't exist\n    os.makedirs(test_folder, exist_ok=True)\n\n    # Iterate through each subfolder in the source folder\n    for subfolder in os.listdir(source_folder):\n        subfolder_path = os.path.join(source_folder, subfolder)\n\n        # Check if it's a directory\n        if os.path.isdir(subfolder_path):\n            # Get a list of all image files in the subfolder\n            image_files = [f for f in os.listdir(subfolder_path) if f.endswith('.jpg')]\n\n            # Calculate the number of images to move\n            num_images_to_move = int(len(image_files) * percentage)\n\n            # Randomly select images to move\n            images_to_move = random.sample(image_files, num_images_to_move)\n\n            # Move selected images to the test folder\n            for image in images_to_move:\n                source_path = os.path.join(subfolder_path, image)\n                dest_path = os.path.join(test_folder, image)\n                shutil.move(source_path, dest_path)\n\nif __name__ == \"__main__\":\n    move_images_to_test(train_path, test_path, percentage=0.15)\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (3.13.1)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.66.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (4.9.0)\nRequirement already satisfied: packaging&gt;=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub-&gt;timm) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch-&gt;timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,&gt;=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision-&gt;timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging&gt;=20.9-&gt;huggingface_hub-&gt;timm) (3.1.1)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2-&gt;torch-&gt;timm) (2.1.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (1.26.18)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests-&gt;huggingface_hub-&gt;timm) (2024.2.2)\nRequirement already satisfied: mpmath&gt;=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy-&gt;torch-&gt;timm) (1.3.0)\n\n\n\n\n100.00% [5686607872/5686607260 02:04&lt;00:00]\n\ndls = ImageDataLoaders.from_folder(path, valid_pct=0.2, seed=42,\n    item_tfms=Resize(256, method='squish'),\n    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n\ndls.show_batch(max_n=4)\n\n\n\nPreviously, we had very big data to be trained on, which is why it took so long to train our model. Learning from that, we can undersample our training dataset so that we can get a picture of which model works best. Generally, if a model is performing well proportion of dataset, it will likely perform well on the whole dataset.\nThere are two ways of doing this :\n\nWe can take 5-10% of all types of food & then train our model\nWe can target 1 food type and train our model on it.\n\nProblem with case 1 is that we would have so little that from every type of food that our model might not be able to understand it well. In case 2, we can significantly reduce the training time and computational resources required.\nsubfolders = [f.name for f in os.scandir(train_path) if f.is_dir()]\nsubfolder_count = len(subfolders)\nprint(subfolders)\n['fish_and_chips', 'caprese_salad', 'strawberry_shortcake', 'pork_chop', 'edamame', 'macaroni_and_cheese', 'gnocchi', 'lobster_roll_sandwich', 'takoyaki', 'baklava', 'sushi', 'beef_tartare', 'miso_soup', 'steak', 'hot_dog', 'grilled_cheese_sandwich', 'greek_salad', 'crab_cakes', 'falafel', 'beet_salad', 'apple_pie', 'onion_rings', 'chocolate_mousse', 'risotto', 'chicken_wings', 'french_fries', 'pancakes', 'paella', 'chicken_quesadilla', 'gyoza', 'bread_pudding', 'beignets', 'carrot_cake', 'waffles', 'ceviche', 'huevos_rancheros', 'ravioli', 'sashimi', 'bibimbap', 'creme_brulee', 'spaghetti_bolognese', 'cheese_plate', 'oysters', 'filet_mignon', 'baby_back_ribs', 'fried_rice', 'ice_cream', 'tacos', 'cheesecake', 'foie_gras', 'shrimp_and_grits', 'macarons', 'poutine', 'french_onion_soup', 'deviled_eggs', 'grilled_salmon', 'eggs_benedict', 'croque_madame', 'seaweed_salad', 'churros', 'hummus', 'bruschetta', 'club_sandwich', 'ramen', 'clam_chowder', 'cup_cakes', 'hot_and_sour_soup', 'garlic_bread', 'breakfast_burrito', 'guacamole', 'lobster_bisque', 'spring_rolls', 'samosa', 'red_velvet_cake', 'pulled_pork_sandwich', 'escargots', 'chocolate_cake', 'spaghetti_carbonara', 'caesar_salad', 'hamburger', 'tuna_tartare', 'donuts', 'fried_calamari', 'mussels', 'omelette', 'panna_cotta', 'pad_thai', 'beef_carpaccio', 'pizza', 'nachos', 'chicken_curry', 'pho', 'tiramisu', 'frozen_yogurt', 'peking_duck', 'prime_rib', 'cannoli', 'dumplings', 'french_toast', 'lasagna', 'scallops']\n# let's randomly take baby_back_ribs folder for training\ntrn_path = train_path/'baby_back_ribs'\ntst_files = get_image_files(test_path).sorted()"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#gpu-problem",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#gpu-problem",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "GPU Problem",
    "text": "GPU Problem\nIn the previous file, we encountered a problem regarding GPU, where we run out of memory & have to wait to till our memory was cleared by Kaggle(on Saturday). We can use Gradient accumulation or Half-Precision floating point to save from future GPU constraints. Regarding Half-Precision floating point, we tested it in our first notebook of this series and observed minimal change in performance.\n\nGradient Accumulation\nWorking of Gradient Accumulation :\n\nForward pass: Input data is fed through the model to compute predictions.\nBackward pass: Gradients are computed by back-propagating the error through the network.\nGradients are accumulated over multiple mini-batches.\nModel parameters are updated after a certain number of mini-batches.\n\nBy accumulating gradients over multiple batches,it allows to simulate the effects of a larger batch size without exceeding the available memory.\nHowever, there is a catch that it can have Impact on Training Time. While increasing accumulation can save GPU memory, it may also slow down the training process. The model parameters are updated less frequently, potentially prolonging the convergence time.\n\n\nfine_tune() vs fit_one_cycle()\nfine_tune() It uses transfer learning, where it take a pre-trained model (on ImageNet) & fine-tune it on a specific dataset. Idea is to leverage features learned by the pre-trained model & adapt them to new dataset.\nIt uses ‘discriminative learning rates’, where earlier layers are trained with lower learning rates (taking more time but understand data better) to avoid disrupting the general features they have learned. In contrast, later layers are trained with higher learning rates to adapt more quickly to the new tasks.\nfit_one_cycle() It used for training a model from scratch or for further fine tuning already fine tuned model.\n\nIt starts with low learning rate & gradually increases it over the courses of first half of learning rate.\nIn second half it decreases.\nThis cyclical pattern of learning rates is repeated for no of epochs specified.\n\nfine_tune() is primarily used for transfer learning, leveraging pre-trained models & adapting them to new data. While fit_one_cycle() is used for training models from scratch or further fine-tuning them using a cyclical learning rate schedule.\nfine_tune() is faster since it doesn’t do an initial fine-tuning of the head.\ndef train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=5):\n    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=item,\n        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n    cbs = GradientAccumulation(64) if accum else []\n    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n    if finetune:\n        learn.fine_tune(epochs, 0.01)\n        return learn.tta(dl=dls.test_dl(tst_files))\n    else:\n        learn.unfreeze()\n        learn.fit_one_cycle(epochs, 0.01)\n                        \n\nCheck the available GPU memory on Kaggle.\nimport torch\n\ndef check_gpu_memory():\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        total_memory = torch.cuda.get_device_properties(device).total_memory\n        reserved_memory = torch.cuda.memory_reserved(device)\n        allocated_memory = torch.cuda.memory_allocated(device)\n        free_memory = total_memory - reserved_memory - allocated_memory\n\n        print(f\"Total GPU memory: {total_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Reserved GPU memory: {reserved_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Allocated GPU memory: {allocated_memory / (1024 ** 3):.2f} GB\")\n        print(f\"Free GPU memory: {free_memory / (1024 ** 3):.2f} GB\")\n    else:\n        print(\"GPU not available.\")\n\n# Call the function to check GPU memory\ncheck_gpu_memory()\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.00 GB\nAllocated GPU memory: 0.00 GB\nFree GPU memory: 14.75 GB\n\n\n\nImpact of Gradient Accumulation\ntrain('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_small_in22k to current convnext_small.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/265M [00:00&lt;?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:08\n\n\n\n**It took 0:08 In GPU T4*2 and 0:22 in GPU P100**\n\nMemory Consumption and Clearning It after usage\nimport gc\ndef report_gpu():\n    print(torch.cuda.list_gpu_processes())\n    gc.collect()\n    torch.cuda.empty_cache()\nreport_gpu()\nGPU:0\nprocess       2200 uses     3250.000 MB GPU memory\nSo with accum=1 the GPU used around 3GB RAM. Let’s try accum=2:\ntrain('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:06\n\n\n\nReport GPU:\nGPU:0\nprocess       2200 uses     2200.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\nAs we can see that, the RAM usage has now gone down to 2GB. It’s not halved since there’s other overhead involved (for larger models this overhead is likely to be relatively lower).\nLet’s try 4:\ntrain('convnext_small_in22k', 128, epochs=1, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:08\n\n\n\nReport GPU:\nGPU:0\nprocess       2200 uses     1664.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\nWe are down to half of original version"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#memory-usage-of-every-model",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#memory-usage-of-every-model",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "Memory Usage of Every Model",
    "text": "Memory Usage of Every Model\nLet’s test this approach on all models that we want to evaluate and determine the optimal value for gradient accumulation. Kaggle provides a 16 GB GPU, and our goal is to fit all of our architectures within this constraint.\nconvnext_large_in22k make GPU Crash always, so let’s tone it down to convnext_base_in22k\ntrain('convnext_base_in22k', 256, epochs=2, accum=1, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name convnext_base_in22k to current convnext_base.fb_in22k.\n  model = create_fn(\n\n\n\nmodel.safetensors:   0%|          | 0.00/440M [00:00&lt;?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:12\n\n\n1\n0.000000\n0.000000\n0.000000\n00:12\n\n\n\nReport GPU:\nGPU:0\nprocess       2200 uses    12246.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\ntrain('convnext_base_in22k', 256, epochs=2, accum=2, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:12\n\n\n1\n0.000000\n0.000000\n0.000000\n00:12\n\n\n\nReport GPU:\nGPU:0\nprocess       2200 uses     6988.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\ntrain('convnext_base_in22k', 256, epochs=2, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:13\n\n\n1\n0.000000\n0.000000\n0.000000\n00:12\n\n\n\nReport GPU:\nGPU:0\nprocess       2200 uses     4360.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone\nWith accum = 4 there 1/3 of the memory consumption than original and also there not very high change in time taken\nvit_base which is a transformer\ntrain('vit_base_patch16_224', 224, epochs=2, accum=4, finetune=False)\nprint(\"Report GPU:\")\nprint(report_gpu())\n\nprint(\"\\nGPU_Memory:\")\nprint(check_gpu_memory())\nmodel.safetensors:   0%|          | 0.00/346M [00:00&lt;?, ?B/s]\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.000000\n0.000000\n0.000000\n00:09\n\n\n1\n0.000000\n0.000000\n0.000000\n00:08\n\n\n\nReport GPU:\nGPU:0\nprocess       2200 uses     2998.000 MB GPU memory\nNone\n\nGPU_Memory:\nTotal GPU memory: 14.75 GB\nReserved GPU memory: 0.14 GB\nAllocated GPU memory: 0.02 GB\nFree GPU memory: 14.59 GB\nNone"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#scaling-it-up-training-on-full-data",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#scaling-it-up-training-on-full-data",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "Scaling It Up!, Training on full data",
    "text": "Scaling It Up!, Training on full data\nLet’s create dictonary of all the required models & the preprocessing techinque like crop,squish etc.\ntrn_path = train_path\n\nmodels = {\n    'convnext_base_in22k': {\n        (Resize(480), (224)),\n    }, 'vit_base_patch16_224': {\n        (Resize(480, method='squish'), 224),\n        (Resize(480), 224),\n    }\n}\nmodels.items()\ndict_items([('convnext_base_in22k', {(Resize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), 'p': 1.0}:\nencodes: (Image,object) -&gt; encodes\n(TensorBBox,object) -&gt; encodes\n(TensorPoint,object) -&gt; encodes\ndecodes: , 224)}), ('vit_base_patch16_224', {(Resize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), 'p': 1.0}:\nencodes: (Image,object) -&gt; encodes\n(TensorBBox,object) -&gt; encodes\n(TensorPoint,object) -&gt; encodes\ndecodes: , 224), (Resize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), 'p': 1.0}:\nencodes: (Image,object) -&gt; encodes\n(TensorBBox,object) -&gt; encodes\n(TensorPoint,object) -&gt; encodes\ndecodes: , 224)})])\nAppend each set of TTA predictions on the test set into a list called tta_res\ntta_res = []\n\nfor arch,details in models.items():\n    for item,size in details:\n        print('---',arch)\n        print(size)\n        print(item.name)\n        tta_res.append(train(arch, size, item=item, accum=4)) #, epochs=1))\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n--- convnext_base_in22k\n224\nResize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), 'p': 1.0}\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.921503\n0.649621\n0.179557\n12:54\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.623931\n0.491215\n0.132964\n16:42\n\n\n1\n0.590722\n0.472942\n0.128422\n16:56\n\n\n2\n0.414496\n0.423165\n0.111881\n16:38\n\n\n3\n0.234155\n0.403548\n0.100291\n17:14\n\n\n4\n0.168659\n0.408064\n0.099418\n16:41\n\n\n\n\n\n\n\n\n\n--- vit_base_patch16_224\n224\nResize -- {'size': (480, 480), 'method': 'squish', 'pad_mode': 'reflection', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), 'p': 1.0}\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.048016\n0.767763\n0.210891\n10:24\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.901554\n0.667587\n0.179441\n13:21\n\n\n1\n0.723949\n0.652103\n0.176296\n13:18\n\n\n2\n0.525216\n0.550479\n0.146302\n13:19\n\n\n3\n0.276363\n0.497780\n0.126616\n13:16\n\n\n4\n0.183772\n0.490051\n0.119802\n13:15\n\n\n\n\n\n\n\n\n\n--- vit_base_patch16_224\n224\nResize -- {'size': (480, 480), 'method': 'crop', 'pad_mode': 'reflection', 'resamples': (&lt;Resampling.BILINEAR: 2&gt;, &lt;Resampling.NEAREST: 0&gt;), 'p': 1.0}\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.054235\n0.758079\n0.205708\n10:19\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.881566\n0.701312\n0.193710\n13:15\n\n\n1\n0.741848\n0.650074\n0.174490\n13:15\n\n\n2\n0.547625\n0.550333\n0.144904\n13:15\n\n\n3\n0.274780\n0.499551\n0.125859\n13:13\n\n\n4\n0.173512\n0.485806\n0.118987\n13:15\n\n\n\n\n\n\n\n\n\n\nSave the Model\nsave_pickle('/kaggle/working/Lecture6_Part3_tta_res.pkl', tta_res)"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#ensemble",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#ensemble",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "Ensemble",
    "text": "Ensemble\nLearner.tta returns predictions and targets for each rows. We just want the predictions\n tta_prs = first(zip(*tta_res))\ntta_prs\n(tensor([[1.4376e-09, 6.0367e-10, 8.9613e-10,  ..., 5.5386e-09, 8.7931e-08, 4.2121e-10],\n         [4.7340e-05, 7.8465e-06, 1.3157e-05,  ..., 3.5937e-05, 6.6248e-06, 2.0246e-06],\n         [2.3749e-05, 2.8122e-07, 8.3784e-08,  ..., 6.6318e-06, 5.9989e-08, 9.9459e-07],\n         ...,\n         [1.9584e-06, 1.3206e-07, 3.0607e-06,  ..., 1.4922e-07, 5.0935e-09, 8.6562e-08],\n         [4.8399e-03, 1.2087e-04, 4.5856e-04,  ..., 5.0185e-06, 9.4111e-05, 1.8684e-05],\n         [5.0047e-06, 4.3755e-05, 1.8506e-06,  ..., 6.1585e-06, 5.6130e-07, 1.9855e-06]]),\n tensor([[3.4493e-08, 5.3500e-09, 1.6126e-07,  ..., 3.8252e-08, 1.5104e-06, 2.6966e-09],\n         [6.6286e-03, 7.0347e-05, 3.0234e-05,  ..., 1.9852e-04, 4.9287e-05, 1.0562e-05],\n         [3.3405e-08, 9.6962e-08, 1.1187e-08,  ..., 7.3134e-08, 6.8583e-09, 2.5434e-08],\n         ...,\n         [3.6105e-09, 2.5499e-09, 1.0355e-07,  ..., 4.7640e-10, 4.5013e-08, 5.3833e-10],\n         [1.8239e-06, 1.0662e-06, 9.2194e-07,  ..., 7.3355e-07, 1.3718e-07, 8.0097e-07],\n         [8.3010e-08, 1.5209e-06, 3.5702e-07,  ..., 2.3531e-07, 7.9341e-09, 3.4715e-09]]),\n tensor([[2.3078e-09, 5.1558e-09, 2.3751e-09,  ..., 1.5020e-08, 2.7991e-08, 4.2394e-10],\n         [2.2522e-02, 1.2250e-05, 2.0199e-05,  ..., 1.2231e-04, 7.0627e-06, 2.2908e-06],\n         [1.0235e-07, 1.3238e-08, 4.5449e-09,  ..., 8.5051e-09, 9.0174e-10, 2.8542e-08],\n         ...,\n         [1.2824e-07, 1.0214e-08, 1.7250e-07,  ..., 3.6925e-09, 3.7722e-07, 2.4337e-09],\n         [1.6956e-05, 5.6481e-06, 5.4464e-06,  ..., 1.2303e-06, 1.3186e-05, 2.0320e-04],\n         [4.9362e-08, 1.2064e-06, 1.6594e-06,  ..., 1.0572e-08, 2.2195e-08, 4.6684e-09]]))\nEnsemble is a model which is combination of multiple models. Bagging,Boosting are it’s types.Those are bit complicated & we will stick to simple version that is averaging them out.\navg_pr = torch.stack(tta_prs).mean(0)\navg_pr.shape\ntorch.Size([15150, 101])"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#test-data-set",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#test-data-set",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "Test Data Set",
    "text": "Test Data Set\ndls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=Resize(480, method='squish'),\n    batch_tfms=aug_transforms(size=224, min_scale=0.75))\nidxs = avg_pr.argmax(dim=1)\nidxs\ntensor([57, 71, 24,  ..., 32, 47, 38])\nvocab = np.array(dls.vocab)\nvocab\narray(['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli',\n       'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros',\n       'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel',\n       'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad',\n       'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque',\n       'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta',\n       'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad',\n       'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles'],\n      dtype='&lt;U23')\ntst_files = get_image_files(test_path).sorted()\nfilenames = [path.name for path in tst_files]\nss = pd.DataFrame({'image_id': filenames})\nss['label'] = vocab[idxs]\nss\n\n\n\n\n\n\n\n\n\n\n\nimage_id\nlabel\n\n\n\n\n0\n1000314.jpg\nhummus\n\n\n1\n1000412.jpg\npaella\n\n\n2\n1000873.jpg\nclam_chowder\n\n\n3\n100127.jpg\nspaghetti_bolognese\n\n\n4\n1001332.jpg\npanna_cotta\n\n\n…\n…\n…\n\n\n15145\n999118.jpg\nfrench_onion_soup\n\n\n15146\n999178.jpg\ncup_cakes\n\n\n15147\n999236.jpg\ndumplings\n\n\n15148\n999449.jpg\ngnocchi\n\n\n15149\n999908.jpg\nfish_and_chips\n\n\n\n\n15150 rows × 2 columns\n\n\n\nSave the file\nss.to_csv('/kaggle/working/Subm_Part3.csv', index=False)"
  },
  {
    "objectID": "posts/FastAI_Course_Lect6_Part3/index.html#concluding-remarks",
    "href": "posts/FastAI_Course_Lect6_Part3/index.html#concluding-remarks",
    "title": "FastAI Course Lecture 6 Part 3 Notes",
    "section": "Concluding Remarks",
    "text": "Concluding Remarks\nconvnext_base worked way better than convnext_tiny and significantly, better than both data augmentated variants of the transformer models ViT. And in the end we created a ensemble model by averaging them all."
  }
]